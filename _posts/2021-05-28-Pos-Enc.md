---
layout:     post                    # 使用的布局（不需要改）
title:      Pos Encoding in TR           # 标题 
subtitle:   Blank.
date:       2021-05-28            # 时间
author:     tianchen                      # 作者
header-img:  img/2021_0603/2.jpg  #这篇文章标题背景图片  
catalog: true                       # 是否归档
tags:                               #标签

---



# Pos_encoding

> 由PointTR中的Relative Pose Encoding的思考，整理一下

### 绝对位置编码

* 随机生成一个一样大的随机数seq，加上去

### 最早的 Relative Pos-enc (Sinsuidal Positional Encoding)

> < Attention is all you need >

* 最原始的Positional Encoding，element-wise的加到输入上

![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20210528144813.png)

* 固定的(本质上是一种相对位置编码)

  * pos+k位置的，可以被pos位置的线性表示

    

![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20210528144525.png)

![image-20210528145223441](C:\Users\A-suozhang\AppData\Roaming\Typora\typora-user-images\image-20210528145223441.png)

* 对称，无法区分前后关系



[1803.02155.pdf (arxiv.org)](https://arxiv.org/pdf/1803.02155.pdf)

### Pos-enc in TR

![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20210528145459.png)



## Materials

- [dk-liang/Awesome-Visual-Transformer: Collect some papers about transformer with vision. Awesome Transformer with Computer Vision (CV) (github.com)](https://github.com/dk-liang/Awesome-Visual-Transformer)

- 让研究人员绞尽脑汁的Transformer位置编码 - PaperWeekly的文章 - 知乎 https://zhuanlan.zhihu.com/p/352898810

* 

