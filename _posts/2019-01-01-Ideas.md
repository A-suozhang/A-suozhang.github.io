---
layout:     post                    # 使用的布局（不需要改）
title:      开新坑的一些Idea记录           # 标题 
subtitle:   。。。        #副标题
date:       2019-10-27             # 时间
author:     tianchen                      # 作者
header-img:  img/bg-zynq.jpg  #这篇文章标题背景图片  
catalog: true                       # 是否归档
tags:                               #标签
     - private
---

# NN Training Application
* FPGA Online Train 
* Senstime在做的是Online Fix这相关的工作
    * 采集到用户识别错误的反馈样本，去Fix整个模型
    * 我理解上可能就是用户这次识别不出来了，as a feedbcak, 然后处理的是人脸上相关的一些Class imbalance的问题，让样本平衡起来



### TODO:LIST
1. 需要把几个数据集的环境搭起来
    * Mnist-Synthdigits-SVNH
    * ~~Office~~
    * ~~ImageCLEF~~
      * ~~需要拿bash命令做一下数据集,可以仿照imagenet那个 ~~
        * rnm那个是个暴力脚本,搞死了
    * VisDA 
2. ~首先复现一下在各个数据集上的finetune效果 (基本就是office) **Sat**~~
3. 无论如何我们都需要证明一下AdaBN能否work  **Sun**
    * ??存疑 
    * ~~以最简单的Office数据集做实验~~
      * 并不Work！！
4. ~~重现一下Async-Tri Training这种填补数据集的方法~~
   1. 还可以参考一下Semi的尝试复现论文有没有用
   2. ??存疑,且非常关键
5. 找到了一个新的算法把我所需要做的东西基本上做过了
   * Self-Ensemble的方法，我傻了 


---

###　2019-11-5
* 算法复现有了一定可能性
* 出现了问题,发现算法不是很稳定
* 几个点可入手
  * 剪枝(先放一放)
  * 




### 2019-10-30
* 发现自己之前的idea被别人做过了(rnm)
  * Self-Ensemble的方法(甚至比我的思路更Elegant)
* 可以拿过来做压缩 - 作为我的切入点
  * （效果还不是很清楚，需要实验）
  * 理论上可行是因为实际上的迁移学习的场景大部分是拿ImageNet Pretrain的模型来Finetune
    * 所以理论上这个模型一定是有冗余的
* （之前在Semi上考虑的问题太多了，比如一直训练会不会崩这种，其实不用考虑那么多）
  * 比如现在这个就存在一个来的数据非常Class Imbalance怎么办
  * 其实是一个OpenSet的问题，也可一定程度上解决

## Problem
* 现实场景中的Label会比较少
* 现实场景与预先的场景不一致(会遇到完全没有见过的东西)

## Possible Application
* Trasnfer
    * Domain Adap
    * ~~其实这个角度会比较偏向算法层面了~~
* KD 
    * 好处在于拿KD做量化基本能够保证涨点数
    * 拿KD相当于Ensemble去做肯定能涨，但是在现实场景中不一定有意义
        * 要是提前训练好了的
    * 现实场景中样本Label较少
    * Facebook的最近的研究：[Billion-scale semi-supervised learning for image classification](https://www.semanticscholar.org/paper/Billion-scale-semi-supervised-learning-for-image-Yalniz-J%C3%A9gou/88ee291cf1f57fd0f4914a80b986a08a90d887f1)
* 在线压缩
    * （？）有一点意味不明，既然我可以fit下一个大模型，为啥还要动小模型

## Related Work
* Semi-Supervised-Learning-From-Unlabel Data
* Self-Training
* Transfer Learning
* Class Imbalance


## Training需要面对的问题
* Label哪里来？
* 存储是怎么样的form？
* 训练崩了
* 在线训练的需求？
    * online场景能够接受到最真实的数据
    * online场景能够接受到大量的数据

---

# ✅ 思路一：Semi-Supervised Training

### 可以Brag的点
* 提升NN效率-设计好的架构，是提高数据利用率
    * 可以说是从**增加数据**的角度提高了网络的Performance
* 利用了没有被利用的数据，自己采集数据更新自己，一定程度上的Incremental

### 解决的问题 (有什么意义)
* 可以解决Label的问题
    * 通过一个Teacher来获得Label，目前除了Self-Training之外没有特别好的别的解决办法
* 可以保证底线
    * （但是理论上如果数据域和训练集差距实在太大的话也会出问题）
    * Teacher Model是Fixed，精度有一定的保证
* 完成了一个Transfer Learning的问题
    * 严格来说不太算是Transfer...但是由于接触到了实际数据域
    * （但是理论上必须是数据集中有的东西，也就是做不到Transductive或者是Incremental）
* 相比于直接Training
    * 有更多的数据，保证能够提高精度
    * 真实世界的数据，拟合Task-Specific有保证
    * 同时支持新的Label的进入(由于维护了一个TrainingSet，不完全需要)
* 与IL的相关部分
    * 相当于没有Label-或者有少数Label的Joint Training
        * *对于很多实际应用场景来说，缺的是Label而不是Data
* 其提供的是workflow，可以尝试对其他网络用

### Related Field
1. Semi-Supervised Learning
    * *Semi-Supervised Learinng 核心在于利用现有的模型，通过一些方法维护一个扩大的Training Set获得更好的效果。*
        * 与Few-Shot Learning相联系，当一开始的数据量和类别很少的时候
        * 与Incremnetal的联系，当Semi -Supervised可以学习到新的类别的时候，就可以叫做Transductive Learning，也就是一定意味上的IL(~~目前我们的workflow做不到，可以作为未来拓展~~)
        * 由于传统NN的Training Scheme属于Full-Supervised Learning，做semi-supervised的时候其实是对如何建立新的Training Set的时候下功夫
            * 有一些基于Toll的方法
            * 如果需要新增类别有时候有一些基于图的方法，比较复杂
    * (FAIR的文章中说的)目前主要的Unsupervised方法，只能取得微弱提升[ECCV2018 Paper](https://scholar.google.com/scholar_url?url=http://openaccess.thecvf.com/content_ECCV_2018/html/Dhruv_Mahajan_Exploring_the_Limits_ECCV_2018_paper.html&hl=zh-CN&sa=T&oi=gsb&ct=res&cd=0&d=8358288919170046195&ei=iBSfXdO5CMi2ywTcv7PYAg&scisig=AAGBfm368DTBQjMnx_giq93EFc4r29RbNQ)
        * 除非是一些Weakly Supervised的(新来的数据不是完全无Label)
    * 传统的一些用到*Label Propogation*的算法
        * 在初始类别少的时候work，但是多了之后gain不明显
        * 而且需要维护一个很大的Graph
        * Low-shot learning with large-scale diffusion
    * 特点是用部分已有的数据，针对大量Unlabeled的数据去提高Performance
    * 在传统ML中是一个很传统的问题，DL领域研究相对少
    * 如果有涉及到Transductive Learning就可以认为是incremental了
        * *也就是是否可以学到pretrain所提供的以外的类别*
        * 但是本文目前没有提及，并且理论上不可以    
        * 而且目前已有的实现方法普遍比较玄学而且复杂
2. with Transfer Learning
    * *TL完成的是一个Domain Adaptation的问题，当实际场景的数据未知(在我们的case中实际场景有数据但是没有Label，也是一定意义上的未知)，通过一些训练技巧以及结构的设计，完成训练*
    * 应该本质上属于弱的迁移学习
        1. 首先完成的任务是一样的
        2. 其次数据物理上差距不大(都是光学，只是不一样的语义信息)
    * ~~又在一定意义上和迁移学习的本质相矛盾，迁移学习是在*获得不到实际场景数据的时候*~~
3. KD 知识蒸馏

### 存在的问题(慢慢看)
1. 不知道论文结果是否能复现 ~~这是个灵魂问题~~
2. 需要一个更小一点的题目做为一个Part
    * 先把题目定为针对硬件的算法优化，这样如果硬件实现做不完的话也可以
    * **也太tm Large Scale了!!** 可不可以把**问题的规模**缩小?（*因为实际应用场景很多不需要一个这么完全的模型，一般都是针对小一些的问题*）
        * 是否可以尝试对小问题？
        * 是否可以尝试对小网络对小一点的数据集？
            * 但是Kill The Bits已经能够把Res压到5Mb了，并没有证明*该种学习方法和压缩网络是否compatible*
                * 为啥可能会不匹配呢？
                    * 被压缩之后存在误差，本身的学习能力可能更差
            * 又但是这篇Work还是没有证明稀疏和压缩网络也具有这继续学习的能力（可不可以是一种新的方式）
3. ✅需要存储的数据到底有多少？
    * 每个Mini-Batch是否是独立的
    * 而且训练数据本来就是存储在DDR里面的，体量比较大
4. 比较依赖于再在true label的数据上面进行标注，那么究竟需要多少这样的数据
    * 和本身需要存下的训练数据是一个体量的，所以还ok啦
5. ✅Dual Network对硬件来说很蠢
    * 可以时分复用，一份逻辑资源，同样的网络结构
6. 必须要存下来一开始具有clean Label的数据集进行Finetune
    * 这个好像大家都必须要存，所以问题不大
7. 如果放在硬件上的话大概率是用T/S一样的Model，没体现这个架构将大模型蒸馏到小模型当中的这样一个优点
    * 需要进一步思考
8. 没利用到KD
    * ~~这个倒不是什么问题...~~
9. 存储的问题
    * 训练数据需要存下来，占据的空间有点大，有优化空间
10. 我们的实验到底需不需要这么用这么大的数据集
    * 可不可以把需要解决的问题简化？

# 可能的创新点
* 软件算法层面
    * 数据集的构建上
        * 它是对所有的排序的，这个对Streaming式的硬件不友好
            * 实际的数据是按照时间到来的，而不是一次性全都有
        * 是否需要构建一个Balanced的数据集？
            * 所以我怀疑存在的问题也许不存在
            * 我现在考虑的是实际世界场景的Class不如ImageNet多，实际只有几类，但是是否我pretrain就直接用实际场景会有的(比如kitti)
    * 是否可以和Compression结合起来
        * 和之前定点稀疏训练的算法？
    * ⭐从Transfer的角度入手
        * 单纯从Classification提点数的意义不是很有效
            * 而且~~客观条件不大允许整个10几T的数据集哈~~
        * 简单的Transfer的Flow   
            * Example-CUB
            * 先再ImageNet上面训练一个网络，最后的FC拿掉，换一个新的Softmax（1k类变200类）然后finetune出一个结果
            * 看上去很Attempting，问题是 *❌实际场景新的类别哪里来的Label呢？去拿Semi做Trasnfer可能识别新类别嗷*
            * 实际能够对应的应用场景也就是
                * 实际的数据和之前训练的数据有一定的差异，原先的模型*不会崩*，经过一个Semi的过程之后去让⭐**整个模型梗贴合实际场景**
                    * 走这个思路的化需要思考一下怎么❔实验验证
        * 🌟由于只训练一个Fc的效果不错，是否可以多个fc共用一个BaseNetwork，完成多任务迁移学习(是否可以与fine-grain的分类相结合？)
            * *但是这样的话相当于需要Training的就只是最后的一个Softmax，用不到很多的Training Trick，而且本身和Semi-Supervised Training关系不大，没有之前那个模型的话也是做不了*
            * 将两个环节结合起来，完整地完成整个学习流程之外，还利用这个做MultiTask，可以用于Fine-Grain的分类
            * ~~从我个人实验角度看不是特别Feasible~~
    * 解决Class Imbalance的问题
        * 利用Imbalance⭐做一个分类问题的*Class-Decrease*,将一个原本比较Unified的大模型去变成一个更加Task-Specific的模型，从而让模型更小
            * 去更好的Handle固定的几类

* 硬件设计层面
    * Teacher与Student的时分复用
        * ~~DPU是基于指令集的，所以这个问题实际没有必要~~

---

### 2019-10-15 组会上讲了一下

* 和云端的区分还是比较难，貌似只有*隐私问题*
    * 作为Online training会有一定的需求
    * 这个WorkFlow对应着一种Framework可能可行
* 数据集维护，可以存一段时间  
    * 理论上只要有比较好的新的数据就可以了
    * 数据集的体量是多少？
        * 目前取得比较好的效果是10x原来数据集大小的样子（对于ImageNet来说我们的实验环境难以接受了）
* 单纯的Classification提点数
    1. 实现起来不太可能，存储量太大了（这个Training一定是一个企业级的活，我自己做一定不能够这么做）
        * 除非换一个比较小的任务
    2. 本身只是为了提高一点点数，用处不是那么大
    * **往Transfer走相对会更有意义一些，需要深入思考和深入了解一下Transfer Learning，有一个系统的见解**
        * 往Transfer方向考虑的曾C说了一个余老板那边的实际需求：仿真环境训出来的东西到了实际场景用不了
            * 这个还是一个比较浅一点的TL，基本都是光照，移动
* 确实Online Training 梯度也会有精度损失，会不会产生影响
* **Class Imbalance**也确实是一个需要解决的问题
    * 一个Idea是是否需要解决这样的一个问题？ 可不可以就以一个大model为Base，然后去依据到来的数据训练出对应的模型（这也是一定意味上的De-cremental？）
        * 其实这个思路就很类似于Transfer了
    * *需要Handle的一个问题是文章中所谓的当dataset不balance的时候准确度下降*其实是因为某些类没有被训练好而导致拉低了总体的精度

* 关于**Online Learning**
    * 是一个肯定存在需求的方向
        * 但其实还是取决与这个Online的场景能不能学到所谓"新的知识"
            1. 按照semi的workflow是完全没有的，还是原来的东西
            2. 按照Transfer的方案，其实是去后训一个Classifier
                * 目前看来最Promising的一个⭐
            3. 能做到辨识新的东西
                * 需要一个Incremental了，目前的算法感觉不是特别靠谱
    * 目前来说很多研究感觉*实验设计都不太考虑实际应用场景，很多都往所谓AI的“学习能力”在做，不是特别和硬件实现相契合关契合*
        * 说白了就是Training的这个Workflow还没有定论，甚至都没有人去解决Label的问题，如果我们最后的目标是硬件实现或者这加速的化，不是很Feasible
        * 所谓的Online偏向Continual“继续学习”的能力
        
---

## 2019-10-18 有了新的思路和思考
* 大概有几个思路
    * Semi-Supervised的思路：Teacher-Student的FrameWork，Require更大量的数据
        * 优✅
            * 可以和后两个思路相结合
        * 劣❌
            * 单纯的提升Classification的点数意义不大
                * 🉑是不是可以和Transfer结合起来？给与Transfer更大的数据量
            * 实现起来不是特别Feasible
                * 如果对ImageNet做拓展的化，需要10倍的数据，到达10T的量级,算法做起来压力会比较大
    * Transfer Learning的思路，本质上是一个Domain Adaptation问题
        * 可以用AdaBN，不会引入太多的额外计算
            * 也可以看是否可以和Coral结合 
        * 可以和Semi-Supervised的思路联系起来
            * AdaBN本质上是一个Unsupervised Transfer的问题，解决的是实际场景没有Label和Data的问题
            * 论文中也提到了AdaBN可以和Semi-supervised的TL联系起来，用Label做Finetune
            * 同样也可和第一文章中的相结合，可以认为是利用Teacher产生的Soft Label去Finetune，获得更好的效果
        * 优✅
            * 实现起来比较Feasible，数据集和代码都比较多
            * 更有意义一点，可以增加模型的*鲁棒性*
            * *如果与Semi的方式结合*可以完成一个压缩（Teacher是一个大网络，Student是一个小的）
        * 劣❌
            * 数据集相对比较小，ResNet会干的很高
            * *Semi-Supervised*的一个要求是Teacher必须基本靠谱，那么就会有一个灵魂问题，*当我们已经有了一比较好的模型的时候为什么还要继续Semi呢？*
                * 🍰:Finetune理论上一定可以增加一定的TL性能（前提是给的Label正确）
                    * 在Teacher推断的时候加上AdaBN（理论可以达到SOTA的）
                * 🍰:可以通过这个过程做一个*压缩*
        * 🔨拟构想实现方式 
            * Transfer Learning的基本方式
                * 先在某一个Sub-Set上Pretrain teacher
                * 按照Semi的方式对数据做一个Soft Label
                    1. 维护一个新的Training Set
                    2. 或者利用这些Soft Label去首先对Teacher/Student做Finetune
                    3. （这个过程中是否可以引入Coral的方式进行训练？）
            * ❌问题：
                * TL的数据集，数据量达不到Larger的程度
                    * 但是理论上不太需要得到
    * Class-Decrease的想法-从一个大模型入手，逐渐走向
        * 🔨也可以利用Teacher-Student的Semi-Learning架构
            * 相比于上面的Design Flow，可以把Teacher做为ImageNet Pretrain模型
            * 然后实际场景的训练是更小的一个Task，同时有Domain Shift
                * 但是不大可能识别之前类别中没有的...

* 原本的数据到底需要存多少?
    * 从AdaBN的角度看只要能够反映分布
    * 从Semi的角度看，需要让最后那个Finetune能保证Clean Label足够
* 还是没有办法解释为何不做云计算训练?

### 目前的思路 2019-10-18 Noon
* 思路 – 进一步改进TL
    * 《Billion Scale Semi-Supervised Learning》说明了大量带Noise Label的数据可以提升性能，以及Teacher-Student架构可以将Stuednt的性能提升到SOTA之上
        * 前提是有一个相对还不错的Teacher，引入AdaBN可以解决这个问题
    * 《AdaBN》不需要额外的计算，就能让Trasnfer的性能达到SOTA
        * 并没有对模型的参数进行改进，所以模型其实是没有改进的
    * 通过大量数据对网络进行Finetune可以显著提升Transfer Learining的性能(显然)
    * Finetune需要Target Domain数据的Label （利用Semi-Supervised的思路可以为新网络提供Noise Label）

* 思路 – 进行模型蒸馏
    * 以上的Teacher-Student Scheme, Teacher Model可以是一个更大的网络，而我们实际的Student可能是一个更小的网络,提升的是小网络上的TL效果
    * Online Pruning(?)
    * 有可能可以解决Online Training的Overfitting的问题
    * 是否可以做Class-Decremental
        * 但是做不到新的类别
* 可能的问题
    1. Training Set 如何构建
        * Training Set取多大？对于Source Domain的数据需要存多少？(用于Semi-Supervised的Design Flow最后的Finetune)
        * Semi文中对构造Training Set是按照置信度排序的（硬件不友好）
        * Semi文中强调构造一个Class-Balance的Training Set
            * 当预训练Dataset中类别比实际类别多的时候其实并不需要分所有
    2. 与量化压缩的方法可否Compatible
        * 模型压缩量化为训练中引入了额外的精度损失，算法在压缩后是否Work？（理论问题不是特别大）
    3. Transfer Learning的算法实现问题
        * 待实验
    4. Online Trainig过多Iter是否会Suffer Overfitting？
        * 需要找到一个采集数据以及训练iter的平衡
        * 或者尝试去做Online Prunning
    5. 当我们已经有了一个相对好的Teacher的时候，Student的必要性？
        * 可以做压缩，以更少的资源代价获得（或许）更好的性能
        * 可以做Class Decremental，更加高效

### 新的思路考虑 2019-10-25 (该找一个切入点了)
* 多出一个所谓的可以做压缩!
  * 做剪枝,体现了硬件友好,而且可以加速
  * 和定点训练理论也可一定程度上结合起来
* 但是是否能够work?
  * 拿一个Teacher给出Soft Label拿过来做训练倒是很有说服力度,也可以和KD结合
  * 一个大Teacher和一个小Student,小的Student还可以是稀疏的,进一步剪枝
    * 大Teacher可以是一个比较普遍的模型
* ATDA还是纯利用训练一个新的fc来做trasnfer
  * 本质上有点暴力,没有从distribution的角度考虑问题
  * 我们通过引入AdaBN,来解决这个问题
* 
* 目前**急需一个能够串起来的一个思路马上去干**
* 目前来说可以Settle的
    * 对Student是Pretrain一个还是Finetune做剪枝,都可以
    * 对于数据集的构建方式(与其说是可以选不如说是要去找到一种)







---
## 🤔待讨论的问题🤔
* 一个CNN的数据表征能力取决于两个要素
    * 模型Capacity和数据量(无限增加两者都会先线性增加，然后趋于平稳)
    * 对于量化与剪枝是否是冗余度越大，就越能够压缩（！）
        * 而KD与一般的剪枝可以并列的原因就在于：KD相当于增加数据，以获得更好的表征能力（用有限的资源解决问题的效率）；而一般的剪枝可以看做是减少资源
        * 该方法与KD相类似，都是通过增加表征能力
* 目前可不可以认为整个CNN结构设计总体上在向Res+Inception收敛
    * NAS相关的领域有没有给出一个很新的很breakthrough很elegant新架构
* ~~定点量化的Finetune和KD是真滴合适~~
* NN的过拟合是不是数据表征能力过于强（模型太大了），而数据集不够大
    * FAIR的SEMI文章的结果表明，引入了数据之后，性能随着训练iter数目的拐点向后延迟了
        * 越训练NN的表征能力越强，同时性能也会越强，当超出数据集之后体现为Overfitting


---

## 参考文献📚

#### Co-Learning

* Dasgupta S, Littman M L, McAllester D A. PAC generalization bounds for co-training[C]//Advances in neural information processing systems. 2002: 375-382.

* Balcan M F, Blum A, Yang K. Co-training and expansion: Towards bridging theory and practice[C]//Advances in neural information processing systems. 2005: 89-96.

* Saito K, Ushiku Y, Harada T. Asymmetric tri-training for unsupervised domain adaptation[C]//Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017: 2988-2997.

#### Transfer Learning
* Sun B, Feng J, Saenko K. Return of frustratingly easy domain adaptation[C]//Thirtieth AAAI Conference on Artificial Intelligence. 2016.
* Tzeng E, Hoffman J, Darrell T, et al. Simultaneous deep transfer across domains and tasks[C]//Proceedings of the IEEE International Conference on Computer Vision. 2015: 4068-4076.
* Motiian S, Piccirilli M, Adjeroh D A, et al. Unified deep supervised domain adaptation and generalization[C]//Proceedings of the IEEE International Conference on Computer Vision. 2017: 5715-5725.
* Long M, Cao Y, Wang J, et al. Learning transferable features with deep adaptation networks[J]. arXiv preprint arXiv:1502.02791, 2015.
* Yang S, Wang H, Zhang Y, et al. Semi-supervised representation learning via dual autoencoders for domain adaptation[J]. arXiv preprint arXiv:1908.01342, 2019.
* Shen J, Qu Y, Zhang W, et al. Wasserstein distance guided representation learning for domain adaptation[J]. arXiv preprint arXiv:1707.01217, 2017.
* Wang M, Deng W. Deep visual domain adaptation: A survey[J]. Neurocomputing, 2018, 312: 135-153.
* F. Zhuang, X. Cheng, P. Luo, S. J. Pan, and Q. He. Supervised representation learning: Transfer learning with deep autoencoders. In IJCAI, pages 4119–4125, 2015.
* K. Saito, K. Watanabe, Y. Ushiku, and T. Harada. Maximum classifier discrepancy for unsupervised domain adaptation. arXiv preprint arXiv:1712.02560, 2017.
* S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. Domain adaptation via transfer component analysis. IEEE Transactions on Neural Networks, 22(2):199–210, 201
* V. M. Patel, R. Gopalan, R. Li, and R. Chellappa. Visual domain adaptation: A survey of recent advances. IEEE signal processing magazine, 32(3):53–69, 2015
* R. Gopalan, R. Li, and R. Chellappa. Domain adaptation for object recognition: An unsupervised approach. In Computer Vision (ICCV), 2011 IEEE International Conference on, pages 999–1006. IEEE, 2011.
* L. Zhang, Z. He, and Y. Liu. Deep object recognition across domains based on adaptive extreme learning machine. Neurocomputing, 239:194–203, 2017.
* Saito K, Kim D, Sclaroff S, et al. Semi-supervised Domain Adaptation via Minimax Entropy[J]. arXiv preprint arXiv:1904.06487, 2019.

### Others
* S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International Conference on Machine Learning, pages 448–456, 2015.
