---
layout:     post                    # ä½¿ç”¨çš„å¸ƒå±€ï¼ˆä¸éœ€è¦æ”¹ï¼‰
title:      Paper Stack æ–‡ç« å †æ ˆ           # æ ‡é¢˜ 
subtitle:   å¾…è¯»çš„æ–‡ç« å’Œæ— å¤„å®‰æ”¾çš„æ–‡ç« è§£è¯»   #å‰¯æ ‡é¢˜
date:       2024-01-01            # æ—¶é—´
author:     tianchen                      # ä½œè€…
header-img:  img/5_1/wf-0.jpg  #è¿™ç¯‡æ–‡ç« æ ‡é¢˜èƒŒæ™¯å›¾ç‰‡  
catalog: true                       # æ˜¯å¦å½’æ¡£
tags:                               #æ ‡ç­¾
     - å¿ƒå¾—
     - å¸¸ç”¨
     - è®ºæ–‡é˜…è¯»
     - ç»¼è¿°
---

# çŸ³å¢¨æ–‡æ¡£List

* [GATES Related](https://shimo.im/sheets/T3Cp36PRHPj38TKp/MODOC)
* [NAS Reading List](https://shimo.im/sheets/T3Cp36PRHPj38TKp/MODOC)



# Paper Stack æ–‡ç« å †æ ˆ

### GNN

* Foundation

### NAS

* [Transfer Learning with Neural AutoML](https://arxiv.org/pdf/1803.02780.pdf)
  * Parallel Training on Multi-tasks, Transfer the search strategy
  * å½“æœ‰äº†ä¸€ä¸ªpretrainedçš„controllerçš„æ—¶å€™ï¼Œåªæœ‰task embeddingéœ€è¦æ›´æ–°
  * Generic SS (Learned task representation & Task-specific advantage normalization)  
  * In standard single-task training of NAS, only the embedding
of the previous action is fed into the RNN. In multitask training, the task embedding is concatenated
to the action embedding. We also add a skip connection across the RNN cell to ease the learning
of action marginal distributions

* [MetAdapt: Meta-Learned Task-Adaptive Architecture for Few-Shot Classification](https://arxiv.org/pdf/1912.00412.pdf)
  * ç”¨MetaLearning+NASæ¥æœç´¢å‡ºæ›´é€‚åˆFew-shotçš„æ¶æ„
  * Differentiable-NAS
  * å‘ç°FewShotLearningçš„backbone modelæ˜¯å…ˆè¶Šå¤§è¶Šå¥½ï¼Œç„¶åä¼šå·®
    * è®¤ä¸ºD-NASå¯ä»¥mitigate overfitting
    * Follow DARTS - Arch as DAG
  * ä¸ä¸€åŠNASä¸åŒï¼Œä¸æ˜¯æ‰¾åˆ°ä¸€ä¸ªæ¶æ„ç”¨
    * æ‰¾åˆ°èƒ½æ›´å¿«adaptåˆ°åˆ«çš„taskçš„
    * æœ‰ä¸€ç³»åˆ—small networks,MetAdapt Controllerï¼ŒåŒæ—¶æ›´æ–°weightsï¼Œä¿®æ”¹connection
  * FewShotLearning
    * Metric Learning based
      * Learn a non-linear embedding into a metric space, use L2 distance for classification
        * (Some change L2 disatnce with a implicit learned function/GNN)
      * Could improve when adding semantic information
    * Generative Based
      * æˆ–è€…è¯´æ˜¯augmentation-based
      * è®¾è®¡åˆ°ä¸€äº›transferç›¸å…³çš„ä¸€äº›ä¸œè¥¿
    * Meta Learning - learn a learning stragegy easily adapted to other few-shot tasks
      * trained on a set of few-shot tasks (episodes)
      * å¦å¤–ä¸€æ”¯æ˜¯gradient-based
        * MAML
        * MetaSGD
    * MetAdaptçš„flow
      * arch as DAG , feature map as node / op as edge
      * Task-Adaptive Block
* è¿™ä¸ªå›¾çš„é…è‰²ä¸é”™
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200313202441.png)

* [Channel Gating Neural Networks](https://papers.nips.cc/paper/8464-channel-gating-neural-networks.pdf)
* æ€æƒ³æ¥æºäºFeature Mapä¸­æœ‰å¾ˆå¤šç»å¯¹å€¼å°çš„åœ°æ–¹ï¼Œè¿™äº›ä¸œè¥¿å…¶å®æ˜¯å¯ä»¥ä¸éœ€è¦çš„
* æ ¸å¿ƒè§‚ç‚¹åœ¨äºï¼Œè®¤ä¸ºpartial sumå’Œglobal sumæ˜¯æœ‰ç›¸å…³æ€§çš„(æˆç«‹çš„å‰æå‡è®¾-åšäº†å®éªŒä¸€åŠçš„channelæœ‰0.86çš„ç›¸å…³æ€§)ï¼Œæ‰€ä»¥partial sumå‘ç°ä¸effectiveçš„éƒ¨åˆ†æ²¡æœ‰å¿…è¦ç»§ç»­åšè®¡ç®—(ä»¥ä¸€å®šcondition)
  * è¿™ä¸ªthresholdæ˜¯ç¡¬çš„
  * å¯ä»¥fine-grainä¹Ÿå¯ä»¥channel-wise
  * æŠŠæ‰€æœ‰çš„W_låˆ†ä¸€éƒ¨åˆ†W_på’Œå¦å¤–çš„W_r,å®ƒä»¬çš„ç»“æœåº”è¯¥åœ¨è¿™ä¸€å±‚æ˜¯è¦åŠ èµ·æ¥çš„ï¼ŒæŠŠW_p* X_pçš„è¾“å‡º(Partial Sum)è¾“å…¥ä¸€ä¸ªChannel Gatingæ¨¡å—ï¼Œä»¥ä¸€ä¸ªthresholdæ¥ç¡®å®šæ˜¯å¦éœ€è¦å¯¹å‰©ä¸‹çš„W_r Apply Maskï¼Œç»™å‡ºä¸€ä¸ªOut_Cç»´åº¦çš„Maskï¼Œé€‰æ‹©çš„ä¾æ®æ˜¯Feature Mapçš„Activationç»å¯¹å€¼
  * ç›¸å½“äºæ˜¯ä¸€ä¸ªæ–°çš„layer type
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200313154531.png)
* æœ‰ä¸€ä¸ªchannel groupingç¡®ä¿all channels are treated equally
  * ç›¸å½“äºé˜²æ­¢æ¯æ¬¡éƒ½æŠŠå‰å‡ ä¸ªchannelåšä¸ºW_rï¼Œæ‰€ä»¥åŠ äº†ä¸€ä¸ªchannel shuffling
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200313162432.png) 


* [Review Netowrk Pruning via Transformable NAS]()
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200317204835.png)
  * ç”¨NASæ¥å¤„ç†Channel Pruningçš„é—®é¢˜
  * æ¯ä¸ªlayerçš„channelsï¼Œé¦–å…ˆéœ€è¦è®¾è®¡ä¸€ä¸ªdistributionï¼Œç”¨ç±»softmaxçš„æ–¹å¼æ¥ï¼Œå†³å®šé€‰æ‹©æ¯ä¸ªchannelçš„æ¦‚ç‡
    * é€‰å–channelçš„è¿‡ç¨‹æœ¬èº«ä¸differntiableï¼Œç”¨gumble-softmaxæ¥
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200317203915.png)
    * CWI (Channel-Wise Interpolation) -  Adaptive Average Pooling
  

* [HAQ: Hardware-Aware Automated Quantization with Mixed Precision](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_HAQ_Hardware-Aware_Automated_Quantization_With_Mixed_Precision_CVPR_2019_paper.pdf)


* [NAO]
    * Discrete -> Continuos 
      * åŒ…å«äº†ä¸€ä¸ªencoderï¼Œå°†archæ˜ å°„åˆ°ä¸€ä¸ªè¿ç»­ç©ºé—´ï¼ŒåŒæ—¶è¿˜æ­é…ä¸€ä¸ªdecoder
      * è¿˜æœ‰predictor 
    * ä¸æ­¤ç±»ä¼¼çš„æ˜¯DARTSï¼Œè¯´DARTSè®¤ä¸ºæœ€å¥½çš„archæ˜¯å½“å‰weightä¸‹çš„argmaxï¼Œè€ŒNAOç›´æ¥ç”¨ä¸€ä¸ªdecoderæ˜ å°„å›æ¨¡å‹
      * è¿˜æœ‰ä¸€æ”¯æ˜¯Bayesian Optimizationï¼Œä½œè€…è®¤ä¸ºGPçš„æ€§èƒ½äºCovariance Functionçš„è®¾è®¡å¼ºç›¸å…³
    * Search Spaceè®¾è®¡
      * ä¸¤æ­¥ï¼Œé¦–å…ˆå†³å®š1ï¼‰which 2 previous nodes as inputs 2)ç¡®å®šè¦ç”¨ä»€ä¹ˆop
    * symmetricçš„design:ä¸ºäº†ä¿è¯symmetricçš„æ¨¡å‹ï¼ˆå®é™…ä¸Šæ˜¯ä¸€ä¸ªæ¨¡å‹ï¼‰çš„embeddingä¸€è‡´ï¼Œpredictorç»™å‡ºå·®ä¸å¤šçš„ç»“æœ
      * ç”¨äº†Augmentationï¼ˆflipï¼‰æ¥è®­ç»ƒencoder
    * Encoderå’ŒDecoderéƒ½æ˜¯LSTMï¼Œpredictoræ˜¯ä¸€ä¸ªmean-poolingåŠ mlp
    * ä¸‰è€…Jointly Train
      * è®¤ä¸ºpredictor could work as regularizationå»é¿å…encoderåªå¯¹åº”decoderçš„ç»“æœï¼Œè€Œæ²¡æœ‰æ­£å¸¸è¡¨å¾
        * è¿™ä¸€æ­¥å’Œä¼ ç»ŸVAEä¸­çš„åŠ noiseä¸€è‡´
    * è®¤ä¸ºweight-sharingå’ŒNAOæ˜¯complementaryçš„

* [SemiNAS](https://arxiv.org/pdf/2002.10389.pdf)
  * ç”¨Controller(å…¶å®æ˜¯é‡Œé¢çš„predictor)å»åœ¨å¤§é‡æ— æ ‡æ³¨çš„archä¸Šåšæ ‡æ³¨(ä¸ç»è¿‡Evaluation)ï¼Œå°†æ–°çš„Data-PairåŠ å…¥è®­ç»ƒ
  * å–ç‚¹æ˜¯èƒ½å¤Ÿæ›´å¿«çš„æ‰¾åˆ°æ¯”è¾ƒå¥½çš„æ¶æ„ï¼Œæ¯”EAä¹‹ç±»çš„æ•ˆç‡æ›´é«˜
    * ä½†æ˜¯é«˜çš„ä¹Ÿä¸æ˜¯å¾ˆæ˜æ˜¾ï¼Œæ€€ç–‘æ˜¯å¦æ˜¯NAOå¸¦æ¥çš„è€Œä¸æ˜¯Semiå¸¦æ¥çš„(æ¯•ç«Ÿç”¨è‡ªå·±æ¨æ–­å‡ºæ¥çš„æ•°æ®æ¥è®­ç»ƒè‡ªå·±(ä½†æ˜¯flowä¸Self-Supervisedåˆä¸å¤ªä¸€æ ·))
  * ç”¨NAO as exampleï¼ˆå› ä¸ºå®ƒæ—¢å¯ä»¥ç”¨åœ¨conventional train from scratchä¹Ÿå¯ä»¥åšWeight sharingï¼‰

---

* [MAML - Model Agnostic Meta-Learning for Fast Adaptation]()
  * Learn2Learn
  * å¯¹æ ‡çš„æ˜¯æœ€ç»å…¸çš„ä»pretrain modelçš„transfer learning (ä¸¥æ ¼æ¥è¯´Fintuneä¹Ÿæ˜¯ä¸€ç§Meta-Learning)
  * MAMLè¿˜å…³æ³¨ç€å¤šä»»åŠ¡(ä¸MultiTaskLearningæœ‰è®¸å¤šçš„å…³è”)
    * æ¯”å¦‚äººè„¸å…³é”®ç‚¹å’Œå®šä½æ˜¯åŒæ ·çš„ä¸€ä¸ªé—®é¢˜ï¼Œä½†æ˜¯å¯¹NNæ¥è¯´æ˜¯ä½œä¸ºä¸¤ä¸ªé—®é¢˜æ¥å¤„ç†çš„
    * MAMLæ˜¯ä»¥ä¸€ä¸ªTaskä¸ºåŸºæœ¬å•ä½çš„
  * æœ€ç»ˆç›®çš„æ˜¯**å­¦ä¸€ä¸ªå¥½çš„åˆå§‹åŒ–å‚æ•°**
  * æ–°çš„Loss Function
    * ä¸€éƒ¨åˆ†lossæ˜¯ç»å…¸çš„lossï¼Œå¦å¤–ä¸€ä¸ªéƒ¨åˆ†å…¶ä»–ä»»åŠ¡çš„æŸå¤±å‚æ•°
    * æœ‰ä¸€ä¸ªæ€æƒ³æ˜¯ä¸æ‰¾å•ä¸ªä»»åŠ¡çš„å…¨å±€æœ€ä¼˜(Global Minima)ï¼Œå› ä¸ºè¿™æ ·å¯èƒ½å¾ˆéš¾æ”¶æ•›åˆ°åˆ«çš„taskçš„å¥½ç»“æœï¼Œè€Œæ˜¯æ‰¾åˆ°å¤šä¸ªtaskä¹‹é—´çš„ä¸€ä¸ªå¹³è¡¡(ä¹Ÿä¸ç”¨æœ€å¥½)
    * è€Œä¼ ç»Ÿçš„finetuneé¦–å…ˆæ˜¯ä»ä»»åŠ¡Açš„æœ€ä½³è§£å‡ºå‘ï¼Œæ‰€ä»¥ä¸ä¸€å®šå¯¹ç¬¬äºŒä¸ªä»»åŠ¡æ•ˆæœå¥½
  * æ“ä½œ
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200317213623.png)
    * æˆ‘ä»¬å…ˆæœ‰äº†éšæœºåˆå§‹åŒ–çš„ç½‘ç»œtheta_0,åœ¨ç¬¬ä¸€ä¸ªtaskä¸ŠæŒ‰ç…§æ­£å¸¸çš„sgdè®­ç»ƒè·å¾—å‚æ•°theta_m,ç„¶åä¸æ­¤ä¸ºåŸºç¡€è·å¾—valid lossï¼Œå¹¶ä¸”ç”¨è¿™ä¸ªæ¢¯åº¦ï¼Œä¸å»ä¼˜åŒ–theta_mè€Œæ˜¯å»ä¼˜åŒ–theta_0,å»å¾—åˆ°theta_1.ä¸‹é¢å†ä»¥theta_1ä½œä¸ºä¸Šä¸€æ­¥çš„theta_0ï¼Œå»applyåˆ°ä¸‹ä¸€ä¸ªä»»åŠ¡ï¼ˆ*è¿™æ ·å»ç»å†A String Of Tasks-æœ‰ç‚¹åƒä¸€ç³»åˆ—è¯¾ç¨‹*ï¼‰

---

* [MixMatch]()
  * ç”¨Autoencoderæ¥é‡å»ºè¾“å…¥å›¾åƒï¼Œæ¥è·å¾—å¥½çš„Representation(æˆ–è€…æ˜¯ç”¨GAN)
  * Semiè¾ƒä¸ºæœ‰æ•ˆçš„å‡ ä¸ªæ–¹æ¡ˆ
    1. Consistency Regularization
    2. Entropy minimizeï¼š æ¥æºäºå…±è¯†ï¼Œå†³ç­–è¾¹ç•Œä¸åº”è¯¥ç©¿è¿‡è¾¹æ²¿åˆ†å¸ƒçš„é«˜å¯†åº¦åŒºåŸŸ(Push Back Decision Boundary)å¸å¼•å¯¹æœªæ ‡è®°æ•°ç»™å‡ºä½ç†µçš„é¢„æµ‹
       * å¯¹å½“å‰çš„ç»“æœè‚¯å®šï¼Œæ‰€ä»¥æœ‰äººç”¨å¸¦Temperatureçš„CrossEntropy 
    3. æœ€åŸºç¡€çš„L2æ­£åˆ™åŒ–(åœ¨SGDä¸‹ç­‰ä»·äºWeight Decay)
       * æœ‰è¯´æ³•è¯´Adamå’ŒL2æ­£åˆ™ä¸€èµ·ä½œç”¨ä¼šå‡ºç°åŒºåˆ«
    4. ä¸€ç§æ–°æ–¹æ³•æ˜¯MixUpï¼Œä»»æ„æŠ½å–ä¸¤ä¸ªæ ·æœ¬ï¼Œæ„é€ æ··åˆæ ·æœ¬å’Œæ ‡ç­¾
       * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200321202307.png) 
    5. MixMatch

* [En-AET]()
  * ç”¨ä¸€ä¸ªVAEå»æ‰¾åˆ°æœ€å¥½çš„transformç»„åˆ
    * encoderæ‰¾åˆ°ä¸€ä¸ªå¥½çš„embeddingï¼Œdecoder re-parameterizeå‡ºtransform

* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200321203810.png)

* å¯¹äºåœ¨NASä¸­åˆ©ç”¨Semiçš„å‡ ä¸ªé—®é¢˜
  * é¦–å…ˆæ˜¯ä¸¤ä¸ªç»´åº¦ï¼Œæ˜¯åœ¨predictoræ‰¾archçš„æ—¶å€™ç”¨semiï¼Œè¿˜æ˜¯ç›´æ¥æ‰¾ä¸€ä¸ªæ›´é€‚åˆsemiçš„ç½‘ç»œ
  * ç¬¬ä¸€ä¸ªç»´åº¦çœ‹ä¸Šå»é—®é¢˜æ¯”è¾ƒé€‚åˆï¼Œå®é™…ä¸ç„¶
    * ä½†æ˜¯åœ¨NAS Predictorä¸­æ€ä¹ˆåˆ©ç”¨unlabelçš„archæ•°æ®ï¼Œæ„Ÿè§‰å€¼å¾—ç ”ç©¶
  * åè€…çš„motivationæˆ‘è¿˜ä¸æ˜¯å¾ˆç¡®å®šï¼Œè€Œä¸”çœ‹ä¸Šå»æœ‰ç‚¹å›°éš¾
    * æ¶æ„å¯¹semiè®­ç»ƒçš„å½±å“ï¼Ÿ fewshotåˆ«äººå…¶å®è¿˜æ˜¯è¯´æ˜äº†è¿™ä¸ªé—®é¢˜çš„
    * evaluationè¿‡äºnoisyï¼Œä¸èƒ½å¾ˆå¥½çš„è¡¡é‡ï¼Œå¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºè®­ç»ƒçš„Trick
  * 1ï¼‰ ç®—æ³•ä¸Šæ˜¯å¦å¯¹æ¶æ„æœ‰å½±å“
  * 2ï¼‰ æœ‰ä¸€ä¸ªæ–°çš„ä»»åŠ¡ï¼Œåœ¨çº¿å¤„ç†è¿™äº›æ ‡æ³¨æ•°æ®ï¼› è¦è¯´æ˜åˆ«çš„ä»»åŠ¡ä¸Šçš„æ¶æ„ä¸èƒ½work
 
* [Data Efficient Image Recognitio with Contrastive Predictive Coding](https://arxiv.org/pdf/1905.09272v2.pdf) by DeepMind
  * å°†Unsupervisedé¢†åŸŸçš„Contrastive Predictive Codingçš„æ–¹æ³•æ”¹è¿›(revisit)å¹¶ä¸”åŠ å…¥åˆ°Semiå½“ä¸­
  * ç›®å‰Semiçš„ImagenetSOTA / Also work on Det (PASCAL_VOC 2007)
  * CPC - Contrastive Predictive Coding
    * Learn Representation
  * Workflow
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200326142002.png)
    * 1. Unsupervised Spatial Prediction
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200326153411.png)
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200326153436.png)
      * é¦–å…ˆå°†å›¾ç‰‡åˆ†ä¸ºå¤šä¸ªæœ‰Overlappingçš„Patchï¼Œæ„æˆä¸€ä¸ªGrid
      * ç»è¿‡ä¸€ä¸ªå‰æ™¯Feature ectractor,æœ€åæ¥ä¸€ä¸ªMean-Poolingï¼Œä¿è¯æ¯ä¸ªPatchå¯¹åº”ä¸€ä¸ªFeature vector
      * ä¹‹åå†ç»ä¸€ä¸ªContext Networkï¼Œç›®çš„æ˜¯Recognizeå‡ºè¾“å…¥çš„Embedding(Feature Vector)æ˜¯æ¥è‡ªå“ªä¸ªGrid Cell
        * ContextVectorè¾“å…¥çš„æ˜¯ä¸€ç³»åˆ—Zij(å…¶æ„Ÿå—é‡æ˜¯æ‰€æœ‰åœ¨å®ƒä¹‹å‰(â†–)çš„Zijï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªcontext Vector cij
        * è¿™é‡Œè®­ç»ƒä¸­ç”¨åˆ°äº†InfoNCE Lossï¼Œæ”¹è¿›è‡ªNCE(NoiseContrastiveEstimation)æœ€å¤§åŒ–cellä»¥åŠå…¶æ¥è‡ªä½ç½®çš„mutual infoï¼Œå°±æ˜¯ä»Z_lä¸­é‡‡æ ·å‡ºä¸€äº›zï¼Œåªæœ‰zij matchäº†æ‰æ˜¯æ­£æ ·æœ¬
        * Encoderå’ŒContext Networkä¸€èµ·è®­ç»ƒ  
        * **è¿™ä¸€æ­¥çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ä¹‹å‰çš„ä¿¡æ¯å»é¢„æµ‹ä¹‹åçš„ä¿¡æ¯ï¼ŒContextVector-Cijä¸­åŒ…å«äº†ZiJ+çš„ä¿¡æ¯ï¼Œä½†æ˜¯å…¶ä¸æ˜¯è¾“å…¥**
          * ä»¥æ­¤å»è·å¾—æ›´åŠ Consistentçš„Featureï¼Œå°±æ˜¯Time(è¿™é‡Œæ˜¯Location-Invariantçš„Feature )
    * 2. ClassificationTask
      * åé¢çš„ContextNetworkä¸è¦ï¼Œç›´æ¥åˆ©ç”¨å·²æœ‰çš„LabelæŒ‰ç…§Supervisedçš„æ–¹å¼æ¥ä¸€ä¸ªåˆ†ç±»ç½‘ç»œ(ç”šè‡³å¯ä»¥æ˜¯ä¸€ä¸ªç®€å•çš„Logistic Regression)

* ä¸Šæ–‡çš„å‰èº«[Contrastive Predictive Coding](https://arxiv.org/abs/1807.03748)
  * [Post](https://mf1024.github.io/2019/05/27/contrastive-predictive-coding/)
  * Unsupervised Training Feature Extractor for Representation
  * æ€æƒ³æ˜¯åˆ©ç”¨Predictionä½œä¸ºç›®æ ‡(objective)
    * å¸¸è§çš„æ€æƒ³æ˜¯Training the model to predict Future / Some Missing Information(å¯¹äºä¸Šæ–‡æ¥è¯´å°±æ˜¯Patchå¯¹åº”çš„Localizationçš„Info)
      * è¿™ä¸ªæ€æƒ³æ˜¯å¦ä¸VAEæˆ–è€…æ˜¯GANçš„æ€æƒ³ç±»ä¼¼ï¼Ÿ
    * åˆ©ç”¨è¿™ä¸ªPredictioné—®é¢˜æ‰€æå–çš„Encoder
  * åœ¨é‡‡å‡ºçš„ä¸€ä¸ªæ­£æ ·æœ¬å’Œä¸€ç³»åˆ—è´Ÿæ ·æœ¬ä¸­ï¼Œè®©é¢„æµ‹ç»“æœå»è´´åˆæ­£æ ·æœ¬ï¼Œæœ€å°åŒ–çš„æ˜¯äº’ä¿¡æ¯é‡/æˆ–è€…æ˜¯KLæ•£åº¦(ç±»ä¼¼è¿™æ ·çš„æ–¹å¼)
  * *è¿™ç¯‡æ–‡ç« æœ¬èº«ä¸æ­¢è¯´Vision(è¿˜æœ‰NLPå’ŒRL)ï¼Œä¸Šé¢é‚£ç¯‡æ˜¯åªé’ˆå¯¹Visual*

* ç›¸å…³çš„æœ€è¿‘çš„paperè¿˜æœ‰[A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709v1.pdf)
  * Hintonåšçš„ä¸œè¥¿
* [S4L-Self-Supervised Semi-Supervised Learning](https://paperswithcode.com/paper/190503670)
  * ICCV2019 - Google




* [BigBiGAN - Large Scale Adversarial Representation Learning](https://arxiv.org/pdf/1907.02544v2.pdf)
  * DeepMind
  * æŒ‡å‡ºäº†è¿‘å¹´æ¥Self-Supervisedçš„æ–¹æ³•é€æ¸æ‰“è´¥äº†åŸºäºAdversarialçš„ï¼Œæœ¬æ–‡ç€æ‰‹äºç”¨Adversarial learningæ¥æ”¹è¿›Representation
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200326155430.png)
  * ä¹‹å‰çš„å·¥ä½œBigGANå’ŒALI(Adversarial Learnt Inference)å…¶flowä¸€èˆ¬ä¸º:
    * æˆ‘æœ‰Data Xæœä»åˆ†å¸ƒP_xï¼Œè¿˜å¯¹latent Variable Zæœ‰ä¸€ä¸ªåˆ†å¸ƒP_z(ä½œä¸ºpriorä¸€èˆ¬æ˜¯gaussian)ï¼ŒGeneratorå»ºæ¨¡P(X|Z)-ä¹Ÿå°±æ˜¯ä»åˆ†å¸ƒP_zä¸­é‡‡æ ·å‡ºLatent Variable Zï¼Œç„¶åè¿˜åŸå›Xï¼›å¯¹äºä¼ ç»Ÿçš„GANï¼Œæœ‰ä¸€ä¸ªDiscriminator(Encoder)å»ºæ¨¡ç›¸åçš„æ¦‚ç‡åˆ†å¸ƒP(Z|X),ç»™å®šæ•°æ®ï¼Œpredictè¿™ä¸ªembedding(\epsilon)
    * BiGAN(bidirectional)åŠ å…¥äº†ä¸€ä¸ªJoint Discriminator,è¾“å…¥çš„æ˜¯ä¸€ä¸ª(X,Z)çš„Pairï¼Œéœ€è¦åˆ†è¾¨çš„æ˜¯å®ƒä»¬æ˜¯æ¥è‡ªSample&Encodingè¿˜æ˜¯LatentSample&Generator
      * è¿™æ ·çœ‹æ¥Generatorçš„ç›®çš„æ˜¯â€œFoolâ€Disciminator by è®©ä¸¤ä¸ªè”åˆåˆ†å¸ƒæ›´åŠ æ¥è¿‘P_x\epsilon & P_zGï¼ˆä¸¤è€…ä¹‹é—´çš„è·ç¦»ç”¨äº†ä¸€ä¸ªJenson-Shannon Divergenceï¼‰
    * ä¸€ä¸ªæœ‰è¶£çš„è®­ç»ƒç»“æœæ˜¯ï¼Œå½“G/Déƒ½æ˜¯ç¡®å®šçš„å‡½æ•°çš„æ—¶å€™(ä¸¤ä¸ªåˆ†å¸ƒæ˜¯ç‹„æ‹‰å…‹åˆ†å¸ƒçš„æ—¶å€™)å®ƒä»¬ä¸¤ä¸ªåœ¨Global Optimalç‚¹ä¸Šæ˜¯äº’ä¸ºç›¸åå€¼
  * æœ¬æ–‡å‘ç°ä¿®æ”¹äº†Discriminatorèƒ½å¤Ÿåœ¨ä¸compromiseGeneratorçš„æƒ…å†µä¸‹æå‡æ€§èƒ½
    * Disciminatoræœ‰ä¸‰ä¸ªç»„ä»¶FHJï¼ŒFçš„è¾“å…¥åªä¸ºXï¼ŒJçš„è¾“å…¥åªä¸ºZ
  * å®é™…åšåˆ†ç±»çš„æ—¶å€™æ˜¯å…ˆUnlabelçš„è®­ç»ƒä¸€ä¸ªBigBiGANï¼Œç„¶åFreeze Representationï¼Œè®­ç»ƒä¸€ä¸ªLinear Classifieråœ¨æœ‰labelçš„æ•°æ®ä¸Šå±•å¼€


* [Convolutional Networks withAdaptive Inference Graphs](https://arxiv.org/pdf/1711.11503.pdf)
  * æŒºæœ‰æ„æ€çš„ä¸€ç¯‡æ–‡ç« ï¼Œæ€æƒ³æ˜¯CNNä¸éœ€è¦ä¸€ç›´FeedForwardä¸‹å»ã€
  * ä»¥ä¸€ä¸ªAdaptive Inference Graphçš„æ€æƒ³
  * Robustnessè§’åº¦ä¹Ÿèƒ½æ›´å¥½

* [Learning multiple visual domains with residual adapters](https://arxiv.org/abs/1705.08045)
* ğŸ”‘ Key:    
  * é€šè¿‡ä¸€ä¸ªResidueçš„Adapterï¼Œå­¦ä¹ å¤šä¸ªTaskçš„Share Representation
* ğŸ“ Source:  
  * VGG-Oxford   NIPS2017 
* ğŸŒ± Motivation: 
  * ä¼ ç»Ÿçš„æ–¹æ³•å¯¹ä¸åŒçš„Problem/Data,å­¦ä¹ ä¸åŒçš„Representationï¼Œæœ¬æ–‡ç›®çš„æ˜¯å­¦ä¹ ä¸€ä¸ªRepresentationå»å¤„ç†å¤šä¸ªä»»åŠ¡
  * Tunable Network Structureï¼Œé€šè¿‡ä¸€ä¸ªAdapter Residue Blockï¼Œå¯ä»¥å¯¹ä¸åŒdataset on-the-flyçš„è°ƒæ•´  
* ğŸ’Š Methodology:
  * å¯¹Data-dependent Learningé—®é¢˜ï¼Œå¯ä»¥æŠ½è±¡ä¸ºç”¨ä¸€ä¸ªAuxiliaryç½‘ç»œæ¥ä»Input Dataï¼ŒPredict Domainï¼Œdomain specificçš„paramå°±å¯ä»¥ç”¨ä¸€ä¸ªç½‘ç»œæ¥predictå‡º(ç›¸å½“äºå»Parameterizeè¿™äº›domain-specificçš„param)
  * æœ¬æ–‡è®¤ä¸ºçº¿æ€§çš„å¯¹filter paramåšparameterizationç­‰ä»·äºåŠ å…¥ä¸€ä¸ªæ–°çš„ä¸­é—´å±‚ï¼Œè¿™æ ·å°±å¯ä»¥æ˜¾å¼çš„åŒºåˆ†å¼€Domain-specificå’Œdomain-invariantçš„featureäº†
  * æ‰€ä»¥å¼•å…¥äº†ä¸€ä¸ªAdaptive Residue Block
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200415131036.png)
    * å…¶ä¸­\alphaè¢«é™å®šä¸º1x1Conv
    * åœ¨Adapter1x1Convä¹‹å‰æœ‰ä¸€ä¸ªBNï¼Œå…¶scaleä¸biasä¹Ÿæ˜¯domain-specificçš„
    * å¯¹æ¯”äº†ä¸€ä¸‹domain-(in)variantçš„dataæ¯”ä¾‹
      * 2(h^2C^2+hC)ä¸ªæ— å…³çš„/2(C^2+5C)ä¸ªæœ‰å…³çš„(hæ˜¯kernel sizeï¼Œä¸€èˆ¬æ˜¯3)
  * ä¼ ç»Ÿçš„Multi-Domain Learningç”¨finetuneçš„æ–¹å¼ä¼šé™·å…¥Catastrophic Forgetting
    * æœ¬æ–‡é¦–å…ˆåœ¨ä¸€ä¸ªå¤§çš„domain(æ¯”å¦‚Imagenet)ä¸Šè®­ç»ƒdomain-invariantçš„ï¼Œç„¶åå†åªtune domain-specificçš„
* ğŸ“ Exps:
  * Different Visual Tasks
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200415115730.png)   
    * FGVC-Aircraftï¼š 100Imagex100Class    
    * DPes: 50,000 Greyscale Pedestrain [18*36]
    * DTD: Texture,5640image,47class
    * GTSR: Traffic sign 43 class
    * Flower102: 102 Class of Flowers (40-258 image per class)
    * ILSVRC12: 1k Class, 1.2M
    * Omniglot: 50 class, 1623 Handwritten character
    * SVHN: 10 class, 70,000 real world sign
    * UCF101: action-recog 101 class 113,320 videosï¼ˆå¯¹æœ¬æ–‡æ¥è¯´ï¼Œå¯¹è§†é¢‘åšäº†Dynamic Image Codingï¼Œå°†æ•´ä¸ªvideo encodeæˆäº†ä¸€å¼ å›¾ï¼‰
  * Metricæ˜¯decathlon discipline
    * (éœ€è¦åœ¨æ‰€æœ‰taskä¸Šæ•ˆæœå¥½)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200415133227.png)
* ğŸ’¡ Ideas:  
  * Different Domain Share Low/Mid level patterns     

---

```
* ğŸ”‘ Key:   
* ğŸ“ Source:  
* ğŸŒ± Motivation: 
* ğŸ’Š Methodology:
* ğŸ“ Exps:
* ğŸ’¡ Ideas: 
```


---

* [Towards Unified INT8 Training for Convolutional Neural Network](http://arxiv.org/abs/1912.12607)

* ğŸ”‘ Key:   
  * Mainly Dealing with the Gradient Quantization
  * Empirical 4 Rules of Gradient
  * Theoretical Convergence Bound & 2 Principles
  * 2 Technique: Directional-Sensitive Gradient Clipping + Deviation Counteractive LR Scaling
* ğŸ“ Source:  
  * CVPR 2020 SenseTime + BUAA
* ğŸŒ± Motivation: 
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200417205828.png)
* ğŸ’Š Methodology:
  * Symmetric Uniform Quantization with Stochastic Rounding
  * Challenged for Quantizing Gradients
    * Small perturbation would affect **direction**
    * *Sharp and Wide Distributionï¼ˆUnlike Weight/Activationï¼‰*
    * Evolutionary: *As time goes on, even more sharp*
    * *Layer Depth: Closely related to network depth(shallower the layer is, distribution sharper)*
    * *Special Block: DW Layer, always sharp*
  * Theoretical Bound afftected by 3 Terms(mainly with Quantization Error & LR & L2-Norm)
    * Useful Tricks: 1. Min Q Error   2. Scale Down the LR
  * Directional Sensitive Gradient Clipping
    * Actually its just plain grad clipping
    * Find the Clipping Value: Cosine Distance instead of MSE(Avoid the magnitude of grad's effect)
  * Deviation Counteractive LR Scaling
    * balance the exponentially accumulated grad error(deviation) by **exponentially decreasing LR accordingly**
    * ```f(deviation) = max(e^(-\alpha*deviation), \beta)```
      * \beta controls the lower bound of lr
      * \alpha controls the decay degree
  * Stochastic Rounding
    * curandGenerator
    * Linear Congruential Generator, yield a sequence of pseudo randomized number
* ğŸ“ Exps:
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200417212040.png)
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200417212102.png)
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200417212118.png)
* ğŸ’¡ Ideas: 
  * (Found with smaller LR, MobV2 training didn't crash,although perf. decay)
  * Deviation of grad *exponentially* accumulated since its propagated through layer




* [Improving Neural Network Quantization without Retraining using Outlier Channel Splitting](http://arxiv.org/abs/1901.09504)
* ğŸ”‘ Key:   
  * Outlier Channel Splitting
* ğŸ“ Source:  
  * Zhiru
* ğŸŒ± Motivation: 
  * Post-training quantization follows bell-shaped distribution while hardware could better handle linear
    * so the outlier becomes a problem
* ğŸ’Š Methodology:
  * Duplicate Outliers channels, then halves its value \
  * Similar to ã€ŠNet2Netã€‹ Net2WiderNet
* ğŸ“ Exps:
* ğŸ’¡ Ideas: 
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200417213824.png)
  * Post-Quantization's mainstreamï¼ŒFirst Clippingï¼Œthen Sym-Linear-Quan
    * Activation Clipping - Use Subset of input sample
    * Earlier work: min L2 Norm of Quantization Error
    * ACIQ: fits a Gaussian and Laplacian,use the fitting curve analytical compute optimal threshold
    * SAWB: Linear extrapolate 6 dists
    * TensorRt: Profile the dist, min the KL Divergence between original and quantized dist

* [DetNAS: Backbone Search for Object Detection](http://arxiv.org/abs/1903.10979)
* ğŸ”‘ Key:   
  * nas 4 Det backbone
  * Supernet
* ğŸ“ Source:  
  * Megvii
* ğŸŒ± Motivation: 
  * Det often needs imagenet pretraining & NAS requires accuracy as supervised signal
    * Imagenet-pretraining + Det finetune
  * Pre-training and finetuning are costly
    * Following One-shot, decouple the weight training and the architecture
  * Det task perf. as guide, to search for the Backbone Feature Extractor
* ğŸ’Š Methodology:
    * Steps: 
      1. SuperNet Pretrain on ImageNet and finetune on Det Task
      2. NAS on Supernet with EA
        * Path-wise(at one time, only updating samples path)
    * Finetuning BN
      * Freezing BN(Traditional) wont work for supernet(normalize couldnt acquired at different paths)
      * SyncBN replace regular BN
        * Compute BN Statistics across multiple GPUs (save memory consumption)
      * Also when EA searches arch, each BN param should be independent
        * need to re-accumulate the BN for every new arch
    * SS Design
      * Small/Big (40/20 Blocks)
        * Small used in Ablation Study
      * based on ShuffleNetV2 Block(involves channel split and shuffle operation)
        * 4 Choices:
        * x3: kernel-size [3,5,7]
        * x1: replacing right branch with Xception block(3 repeated DW 3x3 Conv)
        * 4^(40) choices for big ss
    * EA
      * Mutation + CrossOver
      * arch dont meet constraint will be removed when updating
* ğŸ“ Exps: 
* ğŸ’¡ Ideas:
  * Det's Direction
    * Architecture: FPN - Top-Down arch with lateral connection, integrating features at all scales
    * Loss: RetinaNet's Focal Loss, dealing with the class imbalance(Instability in earlier training?)
    * MetaAnchor: dynamic anchor mechanism
  * AmeobaNet - plain EA without Controller could also achieve
  * Det often uses the image classification backbone which could be sub-optimal(DetNet59 > ResNet101)
  * NAS-FPN only searches for the Feature Pyramid Network
  * EA could better handle Constraints than RL & Gradient-based 
  * [SyncBN](https://tramac.github.io/2019/04/08/SyncBN/)
    * Plain BN with DataParallel - Input distiributed to subsets and build different models on different GPU
    * (Since independent for each GPU, so batch size actually smallen)
    * Key2SyncBN: Get the global mean & var
      * Sync 1st then calc the mean & var
      * (Simplest implemention is first sync together calc mean, then send it back to calc var) - Sync twice
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200418111031.png)
        * modify computation flow and only sync once
    * [Code](https://github.com/tamakoji/pytorch-syncbn)
  * ------------------------------------------
  * Rather Small SS
  * Simple Shared-Weights with interesting handle of BN


* [NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection](http://arxiv.org/abs/1904.07392)
* ğŸ”‘ Key:   
  * Search a FPN(Feature Pyramid Network) in a ss covering all cross-scale connections
* ğŸ“ Source:
  * Quoc V Le Google  
* ğŸŒ± Motivation: 
  * Huge design space(increase exponentially)
* ğŸ’Š Methodology:
  * Following Cell-based SS(author called it as scalable architecture), main contribution is designing **search space**
    * the SS is **modular**  (Repeat the FPN N times then concat into a large net)
  * RNN RL Controller
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200418171859.png)
  * Feature Pyramid Network
    * (following RetinaNet, use last layer in each group of feature map as *the input of the FPN*)
    * 5 Scales(C_{3,4,5,6,7}) stride of 8/16/32/64/126 pixelï¼ˆ6,7 purely max-pooling of 5ï¼‰ for Merging Cell
    * Composed of multiple merging cells  
    * Input/Output same size - can be stacked (num to stack would control the acc/flops trade-off)
    * Each merging cell gives output are appended into the candidate layers, also feeds into next merging cell
      * Finally the 5 merging cells are output 
  * Merging Cell
    * basic element of FPN
    * Merging 2 input feature map of different size
    * Each Cell has its own resolution(the output)
    * 4 Step: 
      1. choose input-layer-1 
      2. choose input-layer-2 
      3. choose output feature resolution
      4. select binary op(add or maxpool) - (scales are handles b4 the binary op)
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200418173400.png)
  * Meshgrid Representation
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200418173458.png)
* ğŸ“ Exps:
  * Scalable: Stacking NAS-FPN blocks could improve acc while stacking simple block couldnt
* ğŸ’¡ Ideas:
  * FPN - fuse features across different scales (cross-scale connection in ConvNets)
    * Deeper layer feature semantically strong but less resolution, are upsampled and added with lower-representation for feature with both good semantic and resolution  
    * sequentially combining 2 adjacent layer feature (with top-down/lateral connection)
    * RW
      1. [Path aggregationnetwork for instance segmentation. In CVPR, 2018.]() - add an additional bottom-up pathway
      2. [M2det: A single-shot object detector based on multi-level feature pyramid network. AAAI, 2019.]() - Multiple U-shaped Modules
      3. [Deep feature pyramid reconfiguration for object detection. In ECCV, 2018]() - Combine features at all scale + Global attention
    * Problem: manually designed and shallow(compared to backbone)
  * Any-time detection: dont necessarily need to forward all pyramid networks
    * Desired when computation effort is concern
  * ----------------------------------------------------------------------------------
  * Google's Work, really strange Hyper-paramï¼ˆlr-0.08/8 epochs trainingï¼‰ (Maybe Grid-Search Again?)


* [EfficientDet: Scalable and Efficient Object Detection](http://arxiv.org/abs/1911.09070)
* ğŸ”‘ Key:   
	* Systematically NAS for Det Task
  * Combining EfficientNet Backbone + Bi-FPN + Compound Scaling
* ğŸ“ Source:  
	* Quo V Le Google Brain
* ğŸŒ± Motivation: 
	* Weighted Bi-directional FPN - for multi-scale feature fusion (Better Feature Aggregation)
	* Compound Scaling method - uniformly scale the resolution/depth/width (Scalable)
* ğŸ’Š Methodology:
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200418223126.png)
  * the "BiFPN", analogy of FPN & PANet
    * from traditional "Top-down" structure(1-way information flow)
    * Adding an extra edge when I/O is at the same level
    * remove node with only one input edge 
    * Adding Weighted Feature Fusion - like Attention
    * exponential scale up BiFPN width
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200418220047.png){:height="100" width="100"}
* ğŸ“ Exps:
* ğŸ’¡ Ideas:
  * One-Stage Det: (Anchor-Free) whether have a region proposal step

---

* [Learning to Remember: A Synaptic Plasticity Driven Framework for Continual Learning](http://arxiv.org/abs/1904.03137)
* CVPR2019
* Arch:
  * Conditional GAN with learnable neural masking
    * During SGD Add Mask on Layer/weight
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200420174733.png)

* [Lifelong Learning with Dynamically Expandable Networks](http://arxiv.org/abs/1708.01547)
* ICLR2018
* Arch:
  * Add Neurons by heuristic rule(Add and re-intialize new neurons)

* [An Adaptive Random Path Selection Approach for Incremental Learning](http://arxiv.org/abs/1906.01120)
* NIPS2019
  * Dynamic adaptive path selection
  * Attention-based on Peak Path Response
    * Paths Re-weighted with new task 
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200420185856.png)

* [Memory Aware Synapses: Learning what (not) to forget](http://arxiv.org/abs/1711.09601)
* ECCV 2018
  * Memory-Aware Synapses: Marking the parameter of a NN online and unsupervised

* [IL2M: Class Incremental Learning With Dual Memory](https://ieeexplore.ieee.org/document/9009019/)
* ECCV 2019
* Dual Memory 1. for examplers 2. initial class statistics(class predictions) - used for rectify the classification(deal with imbalance)

* [Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights](http://arxiv.org/abs/1801.06519)
* ECCV 2018
  * Learn Multi-task Masks  
  * Task-specific loss train the soft threshold
    * one mask per task
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200420192129.png)

* [Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting](http://arxiv.org/abs/1904.00310)
* ICML 2019
  * decouple the arch learning and param learning
  * Growing the network-NAS-like DARTs
    * Search for block (new/reuse/adaption)
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200420202125.png) 

* [Efficient Lifelong Learning with A-GEM](http://arxiv.org/abs/1812.00420)
* ICLR2019
  * Evaluating Efficecny of lifelong learning methods (metric for measuring how quickly learning)
  * Improve the original GEM(Gradient Episodic Memory)
    * Distribute an episode memory
  * mainly discussed why other methods fail to fitting the "Lifelong Learning" because not dealing with a single pass of the stream of data


* [Learning without Memorizing](http://arxiv.org/abs/1811.08051)
* CVPR2019 2019
  * no stroing data sample for old task
  * change in classifier attention map for old tasks
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200420204205.png)

* [Lifelong Learning with Searchable Extension Units](http://arxiv.org/abs/2003.08559)

* ğŸ”‘ Key:  
  * * Lifelong Learning predefine arch, this method search for extension model
* ğŸ“ Source:
  * arxiv 2003 & ZJU 
* ğŸŒ± Motivation: 
  * Summarize the lifelong learning
    1. Fix methods: retaining data information of previous task
      * Often encounter capacity bottleneck
    2. Expansion Methods: 
      * Newly added params are added, though the old are frozen or regularized
      * Then re-train whole/subnet for new task
      * May Increase rapidly(redundant)
      * Also added elements are constrained to be the same with the previous
* ğŸ’Š Methodology:
  * Contains: 1. Unit Searcher   2. Task model creator
    * Super Model(Contain Multihead model)
    * Task Model(Part of the super model,all has the same layer)
    * Each task has task-specific output layer, other layer are shared (composed of many EUs)
  * Proceudre ï¼ˆseems pretty plain for NAS...ï¼‰
    1. Search EU - in current task
    2. Expand the SuperModel: adding EU in each intermediate layer
    3. Create Task Model: Select the best EUs(part)
    4. Train the task model, train the net
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200420213758.png)
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200420215011.png)
* ğŸ“ Exps:
* ğŸ’¡ Ideas: 
  * new metric named mixed score: measuring both param size and accuracy of the life learning problem
---

* [ResNeSt: Split-Attention Networks](https://hangzhang.org/files/resnest.pdf)

* ğŸ”‘ Key:   
  * New backbone for det & semantic-seg
  * Split Attention across feature map groups (within a block)
    * A new ResNet Cell 
* ğŸ“ Source:  
* ğŸŒ± Motivation: 
  * A new resnet cell, plug and play with ResNet
    * help the downstream tasks(like Det or Seg)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200428085217.png)
  * ResNet are meant for Image Classification - focus on depthwise & group-wise conv, howerer for downstream task, cross channel information are ctitical
    * Small reception field, no cross-channel interaction
  * create a versatile backbone with universally improved feature representation
* ğŸ’Š Methodology:
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200428090121.png)
  * Feature maps into groups(num of group is cardinality)
    * Radix as the split within a group
  * Split Attention
    * element-wise sum across multiple splits
    * Hï¼ŒW average pooling for gathering global contextual information
    * Channel-wise weighted soft fusion
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200428091033.png)
    * finally for groups, concat them
    * split block output with a shortcut
      * if stided, add another transformation with the output
  * Related with other attention methods
    * SE(Squueze and activation) use global context to predict channel-wise attention factor
      * when r=1ï¼ˆradixï¼‰ResNest is SENet, only difference is 
      * SE employed on the whole block regardless of groups, ResNest applied on each group
    * SKNet feature fusion between network branches
      * (author says that is could be low efficient and hard to caling to larger groups)
* ğŸ“ Exps:
  * 3x3 Max pooling instead of strided conv
  * All the training tricks(a little-bit concerned, we could employ these though)
* ğŸ’¡ Ideas: 
  * SENet
    * Channel-wise aggregation for the global context, then learn a set of weights
      * The excitation is actually an fc
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200428092523.png)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200428092638.png)
  * SKNet
    * Split - Fuse - Select
      * two group conv branches with different kernel size
      * Fuse is a squeeze and excitation block
      * 2 softmax to get the channel weights, multiplying them, then added   
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200428093221.png)
    * Sacrifice a little flops for better perf.
      * Combine Attention with larger kernel

---

### 2020-03-17 MCMC

* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200317151113.jpg)
* æ’’è±†å­ç®—é¢ç§¯çš„å®éªŒ


### 2020-03-20 DeConv
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200320185002.png)

### 2020-03-24 Gumble Softmax
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200324113027.png)
* ä»VAE(è¿ç»­åˆ†å¸ƒé‡‡æ ·çš„æ±‚å¯¼)ï¼ŒåŠ å…¥ä¸€ä¸ªGumbleå™ªå£°(åŒ…å«äº†å‚æ•°çš„ä¿¡æ¯)ï¼Œé¦–å…ˆä»Gaussianä¸­é‡‡æ ·ï¼Œå¸¦å…¥å€¼
* å¯¹äºç¦»æ•£åˆ†å¸ƒï¼ŒåŠ ä¸€ä¸ªArgmax->Softmax 


### 2020-03-26 Self-Supervised Learning

* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200325231129.jpg)
* [MoCo](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1911.05722.pdf) by Kaiming
  * å°†Contrastive Learningçš„é—®é¢˜æŠ½è±¡ä¸ºäº†ä¸€ä¸ªDictionary Learningçš„é—®é¢˜
    * ç»´æŒä¸€ä¸ªDictå…¶ä¸­æœ‰ä¸€äº›Encodingï¼Œå½“è¿›å…¥ä¸€ä¸ªæ–°çš„Sampleçš„æ—¶å€™ï¼Œç»è¿‡è¿™ä¸ªEncoderï¼Œæˆ‘éœ€è¦å®ƒèƒ½ä»è¿™ä¸ªDictä¸­Queryå‡ºä¸€ä¸ªä¸å…¶æœ€ç±»ä¼¼çš„Keyï¼Œè¿™æ ·å°±æœ‰ä¸¤ä¸ªé—®é¢˜ï¼š 1. dictè¦è¶³å¤Ÿå¤§ 2. Dictè¦å…·æœ‰ä¸€è‡´æ€§
    * Similarityæ˜¯ç”¨InfoNCE(a kind of contrastive Loss Function)
    * Dictä¸­çš„Keysæ˜¯On-the-flyè¢«å®šä¹‰å‡ºæ¥çš„(Momentum Encoder ç»™å‡ºçš„ç»“æœ)
  * å¦‚ä½•åˆ¤å®šæ˜¯ä¸æ˜¯åŒç±»åˆ«ï¼ŸInstanceDiscrimination:
    * è¯¥Sampleä¸å…¶ä»–çš„æ‰€æœ‰å›¾ç‰‡éƒ½æ˜¯å¼‚ç±»ï¼Œå¯¹å…¶æœ¬èº«Augå‡ºçš„ç»“æœè®¤ä¸ºæ˜¯åŒç±»
  * Inferenceçš„æ—¶å€™åé¢ç›´æ¥è·Ÿä¸€ä¸ª1å±‚çš„fcï¼ŒåŠ ä¸€ä¸ªsoftmax
* CPC - CPCé€šè¿‡å¯¹å¤šä¸ªæ—¶é—´ç‚¹å…±äº«çš„ä¿¡æ¯è¿›è¡Œç¼–ç æ¥å­¦ä¹ ç‰¹å¾è¡¨è¾¾ï¼ŒåŒæ—¶ä¸¢å¼ƒå±€éƒ¨ä¿¡æ¯ã€‚è¿™äº›ç‰¹å¾è¢«ç§°ä¸ºâ€œæ…¢ç‰¹å¾â€

---

### 2020-03-27 

* ç”Ÿæˆæ¨¡å‹çš„å‡ ç§æµæ´¾
  1. AutoRegressive 
  2. VAE
  3. GAN
  4. FLOWï¼ˆNICEï¼‰
* éƒ½æ˜¯é€šè¿‡éšæœºå™ªå£°æ¥ç”Ÿæˆæ•°æ®ï¼Œåœ¨å»ºæ¨¡åˆ†å¸ƒçš„æ—¶å€™ï¼Œéƒ½æ˜¯é€šè¿‡åº¦é‡å™ªå£°ä¸è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒå·®å¼‚
* ä¸åŒç‚¹
  * VAEçš„zåˆ°xçš„Dependencyæ˜¯ä¸€ä¸ªéšæœºçš„è¿‡ç¨‹ï¼Œè€ŒGANæ˜¯ä¸€ä¸ªç¡®å®šçš„ï¼Œå› è€ŒVAEçš„Inferenceæ˜¯Well-Definedï¼Œè€ŒGANçš„å°±ç›¸å¯¹ç—…æ€äº†
  * GANæ˜¯ä¸ºäº†ç”Ÿæˆæ–°å›¾ç‰‡ï¼ŒVAEé™¤äº†è¿™ä¸ªä¹‹å¤–è¿˜éœ€è¦å»ºæ¨¡æ•°æ®çš„åˆ†å¸ƒä»¥åŠHiddenState
  * æµæ¨¡å‹ç›´æ¥ä»åŸå§‹é—®é¢˜å‡ºå‘ï¼Œç›´æ¥å»ºæ¨¡è®­ç»ƒæ•°æ®å’Œç”Ÿæˆæ•°æ®çš„æ¦‚ç‡å…³ç³»ï¼Œç”¨å¯é€†æ¨çš„NNæ¥è®­ç»ƒï¼Œzä¸xçš„å…³ç³»æ˜¯ä¸€ä¸€å¯¹åº”çš„
  * æœ€ç›´è§‚çš„ååº”æ˜¯Lossä¸åŒ
    * VAEæ˜¯ELBO(æœ€å¤§ä¼¼ç„¶ä¼°è®¡-ç­‰ä»·äºæœ€å°åŒ–KLæ•£åº¦-æ³¨æ„KLä¸‰åº¦ä¸æ˜¯åœ¨æ•°æ®å’Œå™ªå£°ä¹‹é—´çš„ï¼Œè€Œæ˜¯æ¨¡å‹çš„p(x)ä¸æ•°æ®çš„p(x)ä¹‹é—´çš„)
      * ELBOæ˜¯Likelyhoodçš„Lower Bound
    * GANæ˜¯æœ€å°åŒ–Jenson-Shannon Divergenceï¼Œè¿™ä¸ªä¹Ÿæ˜¯Modelç»™å‡ºçš„P(x)å’Œæ•°æ®ç»™å‡ºçš„P(x)ä¹‹é—´çš„(**è¯´äººè¯å°±æ˜¯ä¸¤ä¸ªEmbeddingä¹‹é—´çš„**)
    * FLOWç”¨çš„ä¹Ÿæ˜¯æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œç”±äºç”¨çš„æ˜¯å¯é€†çš„NN

---

### 2020-04-05

* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200405093121.jpg)

---

### 2020-06-17

* [Multi-Precision Quantized Neural Networks via Encoding Decomposition of -1 and +1](https://arxiv.org/abs/1905.13389)
* ğŸ”‘ Key:   
  * Decomposite Multi-Precision NN into multi BinaryNN, more efficient Deployment
* ğŸ“ Source:  
* ğŸŒ± Motivation: 
* ğŸ’Š Methodology:
* ğŸ“ Exps:
* ğŸ’¡ Ideas:


# [Searching for Accurate Binary Neural Architectures]()
* Huawei Noah
* only search for width(channels), acquire higher acc with less flops
* the arch remain the same with the original fp32 model


# [Learning Architectures for Binary Networks]()
* GIST(South Korea)
* seems like eccv ...
* cell-based, proposed a new cell template composed of binary operations
* novel-searching objective - Diversity Regularization  
* è¿™äº›new ssåŸºæœ¬éƒ½æ˜¯ä¸€ä¸ªå¥—è·¯ï¼Œå¯¹dw separableï¼Œdilated conv binaryåŒ–
  * è¿™ç¯‡æ–‡ç« é‡Œå¤šäº†ä¸€ä¸ªzerorise layer(æ²¡ææ‡‚)ï¼Œè¯´æ˜¯ä½œä¸ºplaceholder

# [Binarized Neural Architecture Search]()
* Beihang Univ
* Darts foundation
* channel sampling / operation space reduction
  * abbadon less potential operation

# [BATS: Binary ArchitecTure Search]()
* Cambridge
* binarized ss
* search strategy

