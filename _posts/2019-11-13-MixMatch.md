---
layout:     post                    # 使用的布局（不需要改）
title:      论文阅读《MixMatch-A Holistic Approach to Semi-Supervised Learning》          # 标题 
subtitle:   Semi的另外一篇操作...   #副标题
date:       2019-11-12            # 时间
author:     tianchen                      # 作者
header-img:  img/10_1/bg-nmb5.jpg  #这篇文章标题背景图片  
catalog: true                       # 是否归档
tags:                               #标签
     - 论文阅读
---

# 《MixMatch-A Holistic Approach to Semi-Supervised Learning》  
* 1905
* Google Research
* Ian Goodfellow

---

* 主要Contribution在label Data和unlabel data之间的mix
* Intro部分提到了Semi处理的是获取Label昂贵的情况
  * 比如说在医疗图片处理
  * 又比如说Label代表了privacy(感觉有一点牵强))
* 将之前在loss上加一个term的方法概括为了
  * Entropy Minimization - 鼓励模型去对unlabel data给出Entropy小的confs(熵小就对应着确定)
    * the classifier’s decision boundary should not pass through high-density regions of the marginal data distribution.A common underlying assumption in many semi-supervised learning methods is that the classifier’s decision boundary should not pass through high-density regions of marginal data distribution
    * **Pseudo Label**进行了显式的Entropy Minimize,把高conf强制转化为one-hot的label
      * *也就是说这里面对的是Hard Label*
  * Consistency Regularization - 鼓励模型在扰动下获得一样好的性能
  * Generic Regularization - 保证模型泛化而不是overfit
    * 就是传统的regularization
    * 是为了防止出现Overfit,更难去Remember起之前的sample
  * (本文号称以上三种都能unify到一个loss内部)
* 除了这些方式之外,还有一些Semi的常用方式
  * 基于图的
  * 基于Transductive的
  * 基于generative modelling的
* 喷了一下mean-taecher的方法使用了*Domain-Variant的数据增强方式*
  
---

## MixMatch
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191113133718.png)
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191113134119.png)
* 需要做K次aug
  * 对K个aug的辨识结果先**平均**再做一个**Temperature Sharpen**
* 实际上是在label更少更极端的情况下
