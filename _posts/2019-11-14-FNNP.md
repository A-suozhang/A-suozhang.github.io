---
layout:     post                    # 使用的布局（不需要改）
title:      论文阅读《FNNP - FAST NEURAL NETWORK PRUNING USING ADAPTIVE BATCH NORMALIZATION》          # 标题 
subtitle:   还在盲审中的文章居然被挂上了榜单...   #副标题
date:       2019-11-12            # 时间
author:     tianchen                      # 作者
header-img:  img/10_1/bg-nmb5.jpg  #这篇文章标题背景图片  
catalog: true                       # 是否归档
tags:                               #标签
     - 论文阅读
---

# [FNNP - FAST NEURAL NETWORK PRUNING USING ADAPTIVE BATCH NORMALIZATION](https://github.com/anonymous47823493/FNNP)
* ICLR2020 - Under Blind Review
* 作者还提到了
  * 自己的方式是可以和比如Lasso这种Prunning方式并行的,是orthogonal的
  * 此外还提到了目前的一些用NAS的Prunning方式只采用了模型的结构而没有考虑训练出的weight(它考虑到了)
* 是目前prune这个领域的SOTA
  * ~~就是prune这个领域刚刚被别人锤了,而且讲道理对实际部署起来不是很容易~~
* 主要解决的是对修剪之后的Subnet,提出了一种**更加好的Evaluation方法**
  * 基于AdaBN
  * 一般的Prune先剪出一个SubNet,然后选择比较有价值的去finetune得到最后模型
    * 如果直接拿剪掉之后的Subnet的accuracy不合理
    * 如果每个subnet都需要finetune来看效果的话,太花时间
  * 原本的方法是用global的BN stastic来作为subnet的,但是这样显然不合理
    * 所以这里就改了,用AdaBN之后的结果来衡量Prune
    * (传统的方式叫Vanilla Evaluation,本文和它对比了)
* 还用了一个Correlation index来尝试说明其理论有效性
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191113185004.png)
  * 锤了所有


