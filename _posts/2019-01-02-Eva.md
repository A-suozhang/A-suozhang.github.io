---
layout:     post                    # 使用的布局（不需要改）
title:      Eva0开发笔记          # 标题 
subtitle:   （待填一个eva梗）   #副标题
date:       2020-01-04          # 时间
author:     tianchen                      # 作者
header-img:  img/10_1/bg-eva.jpg  #这篇文章标题背景图片  
catalog: true                       # 是否归档
tags:                               #标签
     - private
---

# EVA 开发日记

# 网管相关

### LDAP related

1. 登录LDAP系统
   * 通过22222port登录上205，然后将remote的80端口映射到本地12888端口
     * （由于默认打开方式会显示实验室网页，需要用modeHelper插件输入一个rule；Host； ldap.nics.cc; 开启之后就可以进入）
     * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20210404142533.png)
2. 手动添加用户
   * 在用户列表中用搜索“Search”
   * 配置显示uidNumber
     * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20210404142716.png)
   * 找到最后一个用户(uid最大的)，注意个数调大一点
     * 然后copy from existing profile

![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20210404143227.png)

3. 或者是让它们自己注册用户
   * 在实验室官网进Internal进行注册，完成之后应该就有实验室账号了
   * 验证问题: 汪武天弈

## 服务器调试常用操作

1. 查看磁盘IO
   * 现象: vim保存文件卡顿，但是tmux切换窗口不卡顿
   * 使用`iotop`命令，可能需要手动安装一下，在container内部是会报OSError，需要主机上的sudo权限
2. 查看服务器占用内存/CPU最多的程序
   * `ps auxw|head -1;ps auxw|sort -rn -k4|head -10 ` 内存（改成k3就是CPU，改成k5就是虚拟内存）
3. 查看某个用户的进程`top -u zhaotianchen`
4. 发现谁在用卡去查一下ldap看一下个人信息

## LXC知识相关

* LXC能通过改变/var/lib/中的cfg以及其他内容动态管理各个container
* 常用命令
  * `lxc-ls -f` 查看各个container的信息
  * `lxc-start -n XXX` 启动container
  * `lxc-attach -n xxx` 从主机进入某个container
  * `lxc-top`
  * `lxc-monitor`

### Container维护相关

[ LXC Linux系统容器 - 某科学的最后之作 (yunfwe.cn)](https://yunfwe.cn/2019/09/23/2019/LXC Linux系统容器/)

1. 如何开一个新的Container
   * 登录主机，进入root
   * /home/work/lxc 中有一个fork_lxc_new.py文件，有以下的输入args需要填写
     * -n： container的名字
     * -u： user，需要和/etc/login.user.allow对应，可以用逗号隔开
     * --rootfs-size: 一个int表示GB
     * --rootfs-prefix: 表示挂载在哪块硬盘上，输入比如`/mnt/sdd` (事先df -kh查下哪个盘有空间)
     * --bionic： 表示是否是18.04
   * 发个邮件告诉别人
   * 按照当前命令执行就可以从一些对应位置读取一些默认cfg并且执行将空白文件系统复制到对应的位置
     * /home/work/lxc/templates_lxc
       * config: lxc的cfg
       * login.user.allow（默认有网管的）
     * /var/lib/lxc/ubuntu-cuda-base/rootfs.new(默认的空白文件系统)

* 目前已经能够登录各个主机 eva*.nics.cc
  * 在本地config里是用ssh eva8 这种命令来直接登录
* srvAdmin组:
  * 代表了对主机和container的sudo权限
  * 虽然有container的sudo权限，但是还是需要container的进入权限；可以直接进入主机attach进去然后给`/etc/login.user.allow`
* [凯哥的网管部技术整理](https://www.yuque.com/doctor-kaizhong/lab-network)

2. 改Rootfs的大小

* 先stop到当前的container
* 参考fork_lxc_new中脚本中的几行代码
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20210730103216.png)
* 其中的rootfs path从`/var/lib/lxc/$NAME`中找rootfs所link到的位置，是`/data2/lxc/ztc`对应位置的确实是大文件
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20210730103356.png)
* 放了一个脚本在`/home/woirk/lxc/resizefs.sh`

3. 服务器自动入网:

* 入网的脚本auth-linux我放在205的`/home/eva_share`下了，之后可以从这里scp

* 在我的服务器的home目录下写了一个config，然后只要直接执行./auth就可以了，需要写一个crontab
  * [19. crontab 定时任务 — Linux Tools Quick Tutorial (linuxtools-rst.readthedocs.io)](https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/crontab.html)
  * still not safe enough, since should save passwd

* 写一个crontab脚本 `ping info.tsinghua.edu.cn` 让它一直在内网中, and use the ztc.eva7.nics.cc to login

* 创建一个脚本之后，`crontab $FILENAME`,之后`contab -l`查看什么正在执行
  * `crontab -e `直接编辑
  * `crontab -r` 删除

4. eva7上的特殊路由方式

* 在主机上用`iptables -t nat -L` 看了这两条rule，其中将32223端口绑定(目前还是把这种方式改掉了…重启之后就没了，留档)

* ![image-20210510173319946](C:\Users\A-suozhang\AppData\Roaming\Typora\typora-user-images\image-20210510173319946.png)

### 常见问题

1. deviceQuery在sudo下仍然失效：(Error 35)
   * 执行一下`ldconfig`
2. Container里报错没有`nvidia-smi`命令
   * 将`/usr/local/nvidia/bin`加入环境变量
3. deviceQuery失败，或很慢
   * sudo运行`/usr/local/nvidia/bin/nvidia-persistenced`
4. 重启container之后container中deviceQuery报错，报错Error 30；
   * 可能是需要在主机上执行deviceQuery命令，主机的cuda安装在`/home/opt/cuda-xx`
5. （一般不会出现）从主机attach到container中再su到用户，发现不能sudo su了，用`script /dev/null`

## SSH配置

* 现在的新的Config文件的内容

```
Host eva
	HostName 101.6.64.169
	Port 22
	User zhaotianchen
	ProxyCommand ssh zhaotianchen@101.6.64.67 -p 42222 -W %h:%p
Host fpga
	HostName 101.6.68.236
	Port 22
	User ztc
	ProxyCommand ssh zhaotianchen@101.6.64.67 -p 42222 -W %h:%p

Host 205
  ForwardAgent yes
  HostName 101.6.64.67
  User zhaotianchen
  Port 42222

Host eva*
  HostName %h.nics.cc
  User zhaotianchen
  ProxyCommand ssh zhaotianchen@205 nc %h %p

Host proxy-eva10
  HostName eva10.nics.cc
  Port 32222
  User zhaotianchen
  ProxyCommand ssh zhaotianchen@205 nc %h %p

Host ztc.eva10
  HostName foxfi-eva10
  User zhaotianchen
  ProxyCommand ssh -p 32222 zhaotianchen@eva10 nc %h %p

Host *.eva*
  HostName %h.nics.cc
  User zhaotianchen
  ForwardAgent yes
  ProxyCommand ssh zhaotianchen@205 nc %h %p

```

* 一些解释性的文字
  * nc表示不要再Proxy停下来
  * %h 表示了HostName
  * %p 表示了Port
* 经过这样的一套配置应该是可以用```ssh ztc.eva10```这样的命令直接跳过两次跳板机跳上去了
  * 对于一些额外的配置比如说端口映射，可以直接加载最后的这个指令中比如 ```ssh -L 10808:localhost:127.0.0.1 ztc.eva10``` 
* 关于上传私钥以免密码登录
  * 首先再本地进行ssh-keygen，会有一个id_rsa（私钥），还会有一个id_rsa.pub公钥（这个比第一个短一些）
  * 其实只是需要在服务器上将本地的id_rsa.pub的内容添加到./ssh/authorized_keys当中即可 
    * 用```echo XXX >> authorized_keys``` 这种形式
* If after loading keys, logging still requires passwd for eva-8/9
  * Try ```ssh-copy-key -i id_rsa.pub proxy-evaX```
* 可以通过添加 - 将服务器端口映射到本地 
  * ``LocalForward 127.0.0.1:$PORT_ON_SERVER 127.0.0.1:$LOCAL_PORT```
  * 等效于```ssh -L 16379:127.0.0.1:6379 user@host```
  * 反向的话可以用RemoteHost
* ssh的config相关的配置用```man ssh_config```可以查询
  * -L 表示LocalForward - 将本地端口映射到远端
  * -R 表示RemoteForward - 将远程端口映射到本地
* Github配置proxy加速clone
  1. 本地的v2ray在10809的端口上开启了http服务
  2. 通过端口映射在登录服务器的时候指定 ssh -R 12450:localhost:10809 建立remote的映射
     * 端口映射-L会出问题，不明原因
  3. 在git的config中这样写  ```[http] proxy=http://127.0.0.1:12450```
     * 在ssh_config当中可以 ```RemoteForward 127.0.0.1:12450(port on remote) 127.0.0.1:10809```
* 清华校园网准入服务器：
  * 从userreg还是太麻烦了
  * 使用更新之后的[auth-thu](https://github.com/z4yx/GoAuthing)，直接从release中下载可执行文件，然后直接调用 ```./auth-linux_x86_64 auth```输入用户名密码就可以了
* 注意SSH config中的`LocalForward`前面的是本地的IP，可以不用加localhost



## 联网相关(登录服务器)

> 联网真的是一件很费劲的事情

* 可能会出现登录不上服务器的情况
  * 大概率是因为没有准入

### 准入Tips

1. 对于不在罗姆楼网段的服务器(eva8/9/10)，我们一般在主机(eva8.nics.cc)上的32222端口会route到这台eva所对应的跳板机(proxy.eva8.nics.cc),该跳板机会同时在罗姆楼与其他服务器所在网段(如伟清楼)，在跳板机上可以登录到各个container

   * eva8主机(IP: eva8.nics.cc); eva8-proxy(IP: proxy.eva8.nics.cc); eva8的container(IP: foxfi.eva8.nics.cc) 三者IP都不一样，三者如果将其IP直接通过usereg准入，就可以直接登录

   * 登录不在同一网段的机器需要在cfg里额外有一个   

     ```
     Host proxy-eva8:
     	HostName: eva8.nics.cc
     	Port: 32222
     	User: 
     	Proxy: xxx
     	
     Host proxy-eva8:
     	HostName: proxy.eva8.nics.cc
     	User: 
     	Proxy: xxx
     ```

     * 这个cfg定义了eva8中的跳板机，其本质上也是一个container，开在主机的32222端口(主机通过修改路由NAT表自动将包都转发到了proxy container所在的IP) - 所以将主机准入或者是将proxy所在的container准入，都可以将其连入清华内网；proxy container将各个eva container与eva主机通过内网连接(不用每个container都准入，都可以通过这样跳转)
     * 当重启之后，只要将主机入网，就可以让所有的container通过方式A登录了。

2. 连外网

   * 一种是usereg直接输入ip
   * 一种是准入```~/auth-thu.linux.x86_64 auth```

3. 多服务器之间拷贝文件

   * 注意一下可能在cfg中有关于域名的alias
### SCP

* `zhaotianchen@foxfi-eva8:~$ scp ztc.eva7.nics.cc:/home/zhaotianchen/awnas/data/modelnet40_normal_resampled.zip ./`
* 某次出现了无论怎么准入都无法ping通的情况，发现是eva7的某个container的IP table出了问题，删除掉某条rule之后好了
  * 使用`route`命令，找到一个default的路由，gw是10开头的，手动删除
  * `sudo route del default gw 10.0.3.1`
* ![image-20210410105419818](C:\Users\A-suozhang\AppData\Roaming\Typora\typora-user-images\image-20210410105419818.png)

1. 各个服务器中间可能存数据集的地方

   * 只有eva7是`/data/eva_share_users`，其他的基本都是`/home/eva_share_users`


### 开机自启动

* [Linux开机自动化执行脚本的四种方法（真实案例分享）_清风阁-CSDN博客_linux开机自动运行脚本](https://blog.csdn.net/abc_12366/article/details/87552848)

## CUDA Stuff

* 如果smi不出来东西了去/opt/cuda-x.x中执行deviceQuery(可能需要sudo)

* 通过在bash中用 LD_LIBRARY_PATH来指定用什么cuda

  * 如果为空的话就会查询 PATH, 里面一般有 ```/usr/lib/cuda```, 查询之后应该在eva服务器中是一个软连接连接到了/opt/cuda里

  * $PATH变量本身通过"："分隔,后面的覆盖，常用的方式 ```PATH=PATH:some_new_path```

    



## Install  a few stuff

* 听从[初代目网管的意见](https://nicsefc.ee.tsinghua.edu.cn/wiki/dl:install)，安装MiniConda3
  * 文章中，conda公司和Intel有py，从它这里下的包CPU计算会更快说服了我（~~虽然不知道到底有多真实~~）
  * 而且conda也和pip兼容，何乐而不为呢
  * 之前不装conda是因为它起手就安了一万个包，原来是我没有发现miniconda

```
wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-latest-Linux-x86_64.sh
chmod +x Miniconda3-latest-Linux-x86_64.sh
./Miniconda3-latest-Linux-x86_64.sh

// 打开一个新的Shell(重新登录一次)

conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --set show_channel_urls yes
```

* 安装了shadowsocks与Proxychains来加快git clone速度

* 安装opencv
  * ```conda install python-opencv失败```
    * ```pip3 install python-opencv```安装不上
    * 安装了conda之后，对应的python是pip对应的，而pip3对应的是老的python3
  * 中间报了  ```安装opencv时报错 ImportError: libXrender.so.1: cannot open shared object file: No such file or directory```
    * 直接 ```sudo apt-get install libxrender1```

* 安装tmux并配置
  * 按照网管给的tmux.conf启动
  * *修改一下tmux的快捷键prefix(CTRL+B实在是太远了,改成+x吧)*
    * 查看现在的Prefix Binidng```tmux show-options -g | grep prefix```
    * 在~/.tmux.conf中加上
      ```
       set -g prefix C-x
       unbind C-b
       bind C-x send-prefix
      ```
    * 使其生效:
      * 在tmux中 CTRL+B+(此时还没有改好)): 输入source-flie ~/.tmux.conf
      * 这之后的都ok了


* 对vim的安装和配置见[Ubuntu系统配置！](http://a-suozhang.xyz/2020/01/08/UbuntuSetup/)

* Pytorch的安装


  * 有的时候会无法自动匹配到所需要的cuda版本，或者是自动安装了更新版本的pytorch而导致无法cuda()
  * ck CUDA 版本`echo $PATH; echo $LD_LIBRARY_PATH`
  * 强制force安装某个版本 `pip install torch==1.7.0`

    * 但是即使这样有时候tuna mirror找不到当前版本，这个时候就要`pip install torch==1.7.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html`这样那直接从pytorch官方的stable源来下载

* eva0上nvcc貌似没有结果(不知道是不是和有好几个container相关)
  * 按照bing到的结果去看 /usr/local/cuda下的version.txt貌似也不是很行
  * 咨询了网管之后的结果
    * 在/opt/cuda-10.0目录底下有着cuda
    * *测试cuda是否能用*
      
      * 运行/opt/cuda-10.0/samples/1_Utilities/deviceQuery/下的deviceQuery可执行文件
      * **开机之后要首先运行一次这个脚本，否则cuda就用不了！**
      * 正确的现象
        
        * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191021215750.png)
      * 同时给出nvidia-smi结果
        
        * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191021200015.png)
      * 在pytorch官网选择安装: Conda-Python3.7-cuda10.1
        
        * *大概800M的下载之后就安装好了*
      * 测试cuda ok没有
      
        ``` python
        import torch
        torch.cuda.is_available()
        ```


* 🐛 Matplotlib.pyplot import的时候报错了 
    ```
    This application failed to start because it could not find or load the Qt platform plugin "xcb"in "".
    Available platform plugins are: eglfs, minimal, minimalegl, offscreen, vnc, xcb.
    Reinstalling the application may fix this problem.
    ```
    * 原因是缺少了Qt的支持
      * [在这里找到了解决方案 ]](https://github.com/OpenShot/openshot-qt/issues/1809)
      
      * ```sudo apt-get install libqt5gui5```
      
        
    
    ## 



## SSH 配置相关-deprecated

> deprecated

* 那么如何登录eva呢？
  * 配置了Linux环境下通过跳板机直接访问目标机器
    * 一次ssh而不是两次
    * 主要参考了[这篇文章](https://blog.csdn.net/DiamondXiao/article/details/52474104)
    * 在.bashrc里面加上
    ``` bash
      alias eva="ssh zhaotianchen@101.6.64.144 -p 22 -o ProxyCommand='ssh -p 42222 zhaotianchen@101.6.64.67 -W %h:%p'"
      alias fpga="ssh ztc@fpga1.nics.cc -p 22 -o ProxyCommand='ssh -p 42222 zhaotianchen@101.6.64.67 -W %h:%p'"
    ```
  * 按照上面的配置之后还需要再进行一次秘钥copy
    * ```ssh-copy-id  -i id_rsa.pub zhaotianchen@101.6.64.144 -p 22 -o ProxyCommand='ssh -p 42222 zhaotianchen@101.6.64.67 -W %h:%p'```
    * 说明从跳板机登录（2次）需要的秘钥和一次的需要是不一样的
    * fpga1.nics.cc -> 101.6.68.236(由于用ssh config文件这种方式登录的话不能用域名)

* 服务器的跳板机一定要从一定端口登录，不然就登录Permission denied
	
* 比如说eva10.nics.cc必须要从32222 port访问
	
* 关于免密码登录
	* 本机的.ssh文件夹里有一对密钥，id_rsa.pub和id_rsa
	* 其中执行```ssh-copy-id -i id_rsa.pub $SERVER_NAME```实际完成的操作就是把id_rsa.pub里面的东西复制到服务器上的.ssh/authorized_keys里面
		* 由于win并没有ssh-copy-id 命令，可以直接登录服务器手动配置，或者是用scp把authorized_keys给传上去(在win下vim不好使的情况下)
		* 注意scp按照port来传输的命令是```scp -P xxx```
	* 完成复制之后，从**有私钥的服务器**登录到新的服务器，可以直接免密码登录（但是注意没有私钥的地方还是不行，所以从中间节点直接连最后是不行的）
	* 其他的比如known_hosts什么的其实不用改也可以

* ~~Tensorboard远程映射~~（Deprecated） Use ```ssh -L 10808:localhost:127.0.0.1 ztc.eva10``` 
  * [通过跳板机查看内网服务器的tensorbord](https://blog.csdn.net/Woody0729/article/details/80933014)
  * 配置新的登录Eva的方式(以支持端口传播,从而看到Tensorboard)
    * 需要登录两次,首先登录跳板机 with
      * ```ssh -L 16006:127.0.0.1:8008 account@跳板机ip```
    * 然后在跳板机上登录with 
      * ```ssh -L 8008:127.0.0.1:6006 account@服务器ip```
    * 最后直接在本地机器上的localhost:16006观察结果
    * *注意这边可能刷新和Load会有一定的延迟,稍微等一会Tensorboard的内容会逐渐load出来*

* 如果X11 Forwarding出了问题,打不开matplotlib,可以先

```
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
```


---

* [blog-1](https://deepzz.com/post/how-to-setup-ssh-config.html)
* [blog-2](https://mdgsf.github.io/2019/08/01/linux-ssh-study/)


---

# Ray Setup
1. 安装ray
2. 按照scripts/python ray备注中的格式设置ray(每个机器或者conda env只需要设置一次)
	* 需要记录下一个redis-dir
	* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200104165140.png)
3. 新建一个experiment文件夹,内部说明方法的名字
4. 写一个脚本生成新的yaml文件,放置在一个文件夹下
5. 调用脚本 python train_ray.py --redisdir=XXX $PATH_TO_YAML_DIR
	* 则会自动load下dir目录下的每个yaml文件
	* 每当一个实验完成之后会自动建立一个进程将新的实验添加进去
	* 有两个必须的arg
		* redis-addr 启动ray时候会给的地址
		* result-base-dir 存放log的地址
			* 会自动append上这次调整的参数的名字(也就是experiment的yaml setting所在的dir前面一层)
		* 再后面就是正常main函数的yaml所在的文件夹,会读取该文件夹中的所有yaml并且跑

* 记不住redis-addr怎么办,因为每一次start ray的时候会随机产生一个,所以我们可以指定一个,在ray的命令里
	* ```alias ray-start="CUDA_VISIBLE_DEVICES=0,1,2,3 ray start --head --num-cpus 10 --num-gpus 4 --object-store-memory 10000000 --redis-port=12450```

---

# Conda Virtual Env

* ```conda create -n $NAME python=3.7```
	* 最好直接在最后用python=3.7，这样会直接在当前环境下生成一个环境```miniconda3/envs/$NAME/bin/python```，更加不容易和global的python搞起来
	* 然后pip应该也是安装到了对应位置不用修改，然后用```pip install ipython```
	* 安装完成之后虽然```which ipython```正确，内容也正确，但是输入ipython还是global的 - 需要**decativate再重新登录虚拟环境以reload环境**
* ```conda deactivate``` 退出现有环境
* ```conda info -e``` 查看现有的环境
* ```conda remove -n $NAME --all```
* ```conda create -n $NEW --clone $OLD; conda remove -n $OLD --all```

* 有的时候更新了环境之后还pip还是指向了base里面的pip
	* 这个时候decativate一下然后再activate就可了
	* 注意一定要deactivate再activate，关掉panel再activate好像是没用的(貌似不是一直work)
		* 现在居然是先输入一个错的conda env名字然后再输入就好了……(人类迷惑)

* 有的时候会出现无论操作什么都segmentation fault的情况(甚至重装conda以及更新conda)
  * 这个是偶用```conda clean -a```来清楚本地的缓存(可能是因为中途网络错误导致状态崩颓)
  * [居然是一个CSDN的blog救了我](https://blog.csdn.net/u012110870/article/details/103800701)


* 如果需要rename一个env的话
	* 需要复制一个新环境 ```conda create --name NEW_NAME --clone OLD_NAME```
	* 然后删除老的环境 ```conda remove --name OLD_NAME --all```

* de了一个ipython环境的bug，一开始的错误提示是在环境中仍然使用了base环境的ipython
  * 由于$PATH内部.local/bin在conda/env/xxx的前面。所以优先调用了base环境下的ipython
  * 检查bashrc的时候发现并没有.local/bin这个东西，然后发现是在~/.profile当中改动了$PATH，将.local/bin放到PATH的最后
  * **基本conda环境中对不上的情况，包括pip和python，都是$PATH的问题，其运行准则是优先匹配前面的**

## 源码编译TF

> following [official guide](https://www.tensorflow.org/install/source)

1. 安装prequisite

``` py
pip install -U --user pip six numpy wheel setuptools mock 'future>=0.17.1'
pip install -U --user keras_applications --no-deps
pip install -U --user keras_preprocessing --no-deps
```

2. 安装[bazel](https://docs.bazel.build/versions/master/install-ubuntu.html)
  * **注意需要查看一下bazel的版本，在tensorflow源码的configure.py中有着对应版本所能接受的bazel版本**
  * 建议直接从官网，以及[官方git repo](https://github.com/bazelbuild/bazel/releases)下载binary安装包安装
  * ```chmod +X ./bazel-xxx```
  * ```./bazel-xxx --user```
    * 注意这里的--user很关键，会加入环境变量，并且默认是将当前版本的bazel安装到```~/bin/bazel```
  * 需要在bashrc中加一行
    * ```export PATH="$PATH:$HOME/bin"```
  * 还有一种替代方案，相当于是bazel的编译完的版本[bazelisk](https://github.com/bazelbuild/bazelisk)个人没有尝试
    * 其使用应该是替换bazel的，可以直接在bashrc中```alias bazel=$PATH_TO_BAZELISK```

3. 下载tf源码
  * (其实可能应该放在安装bazel之前)
  * ```git clone https://github.com/tensorflow/tensorflow.git```
  * 切换到想要的分支，默认为最新的master分只```git checkout branch_name  # r1.9, r1.10```

4. 配置Build
  * ```./configure``` - 别的都无所谓可以默认，就是要指定一下CUDA的位置```/opt/cuda-10.0```
  * 经过configure之后的内容是在
  * 有几个预设的bazel build指令
    * ```--config=mkl```
    * ```--config=v1``` 

5. 编译(最可能出错的一节)
* 经过我自己的体验，貌似checkout到老版本进行编译容易出问题(总之我是失败了)
* 默认的TF-2.0编译 ```bazel build //tensorflow/tools/pip_package:build_pip_package```
  * 对master分支编译1.x版本 ```bazel build --config=v1 //tensorflow/tools/pip_package:build_pip_package```
  * CUDA版本 ```bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package```
    * 上次跑这个是失败了
* 注意如果需要在同一个目录下编译多次tf，需要执行```bazel clean```
* 该步骤生成了一个```build_pip_package```的可执行文件，下一步使用

6. 生成whl
* 这一步貌似不容易出问题
* ```./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg```
  * 官方说如果是最新的需要加上一个nightly flag，```./bazel-bin/tensorflow/tools/pip_package/build_pip_package --nightly_flag /tmp/tensorflow_pkg```
* ````pip install /tmp/tensorflow_pkg/tensorflow-version-tags.whl```


### 安装nccl

> 不确定可能编译出来的tf需要安装这个东西

* [Nvidia官网进行下载](https://developer.nvidia.com/nccl/nccl-download)
  * 下载对应的cuda版本，需要的平台(x86)，需要的发行版(ubuntu 18.04)
  * (当前NCCL好像要求cuda>10.0/cuda-driver>一定版本)
* ```sudo dkpg -i nccl-xxx.deb```安装
* 添加key ```sudo apt-key add /var/nccl-repo-2.6.4-ga-cuda10.0/7fa2af80.pub```
  * 甚至我添加key还少了一个库 ```sudo apt-get install gnupg```
* ```sudo apt-get update```
* ```sudo apt install libnccl2 libnccl-dev```
* 安装的nccl.h在```/usr/include/nccl.h```

* 由于我的cuda并不在标准位置```/usr/lib```，所以需要在cuda的对应文件夹里创建两个软连接，才能让tf的configure能够detect到
  * ```/usr/lib/nccl.h``` -> ```$CUDA_PATH/include```
  * ```/usr/lib/x86_64-linux-gnu/libnccl.so.2``` -> ```$CUDA_PATH/LIB64```
### 安装android studio

* [Tutorial](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android)
* [官网安装]()

