---
layout:     post                    # 使用的布局（不需要改）
title:      Bayesian & Non-Parametric   # 标题 
subtitle:   (...炼出一个丹方子)  #副标题
date:       2019-12-16           # 时间
author:     tianchen                      # 作者
header-img:  img/11_30/bg-ucentre.jpg  #这篇文章标题背景图片  
catalog: true                       # 是否归档
tags:                               #标签
     - 碎片知识
---

# Bayesian
  
*  Bayesian学派和频率学派(Frequentism)的对比
*  贝叶斯概率公式 - P(A|B) *{Posterior}*  =P(B|A) *{Prior}* xP(A) *{Likelyhood-We Want}* / P(B) *{Evidence}*

|Bayesian | Frequentism|
|--|--|
|利用先验分布来描述事件| / |
|将参数$\theta$看作一个服从某个后验分布(Posterior)随机变量(Stochastic Variable)|将起看作一个待求的常数|
| 给定样本X，求参数theta的条件分布-后验分布| 求常数theta的值 |
| 认为样本X是固定的 | 认为样本是随机的 |
| 最大后验估计(分布估计-所以要用交叉熵) | 最大似然估计(点估计) |


---

* 最小二乘回归(Least Square) - 等价于在高斯先验(Prior)下的最大似然估计
  * *高斯分布先验对应着二阶矩，原理同L2 Regularization等价于加上高斯先验*
* Ridge回归 - 等价于高斯下的最大后验估计（MAP）
* LASSO回归 - 等价于Laplace分布下的最大后验估计
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191218153125.jpg)
---

* Bayesian方法能给出不确定度的度量?
* NN中的BayesianNetwork（贝叶斯网络）是一个DAG(有向无环图)和Bayesian Neural Network不是一个东西

---

* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191218162209.jpg)


# Variational Inference

* 大部分Probabilistic-Based模型的inference方法，都基于MCMC(Markov Chain Monte Carlo)
  * Example: Gibbs Sampling / Metropolis-Hastings  
  * Shortcomings: 虽然保证能够获得Optimal，但是不知道当前解距离最优解的距离有多少； 需要一个很好的Sampling