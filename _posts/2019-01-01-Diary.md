---
layout:     post                    # 使用的布局（不需要改）
title:      日知录          # 标题 
subtitle:   看看自己能够坚持多久       #副标题
date:       2048-01-01            # 时间
author:     tianchen                      # 作者
header-img:  img/10_1/bg-tz1.jpg  #这篇文章标题背景图片  
catalog: true                       # 是否归档
tags:                               #标签
     - private
---
# 日知录

> 这个习俗大概来自于高中？FXB让我们记录下每天学到的东西，高中时候没有记住，不知道之后能不能记下来

### TODO:
* ⭐找飞哥安排一下量化的bug
  * 可能还需要尝试一些新的？
* 有可能(时间允许的话)压一下digit的网络大小？
  * 反正文章中说是可以的（而且理论上我们最后的场景也还没定呢）
* VisDA的exmaple可以写到本子里但是估计没时间做

### 2019-11-22

* 和汪总交流之后
  * 首先把我们所解决的问题更明确的场景给提出来
  * 开头先把实验场景写了
  * 把我们方法的优点列出来
* 凯哥提到了sim2real的东西可以搞一下
* **需要改PPT**
  * 改好了PPT
* 做了一半北航开题的PPT
* 测试了1k Label的实验场景
  * 还没有达到我希望达到的点
* 纯定点训练掉了几个点，回头调一下
* 需要继续调研量化的方法

---

### 2019-11-21

* 看到了一篇将Semi引入到Transfer中的文章
  * 说实话单纯文章没太大contribution,但是我可以引
* 做了定点测试，有一些问题
  * 发现了原来的网络其实小了
  * 用student做test发现结果超级noisy，改成teacher稳定多了
  * 貌似对小lr来说，量化炸了？ 


#### 组会

* DAC准备投稿的内容
  * 考神的一个spNN的工作,GPU上稀疏矩阵乘
  * 一个RRAM的加密的工作

#### 算法组会

* Multi-Agent Communication in RL
  
* Category
  * 隐式的通信：对环境作用或者式通过自身行为的变化
  * 显示的通信
* MultiStep-Mnist
  * 两个Agent通信，每人获得一张图片，经过5步之后猜测，鼓励猜对数字
* CommNet
  * 每一层网络取所有在通信范围之内的agent，取一个平均过一个transform和自己的结果一起做下一层
  * 设置了一些场景
    * 车过红绿灯
* 灵活的局部通信
  * Attention，独立于RL(DDPG)的训练之外
  * 用Attention取判断该通信是否有value
  * *减少了无效通信的需求*
* 涛哥说的非常有道理
  * Reinforcement做的是**已知奖励，找策略的问题**
  * DL做的是对大量的数据做**表征学习**
  * 两者compatible的点在于
    * RL有Policy Gradient能让策略变得可导
  * 数据分布首先要平稳而且独立同分布
    * SGD是有前提的，偏离前提太远，会不work

* Adversarial

* ICLR2017 Goodfellow 《Adversarial Examples In Physical World》
  * 产生三种数字域的对抗样本
    * Attacker Strategy （从梯度传播入手）
      * 完全已知目标模型之后，去把输入图片依据传回来的梯度做一个传播
  * 直接打印出来就能work
  * 还提出了一个Destruction Rate作为评价指标
  * 此外还给出了一个Lower Bound


* CVPR 2018 - 3D的样本


* 有一个哥们水了好几篇
  * 先说对抗样本不鲁棒，对距离光照不是很稳定，对Detection无效，说前面 的对的很齐
    * 《NO Need To Worry about Adversarial Example in Detection》
  * 再说我找到了一种
    * 《Adversarial Example That Fools Detectors》
    * 需要对场景有一个3D模型，生成一个Texture依据空间特征贴到




---

### 2019-11-20

* 做PPT的一天
* 整理了一下文件综述和ReadingList
* 约了汪总讨论

---

### 2019-11-19

* 测试了Warmup，没什么问题
* 准备测试定点训练，出现了一些小bug，还有一些实现上的问题需要咨询飞哥
  * **具体是怎么确定的，看了一眼Quantzie-Aware的东西**
  * fix建立net的时候，必须要自己一个模块一个模块去搭吗，比如我要做一个Res18的量化，需要自己搭一个吗
    * 可以去做Patch
  * 对于DataParallel怎么处理
    * 是可以做的，我目前姿势有问题
  * 我现在的case，需要对所有的样本做一个0.99x+0.01(x+1),是否仍然有效，会存在一个float赋值给到int的问题
    * 思考了一下每个weight其实是有一个buffer的，那个buffer其实是可以存储我转换之后的东西
    * 然后定点的过程设置成auto的话是会在前向的时候先遍历一遍所有的weight，找到最大之后往后退几位，定点Register并且走
* 另外一个就是剪枝
  * 有没有什么比较耐操的方法
    * 目前就是L1范数
    * 还有涛哥文章之前提过去寻找最远的L2范数
    * 之前文章也没有在FPGA上跑起来，做了一个软件的实验
  * 郭哥之前那篇文章里大概剪到一个什么地步？
* 一个非常关键的问题就是定点之后这个Self-Ensemble的效果可能没了！大部分都是设置为0.99
    * 也是刚刚发现，很难搞，但是是不是可以和郭哥文章里的weight buffer那种方式，多存一份，多用一个
    * 还有一个想到的就是图像压缩解码的方式能不能作为一种aug？(值得测试) - 其实损失会有些小把。。。
* 做PPT整合思路，约汪总

---

### 2019-11-18

* 养病
* 跑手续好像比较可行了
* 摸鱼Day

---

# 2019-11-16/17

* 草我好像知道昨天那个是为什么了...**我居然把Mask弄反了...**
  * 其实替换softmax到logit其实只是加了一个约束,防止太错误的样本影响性能
  * 原本其实是th越高,而把th以下的东西采纳了,我是傻卵
* 上午到中午都在复现这个新的实验
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191116131701.png)
  * 这段话我感觉还是比较关键的,transfer其实是一个很好的解决Semi-Supervised Learning的方法
* 当前有一个很搞怪的Bug
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191116191603.png)
  * 在SVHN实验的时候Loss有抖动,飞哥说应该是随机性相关的原因
    * 目前已经排除了Dataloader的问题(用最直接的Dataloader也会存在这个问题)
    * 难道是这个任务太难了?
* 晚上开始测试Office集
  * 发现也有毛刺
  * 认知上难道说是计算Logit的MSE炸了?

---

#　2019-11-15

* 上午调试SVHN的半监督学习环境,顺便把Cifar的Semi调通了(**感觉这个步骤非常关键啊!**)
* 下午阅读郭哥文章,构思下周讲一下
* 晚上摸鱼+开始做PPT
  * 被v2ray折磨好久

---

# 2019-11-14

#### 组会 - 曾C讲了一下NAS

  * 将搜索空间看作一个有向无环图，每一个架构都可以看作一个子图
    * 需要一个评估标准（可能不仅是Accuracy，可能还有一些其他的）
* **Search Space**
  * Global Search Space - 首先是Block By Block的一个一个Op搜索
    * （这里是搜每个模块是不是用Conv或者Pool）
    * 同时还去探索有没有分支和Jump Connection(改变链接方式)
      * 比较复杂比较多
  * hardware基本都是Segment Based，就是一个Module一个module
    * 而另一种是Cell-Based固定好了每个Cell的结构
    * 而Block-By-Block是更加细粒度的
* **怎么选择**
  * 用Reinforcement Learning去做
    * 对一个Agent，Accuracy是
    * NASNet就用了Policy Gradient
  * 用遗传进化算法去做
  * 去缩短评估Acc的时间
    * 用替代模型（一般是ML，用高斯模型去大概地估计）
  * OneShot的
* **评价标准**
  * 先少训一些Epoch，再排序
    * 后续工作提出要做动态的变化
  * Learning Curve Extrapolation（外推）
  * 权重继承与结构变化
    * 先有一个Warm-Up 
    * 可以说是利用了Weight的信息
  * Oneshot一次只评估一个
    * 问题在于这个bias会比较大          
    * ProxylessNAS - path-level-binarization
* 与Hardware结合-
  * Constraint变多，比如加入Latency
    * *MNasNet* 第一个将Latency引入的工作
  * 直接对多目标优化
    * 基于Pareto Optimal的 - 找到满足多目标（当多目标矛盾的时候，零和优化）找到那个最优的边缘
    * 一些work尝试去分解       
* 不仅做Hardware-Aware，做与Co-Design
  * 基于RL的NAS和HLS的FPGA加速相结合 - 白盒的Simulator
  * *思考如何把两个东西更加紧密的结合起来*

#### CORL会议

  * [链接](https://github.com/zoeyuchao/Conference_Minutes/blob/master/CoRL2019.md)
  
#### 算法组会

* 算法组会 - 对抗样本
* 基于Adversal Example
  * 比如叠加一个干扰，网络就不work了(垫一个分布)
* Adversal Training
  * 包含了生成和抵抗
    * 基于最大化Loss的角度从数学推理去寻找一个对抗样本的分布
  * L-BFGS-Attack (一般针对二维图像)
    * 但是对于实际的三维的物体作为对抗样本，还需要考虑光照等因素，不是特别友好 - EOT(Expeatation Over Transformation)
* **EOT**
  * 寻找一个变换的集合T （这是对对抗样本加上了一些光照等的数据增强）- 这个T是一个三维到二维的映射
  * 很数学的一些评价指标
  * **最大的问题是解决了Render这一层次的问题，主要是很多render不可导，把这个东西给考虑进去了**
* 黑盒和白盒子攻击
  * 对模型本身的了解情况，白盒知道结构，并且能知道Gradient
  * 有的是加入随机，将其变成灰盒，就是我得到的Gradient不一定准确
* 目前玩法
  * 1. 实践上的，Adversal Training，针对某种方式去产生训练样本s，Follow Gradient去攻击
  * 2. 理论上去找到一种好的衡量网络鲁棒性的性能的方法，定义为对输入加上一个多小的扰动，能够让网络失效的期望的lower bound
    * 由于计算量的问题，难以做到对一些大的数据集和结构进行评估

---

* OFA - Once For All
  * Han Song，一个特别大的架构，包括了各种KernelSize和各种的Depth和各种Expansion
  * 7x7 - 5x5 -3x3之间是有weight Share的，扣中间一块过一个Transform（这个对每个channel是一样的，省了很多weight存储）
  * 训练一次，一个超大的，对所有Arch的Accuracy打表，到时候用用哪个硬件就直接选哪个Arch
  * 和一般的NAS从一个小的不断到大的

---

* GNN
  * 卷积
    * 基于空域 （Spatial） - 相当于对于每个点每次选择最近的K个值进去卷，本身不包含链接信息，但是选择点的过程包含了信息
    * 基于谱域的（Spectral） - 有一个所谓的傅里叶变换，就是对Adjacent Matrix或者是对Laplace矩阵做一个奇异值分解，相当于得到了一组正交基，对这组正交基变化一下，作为新的基地，进行一个变换，将原来的输入映射到一个新的域当中进行处理（怎么处理这里的卷积核也可不同）
  * GCN，就是相当于再原本计算的基础上加上乘一个邻接矩阵
    * 这样的好处在于图的计算是累进的，比如说定义一次运算为取交集的话，反复运算就变成求它的闭包
    * 这样每一次卷就可以让图的链接关系更深入一层
  * 牛逼的地方在于顺序不变性 - 对于一些具有旋转特性的样本网络的计算方式就导致它本身就是等价的
  * 拉普拉斯矩阵的意义
    * Laplace算子-求的是梯度的散度
      * 对于图来说：从该点射出的梯度，减去汇入该点的梯度
      * 与边的方向无关，用来描述无向图
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191114230547.png)
      * 其N个特征值都非负


---

### 2019-11-13

* 让整个代码跑了起来
  * 目前还在添加trick让其获得标称的效果
  * 目前还没有跑到,这个加th的方法好像卡主了?
* 看了新的论文 MixMatch,Semi-supervised的另外一个SOTA
* **Ablation study**
  * ```An ablation study typically refers to removing some “feature” of the model or algorithm, and seeing how that affects performance.``` 
  * 简单来说就是去掉某些Feature之后模型还work不work,**控制变量**
  * 根据奥卡姆剃刀,简单和复杂的方法都能解决问题,而简单的方法更可靠
* 看了几个Prunning的方法,似乎希望能够对我的问题起效果   

---

### 2019-11-12
* 摸的一天，狗命
* 上午读了UDA，感觉数据增强的方法还有空间
* 对于选切入点有了一些信心，Semi是一个比较好的方法
  * 可以改成Consistent Learning
* 仔细读了一下resnet的源码,大概知道了是个什么样子的组成(很惭愧啊之前都是脑瘫拿来主义)
* 让semi的代码几乎能跑起来,还缺了一些feature



---

### 2019-11-11

* 看到了一篇文章[THERE ARE MANY CONSISTENT EXPLANATIONS OF UNLABELED DATA: WHY YOU SHOULD AVERAGE]()
  * Cornell
  * ICLR2019
  * 针对原本Meanteacher类的Weight Average方法在优化方法上进行了修改，提出了fast-SWA(Stochastic Weight Averaging)对标SGD的一种算法
* 注册了ASPDAC
* Load Data方法调好了


---

### 2019-11-10

* 苟命
* 下午做完了并整理了office31以及imageCLEF的结果
  * Work的不是特别好...
* 测试了一下定点工具
  * 但是好像有bug?
* 晚上整理了一下现在的思路,准备和汪总交流一次
  * 下午思考了一下并且找了目前思路的点
* 并且看了一下meanTeacher的Code,准备Setup一下SemiSupervised场景下是不是work

---

### 2019-11-9

* Office31实现确实会有一些问题ＡＷＳＬ,主要是到Ａ这个过程点会很低
* 可以尝试imageCLEF
* 正在入门飞哥的定点工具
  * 和飞哥交流了一下,大概还是有一些收获的


---

### 2019-11-8

* 更新了数据集,整理了一下digits上的结果,基本也就是只能复现之前的结果,而且基本证明了vgg不work是因为train from scratch而网络太大的问题
* 准备好了imageCLEF和Office数据集
* 正在准备硬件部分的Proposal
* 
---

### 2019-11-7

* 上午考试
* 组会群里发了 [NN Benchmark](http://www.npubench.org/?cat=21)
  * 两张很有意思的图
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191107123504.png)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191107123526.png)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191107123546.png)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191107123627.png)
* 中午组会
  * DPU Strcuture
    * 组成
      * 计算阵列
        * 以MAC为主要组成
      * 片上存储 
        * 带宽大 （100GB/s）
        * 容量几十M
      * 片外
        * 可以很大，但带宽在10G
      * 控制逻辑
        * 时分服用
        * 固定的有限状态机
    * 工作点
      * 近存储计算(和NVM关系更大)
      * 如何选取并行度
      * 指令接口的设计
      * 近似(fc层的SVD分解)、
* TVM
  * 端到端的DL算法编译工具
    * unify heterogeneous  
    * 部署的实现方式和硬件相关，目前的方法基本基于硬件厂商的高性能库 
    * 手工优化成本高，移植性差
    * 并且每个框架对于每种硬件都有独立的编译优化
  * 生成一个中间表示层
  * 在计算图优化层面已经比较ok和生成硬件代码之间有一个Gap
    * Solu： 张量表达式的中间表达
  * 计算图的优化v
    * Op Fusion
  * 计算图层次？(是否与硬件相结合)
    * 在数据流图后又包了一层
    * **张量表达式**：类似一个placeholder，描述了不同数据流之间的依存关系
      * 以及对卷积计算中的展开与变化
        * 比Halide要多的 Memory Scope， thread co-operation之间等特征
  * 张量表达式之后
    * LLVM，OpenCL CUDA HLS等等
  * 现在还又AutoTVM
    * 上板之后再调
  * 对不同的Structure
    * CPU - Scalar
    * GPU - Vector
    * Accel - Tensor
    * 这样可以减小搜索空间
    * 我理解和OneAPI不一样的是
      * 根据平台的搜索空间缩小其实是再autoTVM那一环
      * 而OneAPI是在直接生成张量表达式这一环就做了的
  * 搜索的方法
    * 随机搜索，遗传算法
    * XGBoost
    * Meshgrid
  * 未来工作
    * 支持更多后端
    * 根据硬件特点，完善scheduler的搜索空间    

* 下午接着调算法,原本比较困难的Task好像还是没有特别好的解决
* 被一个问题卡了很久,在同一个Domain上teacher的性能比student差很多
  * 考虑了很多原因,最后发现是因为Train的时候没有让Teacher参与训练,导致Teacher的BN参数没有被更新(因为我copy的时候没有把BN的参数更新过去)
  * 暂且解决
* 现在看起来AdaBN是有一定作用的
  * 直接到新的域apply，掉到10%，但是用了它还有50%



---

### 2019-11-6

* 复习通信网络原理的一天；
* 继续思考算法怎么改

---

### 2019-11-5
* 小组会，加速器相关内容
  * MICRO，ISCA的几篇文章
  * 主线是做稀疏化的加速，大部分的操作是存一个bitmap，然后有很多种切入点
    * 有一些关于负载均衡的比较有意思（但是大部分还是放在软件层面去做的）
  * 还有一些其他的工作
    * 拆分矩阵省存储
      * 不同的运算顺序会导致计算复杂度不一样 （nx1）(1xm)(mx1)
        * 顺序算 mxn+mxm
        * 先算后两个m+n
      * 最后的结果VGG16 ImageNet上能压到5倍左右？
        * 孙博说正常剪枝能够压到10
    * 对每层内的参数做细粒度的量化位宽
      * 对每个组(group)取不同的量化
      * 做了一个统计发现40%左右的只需要4比特
      * 后续怎么做？
        * 自适应地去调整乘法器所需要的周期数
        * 如果利用了这个，那么就不能在位宽这个维度有并行度
    * 有一篇文章尝试榨干最后一点优化
      * 在用乘法器算8比特乘法的时候，采用[Booth编码](https://www.zhihu.com/question/37637775)去把0的乘法给跳过去(因为0乘什么都是0)
        * Booth算法把连1换成两个1，来减少逻辑资源使用(我寻思我们实际用的DSP啊？)可以减少延迟
        * 本质上是减少了二进制乘法中的部分和

* 和郭哥讨论了一下
  * Prunning可以放一下
  * 首先还是要把Task完成,可以做一个偏应用的
* 继续炼丹
  * 找到了一个稳定的点
  * 摸索中
* 在看飞哥的定点工具用法
  * 主要库 ```import nics_fix_pt as nfp```
  * nnf就等价与nn
    * ```import nics_fix_pt.nn_fix as nnf```
  * 对每个model要做一个```model.set_fix_method(fix_method)```
    * fix method有三种
      * FIX_AUTO/ FIX_FIX / FIX_NONE
  * 这样定义model
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191105211057.png)
  * ```net.fc1_fix_params['weight']['method']```
    * 两层都是dict,里面存着信息

---

### 2019-11-4

* 早上突然发现服务器登录不上了
  * 然后发现是因为我开了Tensrboard的端口转发导致登录不上
  * 所以以后不要吧thinkpad上的tensorboard开着回去
* 继续炼丹的一天
  * 用Tensorboard找了一些规律
  * 调整了一下东西,昙花一线了昨天没有解决的问题(但是还是没有本质解决)
* 签了个字

---
### 2019-11-3
* 今天是突破性炼丹的一天...
* 复现出了Self-Ensemble的一部分内容,但是仍然有几个Task没有完全搞定
* 现在最大的问题是**某些模型一开始训练的时候conf就很低,低到无法打破conf_thresh而导致一直很菜**
  * 目前还不太清楚怎么解决
* 发现的一个新点
  * 一开始训练warmup的阶段,由于还没有触摸到conf-thresh,所以说相当于只有source domain在work(思考了一下好像确实是和target domain没有关系的)
    * 那么这个阶段是否可以提前做好?
  * 如果这样可以的话,那之后可能可以做一个实验,需要取多少个TrainingSample来存下来来保持label的clean?
* 还有一个多卡的Bug还没有解决


---

### 2019-11-2
* 熊哥实验（糊弄了好久）
* 继续炼丹,继续搭实验环境
  * 发现前面的augmentation和一些预处理可以直接用Salad的东西

---

### 2019-11-1
* 手续很闹心
* 回来汇报工作
* 配置一下弱智环境(IDM貌似还是没有work)
* 稍微推进了一丢丢代码

---


### 2019-10-31
* 组会
  * RRAM相关的一个INtro
    * 忆阻器认为是一个单比特，通过加电压来Set和Reset
    * Cell/Wire - Wire/Cell 
* Multi-Label Few-Shot via Memory-Enhanced
  * Metric Learning
  * MultiLabel 一个图片内有多个物体
    * 本质上相当于做N个2分类
      * 用BCELoss
      * 本质上是一个2^N，用Pair的方式减低
      * 留一个memory
      * 从FeatureMap通过一个Fc映射到一个概率空间
        * 传统的方式是取一个argmax，这里是每个再过一个Sigmoid，看大小定True，False
      * Cosine Similarity（Pearson Correlation Coefficient）
  * Few-Shot 利用少量样本获得
    * Augmentation-Based
    * INitialized-Based
    * Metric Learning
      * 寻找一个合适的Embedding空间
    * 先从ManyShot的数据集Pretrain，然后只训Classifier
    * 有一个思想是去把新的样本去Pair


---

### 2019-10-30
* 干了一天
* 上午和下午沟通了一下Self-Ensemble这种方法
  * 感觉还比较可行
  * 主要时间花在看弱智代码上
    * 真的很难用...
* 晚上做PPT，更新了思路，准备明天讲

---

### 2019-10-29

* 汪总表示需要把故事先说好，更新PPT
  * 提炼出来一个更小的故事（确认一个点了）
* Caoyu 
* Online Adaptation For Intelligent Dyncamic Systems
  * Edge Inference(1Tops) - Cloud Inference 
    * Between those (无人驾驶汽车，飞机)
    * 所谓*Compact的Data-Centre*
    * 强调*实时性*
  * 强调了新数据的存在
    * 不需要From Scratch，但是需要在线调整
  * Brain-Inspired了...
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191029111711.png)
    * Related到Transfer，Reinforces & Continual
  * 从硬件角度
    * Hybrid Memory Arch
    * 一部分需要很快的调整
      * NVM（不写，只做Inference） & SRAM（读写都快，可写）
      * 再次强调了**实时性**
  * Conrinual Learning - Catastrophic Forgetting
    * Regularization
    * Memory-Replay (有神经学的背景)
  * Cumulative Learning
    * Incremental对于一个假设10分类的问题，一类一类学，这个其实不太make sense
    * 先在云端学9类，再学最后一类
    * 核心的区别是*Pretrain On Clod & Adaptation On Edge*
      * 很奇妙的比喻： 1岁的小孩啥都不会，过来一年全都会了
      * 放在云端计算，留给终端的计算小
      * PST
        * 做一个Important Sampling，去固化比较重要的（like Prunning）
          * 权重大小*梯度
      * 将其Apply到NVM
        * 首先第一轮就会有损失（量化损失）
          * （软）也是做了KD（相当于在量化的过程中引入KD去Finetune） （P17）
          * （硬） RSA，去训这个SRAM
    * NN的发展趋势
      * Synapse 多，Neuron少，更加Dense
      * 从Memory-Bound更深一层，是内部lattice 
  * 提问
    * 提到可能下一步工作在前面这个第一个Task怎么确定
    * KD都是Offline的
    * Training放在FPGA上
* 尝试去讲故事
  * 晚上读新的论文，看可行性


---


### 2019-10-28
* 炼丹的一天
* ~~顺利反向复现论文~~
  * 我真🥦
  * 接着做实验把
* ~~visDA的有一篇self-ensemble的文章可以看看~~
* 签字的问题需要找老师

---

### 2019-10-27
* 上午过来接着配系统装软件
  * ~~win下跳板登录好像有一些问题...~~
    * 是因为初次登录貌似要下载一些东西，但是服务器没有入网，所以卡住了
* ~~做熊哥PPT~~
* 接着尝试炼丹,写Finetune的代码
  * 写好了,明天实验
* 继续思考
* ~~这篇文章的所谓Adaptive BN?~~
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191027210537.png)
  * 没啥子鸟用

---

### 2019-10-26
* 没有打卡的一天...
* 上午和中午校庆活动
* 下午修电脑，晚上装系统   
  * 做了一半熊哥PPT
* **是最近最摸鱼的一天了，需要反省啊！😡**

---

### 2019-10-25

* FCCM - Online Learning
    * 1-6  / 
* 罗列了很多了，找一个比较小的点去展开
    * 我的思路还是在Hardware-Friendly的TL方法(或者说是UDA)
* 首先还是要想一下目前的方法怎么不Hardware-Friendly了
    * 肯定是有东西的，优先度不是特别高
* TODO:*尽快把算法给拿出来*
* 和Design无关的盲测的方法
    * 给HLS Debug - 反馈回来的Verilog不可读 
    * Pre-Sliicon : Logic，
    * Post： 电特性，
        * 复制一份进去，检错
* TODO: **尽快找一个可行的方案去干**
    * Async是想要获得一个比较好的分类器，训练了一个Labelling网络(Feature Extractor共享这个还是比较elegant)
      * 问题是训练方式不是很elegant
      * 或者说如果能work的话这个方法也不是不可
    * Semi证明维护一个数据集能更好
        * 前提是需要一个Acceptable的老师
        * 尝试下AdaBN能否解决这个问题
* ~~TODO:盖章的问题~~.
    * 颖姐那边能handle


---

### 2019-10-24
* 中午讲了一下PPT
    * 问题
        * 提出往Meta-Learning（学习如何去学习），不是很Feasible
        * 提出Teacher有了Student有什么用
            * 俺准备把Teacher也放终端
        * 场景:我还是踩着TL这个场景
    * *先把算法整出来才是最关键的*
        * 淦...
    * 算法上的Contribution在哪里
        * 凯哥提的，Semi文章第一个是堆了大量的数据，和那种不是特别一致
        * *看我的TrainingSet准备怎么构建了*
            * 单纯的拿置信度应该是不大行？
* TODO: 改PPT，炼丹，
    * ~~ Load一下ImageNet  ~~ 
        * 顺便搭一下ImageNet的训练环境 
            * 搭好了，但是...好像被磁盘读取卡了性能
              * 测试实际涉及和sda的读写,速度10kb/s
              * ~~LZZSCL...~~
              * 另外测试了一下我的/home目录底下
                * 看不到速度,读取速度也正常,没有和sda通信
              * *目前的推测是我们的home目录是一SSD,但是那个3T的玩意估计是个机械*
            * 要么是DataLoader的问题，要么是?
    * 看懂DAN的那个MMD是怎么弄的
        * (写个论文解读)
    * ~~远程Jupyter Notebook~~ 。
        * 出现了奇妙bug，不能从0.0.0.0启动jupyter
        * 对Tensorboard给搞定了！  
        * 同理Jupyter Notebook也解决了!
        * 方案放在EVA开发日记里了




---

### 2019-10-23

* 今天是炼丹的一天
* 又深入了解了一下pytorch的设计,还是有点东西
* ~~多卡非常爽~~
* 继续读了几篇文章,昨晚发现的这个online trasnfer的pruning有点东西,和我的主题很切合
* TODO: 继续炼丹
  * 还有看一下Data AUG和可视化怎么做
  * 接着研究代码
* 继续读文章,改PPT,准备和汪总的交流
* 文件还没有出,就很尴尬

---

### 2019-10-22
* 把无线电导航和通信网络补了（上午）
* 下午上课，跑了个餐卡手续
* 晚上接着配环境
    * 发现充钱之后我在服务器上不能上线了（很尼玛神奇）通过手动添加ip的方式上线了 
* 下午在配置WSL，这东西有点好使
  * 记在UbuntuSetUp一文中了

---

* 配置了Linux环境下通过跳板机直接访问目标机器
  * 一次ssh而不是两次
  * 主要参考了[这篇文章](https://blog.csdn.net/DiamondXiao/article/details/52474104)
  * 在.bashrc里面加上
  ``` bash
    alias eva="ssh zhaotianchen@101.6.64.144 -p 22 -o ProxyCommand='ssh -p 42222 zhaotianchen@101.6.64.67 -W %h:%p'"
    alias fpga="ssh ztc@fpga1.nics.cc -p 22 -o ProxyCommand='ssh -p 42222 zhaotianchen@101.6.64.67 -W %h:%p'"
  ``` 

* 按照上面的配置之后还需要再进行一次秘钥copy
  * ```ssh-copy-id  -i id_rsa.pub zhaotianchen@101.6.64.144 -p 22 -o ProxyCommand='ssh -p 42222 zhaotianchen@101.6.64.67 -W %h:%p'```
  * 说明从跳板机登录（2次）需要的秘钥和一次的需要是不一样的
  * fpga1.nics.cc -> 101.6.68.236(由于用ssh config文件这种方式登录的话不能用域名)



---

### 2019-10-21
* 上午看了几篇新的论文，和VisDA的比赛解决方案，发现多了一些可用的Trick，同时发现多了一些文章要读
  * 主要就是在Noisy Label下怎么取得比较好的效果
* 今天FAIR把Semi文章的模型开源了    
  * 但是代码没有开源
  * 在git上找到了一个人的复现代码，但是好像有一些不大Work，可以参考
* 下午上课，复习了一下无线电导航
* 中午和晚上办网络的手续（好狠）
  * 有一说一网很贵
  * TODO: 问一下凯哥怎么整训练数据
* 晚上配置eva0

##### 网络实验
* 正常时间可以用DIVI（这个不要钱，而且挺快的）不属于清华内网
    * 可以通过跳板机连接eva和各种东西
* 如果用Tsinghua Secure，相当于连入了清华内网了，就可以直接通过ip地址连接eva了（而不需要通过跳板机）
* eva需要上线
  * 和wiki上不一样我只要进去调用eva_share目录下的Tunet-2018c启动了之后就直接可以联网了（而且还是外网）
  * 运行之后理论上会一直占用这个Term，但是我CTRL-C强制退出之后连接没有终止
* 当然每天要去充钱
  * 冲10块，只能微信（因为理论上你在看到自服务界面的时候还没有进入清华内网）- 但是每天充钱好像必须首先在清华内网里（日）
  * 所以说充钱也是需要在清华内网里面的（日）
* 上线之后打开usereg的自服务可以看到eva的ip出现，并且开始跑流量了
* 实际测试了一下，如果账户里没有钱了，是不能正常用服务器登录的
    * 但是可以传文件上去，目前利用Win里的MobaXterm证明是可以的，在服务器没有联网的情况下把数据传上去了
* 第二天起身发现，我的网络在服务器上是连不上去的，只有通过手动添加ip上去，所幸这样的方式目前能work

---

* 遇到问题 1.其实和网络没有太大的关联
  > Release file for http://… is not valid yet (invalid for another xxd xxh xxmin xxs)
  * [这篇文章](https://www.cnblogs.com/outs/p/9706437.html) 据说是改一下系统时间
  * 这个问题过了一段时间自己消失了，很nb
    * （~~炼丹炉的自我修复？~~）
  * 第二天这个问题又出现了，修改至阿里的源，问题暂时消失`

---

* 配置一次性跳板机的登录，并且推送图形界面
  * Win：利用好MobaXTerm
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191021230929.png)
    * 按这个方式配置，可以直接上去，然后测试过可以推送图形界面

* VsCode Jupyter-Notebook Built-In的支持
  * 先命令行```Python: Interpreter```
  * 然后```Python：Create New Blank Jupyter```
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191022201033.png)
  * 很香，然而服务器端用不了，因为Remote上没有Python插件？





---

### 2019-10-20
* 上午改了下PPT，做了点作业，看到一篇有意思的文章[数学之美番外篇：平凡而又神奇的贝叶斯方法](http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/)

> 概率论只不过是把常识用数学公式表达了出来。    —拉普拉斯

* 贝叶斯方法，一种相当General的推理框架
    * 从*逆概率*的角度思考
        * 正思路：从一个已知内部黑白球个数的袋子里摸球，摸出不同球的概率
        * 逆思路：从我们已经摸出来的球的情况，分析袋子里球的分布
    * why？ 人的观测能力是有极限的 ~~我不做人了JOJO！~~ 
        * 对于上面的问题：*不太可能完全获得袋子里面球的情况*而只能通过“取球”这个过程观测之后的结果
    * 分析问题方法
        * 首先给出几种Hypothesis（这里可以理解为*猜测*）
        * 然后根据观测到的结果，计算特定猜测的*后验概率*，从而选择最“靠谱”的假设，进行了*最大后验估计*
            * 当这个过程不考虑先验知识的话，就是*最大似然估计* （贝叶斯方法比简单的最大似然就是多了一个这个*先验概率*）
            * 对于上面的场景，先验知识就是袋子里都是球，~~不可能摸出一个皮卡丘~~
                * 而对于Bigger Picture来说，最大后验的事件的先验概率可能很小
                * 当我们实在没有先验信息的时候（在我们看来先验就是一个均匀分布）这时候只能用最大似然
                * 这里也是统计学家和贝叶斯学派的
                    * 统计学家：Let The Data Talk Itself
                    * 贝叶斯： 数据本身就有偏差
                * 一个有趣的例子 - 树后面有几个箱子
                    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191020110240.png)
                    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191020110312.png)
                    * 先验告诉我们两个箱子不大可能，因为两个箱子刚好一样颜色一样高概率比较小
                    * 但是这样的先验是否靠谱？这两个箱子会不会是同一批？    
            * 对于连续的情况，就是计算*PDF-概率密度函数*
    * 简单的贝叶斯公式
     > P(B|A) = P(AB) / P(A)
    * Example
        1. ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191020105057.png)
        2. 拼写纠正问题 thew被修改成什么

> 如果两个理论具有相似的解释力度，那么优先选择那个更简单的

* 谈及奥卡姆剃刀
    * 比如*Overfitting*的模型，将一些观测的误差，都尝试去解释
    * *贝叶斯奥卡姆剃刀*
        * 修正我们上面提到的先验出问题的问题？
        * 如果一个先验导致我们拟合的模型更加复杂
        * 相当于*奥卡姆剃刀原则*也是一种先验？

* EM算法
    * EM聚类，先验知识是数据一般按照*正态分布*
* 最大似然与二乘拟合  
    * 直线给出的是相对最靠谱的直线，而偏移的被认为是噪声
* 朴素贝叶斯方法
    * 条件独立假设：激进的认为条件概率竖线右边的各个事件是独立的
    * 为什么靠谱？
        * 讲道理是一定有关联不可能独立的
        * 有[前人帮我们证明了这些关联可以相互抵消](http://www.cs.unb.ca/profs/hzhang/publications/FLAIRS04ZhangH.pdf)

---

* 下午跑了修理，还没解决
* 下午修改发给汪总的PPT
    * 这个东西和incremental的联系
        * 充分利用数据，持续做训练，提升性能
    * 避免Overfitting
* TODO: 打印毕设需要的文件，约汪总一次线下
    * 还需要解决上网的问题，汪总回复之后问一下子把
      * 给颖姐发了邮件，等着回复吧...
    * ~~问一下凯哥是不是可以不存明文（可以存在cfg文件里面）~~
      * GG，看来必须自己搞一个账号了

---

### 2019-10-19
* 上午摸🐟+修电脑+空想是否思路有修改空间
* 下午读论文，改PPT
* 把Prim给做了
* 晚上给郭哥讲了一下
    * 看上去还比较feasible
    * ~~需要把基础知识部分改进一下~~
    * ❔考虑哪里可以hardware-friendly...      
        * 一个是训练集的构建方式

---

### 2019-10-18
* 上午整理思路做PPT
* 下午给雷老师讲PPT，整理论文阅读Post
    * 提的一个比较关键的问题是怎么个Hardware-Friendly
* 晚上补充文章和思路
    * 重新Review了一下TL的DataSet，还是有一定效果的
    * 接下来改一下PPT发给汪总把


---

### 2019-10-17
 
##### 组会
* RL在实际应用中获取对应平台的新数据
* 搭建仿真器来代替在实际场景中训练
    * 快，成本低，操作空间更大
    * 仿真器有抽象/非抽象(更难)
    * 仿真器的粗粒度和细粒度不一，且不同精度之间不能直接迁移(分布不一样)
    * 在类似*自动驾驶*等实际场景成本高的情况下
* 以多车避障为背景，构建一个仿真器
    * 局部最优-不动了就
    * 用激光雷达扫周围的东西
* 涛哥的Work把高低成本的仿真器给结合起来了
    * 对于一个局部子问题上用低成本的搜索可行策略，并且传递回高层次仿真器，类似一个“专家”Advice，或者说是“攻略”
* 重新讲了一遍RL基础（挺有价值的）
* 仿真场景
    * 有的时候很难遍历
    * 一个经典的N chains问题，可以向左或者右，左可以+1，右走到尽头再向右会获得很多
    * 小车坡度的问题，向右开不上去，需要向左先走一段再向右
    * Multi-Bandit 多个老虎机,某个老虎机的P很高，两种策略1.先对每个做一个sample，选最好的，玩到死 2. 去趋向效果更好的，偶尔也试一次效率差的（这个概率如何选择？）
        * 后验采样Thompson Sampling-不是Greedy的对每个分布去均值，而是从分布中采样，因而对于劣势的分布方差大的化也可能被认为是一个好方法
* 一个Work是在NN都SGD Framework下去找

##### Sensetime 宣讲
* 一个港中文的老师 - 王晓刚
* 演讲的标题是工业界落地的
* 整了个自己的计算平台Parrots
    * 多卡的一个操作
* On Hardware 软硬结合，算法和传感器以及芯片的结合，创新点
    * 提到的是硬件背景
* 工业布局
    * 智慧城市
        * 大规模的人脸识别；
            * Smart Locker
            * SenseID
        * 跨摄像头的视觉追踪
        * 3D
            * 人脸的建模与特征点（AR）
            * Vtuber(雾)
        * AR Navigation
* 干货，招人相关

##### Tusimple宣讲

* 找了货运这样一个相对更加合理的场景  
* 技术
    1. 感知 (主要用Vision)-卡车紧急刹车距离会比实际长，需要感知更远(Lidar)
        * 直接
        * 融合： 统一的表示，融合
            * *?时间上的Alignment*
            * 需要将图像从2D-3D,ill-posed,需要额外的辅助信息
            * 雷达的精度实际还是比较差，虽然能够直接获得速度（via 多普勒效应）
        * 1km的感知Demo
            * 一个激光雷达80m左右
            * 短距以及长焦的摄像头
    2. 定位
        * 卫星惯导-可行性不够
        * 摄像头：信息丰富，冗余而且不直接
        * 本质在于*匹配*
            * 与之前已经有的先验做匹配（也就是和实际的地图做匹配）
            * 绝对与相对相结合
    3. 路径规划
    4. 控制
* 工程
    1. 车载系统
        * 模块的调度
        * 异构平台支持
    2. 仿真平台-用于集成测试
    3. 基础设施
        * 大规模计算平台
    4. 硬件设备
        * 做自己的摄像头
* *？硬件平台*
* 广告
* 汽车不是刚需
* 5G做云端运算不是特别靠谱
* 雨天等复杂环境

---

### 2019-10-16
* 上午上课并且把银行卡的问题给解决了
* 中午整理了一下子装备哈
*  ~~等具体方案出来之后先和郭哥碰一下（大概周五左右） 约了周六下午 ~~   
    * ~~ 顺便问一下是不是需要把几个思路都放在里面  ~~  
    * 周末把PPT改好给汪总发过去
* 目前暂时的方案还是以Online Training为一个核心话题点，展开有大概3个思路，都可以Dig Deep
    1. Semi-Supervised
    2. Transfer
    3. Class Imbalance

---

### 2019-10-15
* 上午重新装Ubuntu...
    * 被代理卡了好久...
    * 搞定了ssh显示图形界面

##### 组会

* 讲了一下Semi的东西
    * 和云端的区分还是比较难，貌似只有*隐私问题*
        * 作为Online training会有一定的需求
        * 这个WorkFlow对应着一种Framework可能可行
    * 数据集维护，可以存一段时间  
        * 理论上只要有比较好的新的数据就可以了
        * 数据集的体量是多少？
            * 目前取得比较好的效果是10x原来数据集大小的样子（对于ImageNet来说我们的实验环境难以接受了）
    * 单纯的Classification提点数
        1. 实现起来不太可能，存储量太大了（这个Training一定是一个企业级的活，我自己做一定不能够这么做）
            * 除非换一个比较小的任务
        2. 本身只是为了提高一点点数，用处不是那么大
        * **往Transfer走相对会更有意义一些，需要深入思考和深入了解一下Transfer Learning**
    * 确实Online Training 梯度也会有精度损失，会不会产生影响
    * **Class Imbalance**也确实是一个需要解决的问题
        * TODO: 约意如神聊一下
    * 关于**Online Learning**
        * 是一个肯定存在需求的方向
            * 但其实还是取决与这个Online的场景能不能学到所谓"新的知识"
                1. 按照semi的workflow是完全没有的，还是原来的东西
                2. 按照Transfer的方案，其实是去后训一个Classifier
                    * 目前看来最Promising的一个⭐
                3. 能做到辨识新的东西
                    * 需要一个Incremental了，目前的算法感觉不是特别靠谱
        * 目前来说很多研究感觉*实验设计都不太考虑实际应用场景，很多都往所谓AI的“学习能力”在做，不是特别和硬件实现相契合关契合*
            * 说白了就是Training的这个Workflow还没有定论，甚至都没有人去解决Label的问题，如果我们最后的目标是硬件实现或者这加速的化，不是很Feasible
            * 所谓的Online偏向Continual“继续学习”的能力
* 看了一下实验室的手册，准备预约一下机器
    * 内容好...充实
    * 顺手学习一个
        * [LDAP(Lightweight Directory Access Protocol)](https://segmentfault.com/a/1190000002607140)-专业的分布式数据库，写性能差，用于查询，满足树状结构
        * ICP备案
        * BeagleBone是TI与Digikey联合生产的低功耗开源单板计算机（信用卡大小，可跑Linux）
    * ~~一些数据集在服务器share（或eva_share、/dataset等共享的）文件夹已经有了，可以先问一下你的负责研究生~~
    * ~~填写一下参考，占用的容量~~
    * TODO: 熟悉一下官网上的vim和tmux教程  ~~希望自己不要又从这个简单的弄起~~
* ~~ 需要改一下PPT先和汪总发一版 ~~
    * ~~需要看一下怎么用PPT高雅地画图，太丑陋了(暂时搁置了)~~
    * TODO: (比较后的，预计是对TL有了一个比较Feasible的方案之后)
        * TL还是相对比较Feasible的，具体的找算法已经思考还需要进一步看（可以给几个Example大概讲一下子他们的）

##### 平头哥讲座
* CTO，首席科学家 - 谢源
* DL-BigData-算力的三重Positive Feedback（画饼可以用）
* AI芯片场景
    * 服务器端；移动终端；物联网 - 需求不同 
* 产品
    * 玄铁CPU-RISCV-16Core-2.5GHz
    * 无剑Soc平台   
        * 缩短研发周期
        * 基于中天微的指令集
    * 含光 - AI云上推理
        * ~~都是剑的名字，很恶趣味~~
* 异构计算 Heterogeneous
* 半导体公司的3 Stage
    1. TI 传统方式
    2. TSMC
    3. HiSilicon - 由系统公司驱动而来
* RISCV的生态
    * 开源指令集的使用
        * 目前choice相对比较多x86和mips以及arm
    * Chisel - 面向对象的RTL描述语言 （但是编译器其实不开放）
        * 有尝试利用其做敏捷设计的开发
        * EDA工具上中国有欠缺
* 低功耗，终端(IOT)的芯片
 

---

### 2019-10-14
* 上午把雄哥作业做了，把显示器和硬盘安排了
* 读了一下Pytorch文档，有微小收获嗷👍
    * 微软自带的输入法居然可以打Emoji🐂🍺
* 晚上看了HLS，Vivado2017有奇妙bug，卸载换新的，好像ubuntu系统引导坏了

---

### 2019-10-13
* 继续修改和进一步思考开题的问题
    * 发现了很棘手的问题，这个YFCC不是很好用，有一定阻力，但是不是不行
    * 也有一些新的idea
        * 可以去证明一下定点的网络是否还是具有这样的性质
* 更加看了一下Transfer learning的tutorial
    * 感觉这玩意还是玄之又玄
* 复习了一下熊哥的课，名词太tmd多了，淦


---
 
### 2019-10-12
* 今天主要工作是做开题的准备PPT，稍微更加深入了一下文章
    * 数据集是怎么构建的
    * 大概是怎么训练的
* 如果需要把题目开小一点的话，可不可以直接从迁移学习入手，训这个CUB数据集，比较好训一点
* 读了Weakly Supervised Training
    * 网路对于Label Noise的容忍程度比想象中要高一些
* CUB2011数据集
    * 经常用来做*迁移学习*
    * 还有*细粒度的图像分类*
* 晚上还看了一些关于CNN加速方式以及TL的内容

---

### 2019-10-11
* 感冒依旧，躺了好久...还要参加一个1802的开学典礼，今天就继续思考了一下开题
* 找到了一个possible的开源代码(但是是做量化的) - 然而kill-the-bits里面还是只是开源了模型没有开源代码 ~~还是要自己刚~~


##### New Idea
* 想到了一个让Teacher和Student做**时分复用**的Idea，还ok
* 还需要看看Self-Training相关的东西
    * 貌似现在还是一个比较开放的Field，主要描述了一个在Unlabel数据集上利用某一网络进行标注，维护一个新的Training Set(这里有一些玩头)
* [EfficentNet提出对CNN结构设计的一些思考](https://mp.weixin.qq.com/s/T1ZwpaGO6PJR5Z6t2MULGQ)
    * 提出了**混合尺度变换**
    * 看来已经全面进入NAS时代了
    * 从3个维度开始考虑问题
        1. 深度
        2. 宽度 (体现在CH数目)
        3. 分辨率 (体现在输入图片的大小) 会影响到fine-grain的特征
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191011211753.png)
        * 将三种NN的尺度，混合起来限定为一种Block(代表这使用一定的资源？)，依据Block去搜索，相当于约束了搜索空间
            * 至于这个约束条件怎么来的，比较arbitary
* [Pytorch 1.4他lei了](http://pytorch.org/)
    * 更新了[移动端](http://pytorch.org/mobile )和[量化](https://pytorch.org/tutorials/advanced/dynamic_quantization_tutorial.html)的一些操作


---

### 2019-10-10
* 十一之后刚刚回学校，就持续感冒，约莫有2~3天没好了，对工作时间的大量浪费，下面需要学习养生
    * 早睡早起
    * 能运动运动
    * 吃吃早饭
* **可持续发展非常重要**快些养病
* 学习了一下*通信网络原理*
    * 复习了一下之前落下的内容(还真不少...)
    * Chap2 排队论
        1. 一些基础的概念和描述
        2. MM/m/n模型 - 马尔科夫
        3. M/G/1 - 非马尔科夫，无限队列容量
    * Chap3 通信网络服务的建模
    * Chap5的一点尾巴
    * Chap6图论的相关内容(在通信网络的field内与路由密集相关)，记住的
        * 几个anecdote-哥尼斯堡7桥；四色猜想
        * *树*是任意两个节点之间只有一条边的
            * *引申到最小生成树*
        * 欧拉图，能够走回来的
            * 充要条件：每个节点的**度(degree)都是偶数**

#### 组会
##### ReRAM组的主要Contribution
* 梳理了一下RRAM组的主要contribution(2013-2019)
    * 达成了从器件-组成逻辑结构-系统架构-算法的完整Workflow
    * 在EDA层面搭平台，设计仿真器，以替代spice
* RRAM非易失存储，高阻表示0，低阻表示1
* NVM - Non-Volatile Memory非易失存储
* 说到了一个新坑（据说是汪总现在在Stanford讲的）
    * 针对不同的平台通过NAS直接搜架构，是比较高层的一个说法
        * *不做对应设计，直接暴力搜。。。太狠了*

##### 曾C讲的关于FPGA虚拟化的一些Work
* 主要是对FPGA云服务器，单块FPGA做多任务复用的
    * 不用TDM那样效率低，实际用的还是空分复用
* 存在一个动态负载（Dynamic WorkLoad）的问题，不知道新的任务什么时候到来
* 主要任务-提高修改FPGA配置的速度
    * 完整重配置-生成bit-让EDA去选择如何布线去生成架构，太慢了-需要1day
    * 基于指令集的FPGA设计(DPU)需要10-100s
        * 目前的指令集，缺少对*多PE可控并行*，以及*动态重配置*（将配置的指令分为Static和Dynamic的，Static的只需要执行一次）的支持
> 感觉自己对基于指令集的FPGA设计理解不够深刻，也就是DPU是如何开发的，每一步做了什么，映射到这个问题上面是怎么更新

##### New Idea
* Multi-Precision CNN 对CNN来说不同层的敏感度是不一样的（可量化位数）

---

## 🤔自省🤔
* 认为自己不熟悉的领域过于万能，希望别的部分能够万能。（本质上还是一种程度上的推卸责任）
* 想得太往后，比如这一次的Semi-Supervised Learning，郭哥说的现在先想怎么把故事讲好
* 自己很容易追求短期内工作/学习获得的短暂成就感，但是没有及时巩固(或者所选择学习的东西不太有机会及时巩固)，比如Graph的那次
* 越来越感觉DL的某个领域到了这几年发展的论文有种比较排斥的感觉，不知道是超出了自己的认知范围还是为什么，我总是感觉他们在找水点，而没有靠谱的方案，反思一下自己认知里的“靠谱”是不是鼠目寸光了
* 所谓的去寻找硬件友好的算法，其实会排除掉有效东西

