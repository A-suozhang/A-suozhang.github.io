---
layout:     post                    # 使用的布局（不需要改）
title:      日知录          # 标题 
subtitle:   看看自己能够坚持多久       #副标题
date:       2048-01-01            # 时间
author:     tianchen                      # 作者
header-img:  img/4_1/roof1.jpg  #这篇文章标题背景图片  
catalog: true                       # 是否归档
tags:                               #标签
     - private
---

# 日知录

> 这个习俗大概来自于高中？FXB让我们记录下每天学到的东西，高中时候没有记住，不知道之后能不能记下来

### 2020-05-26 ~ 2020-06-15

* 写Rebuttal
* 做毕设PPT以及毕设论文
* 补充实验  

* 更新代码仓库
  * 编写并且通过Pytest
    * ```pip install pytest```
    * ```pytest -x ./tests```
    * 使用-s来用ipdb  
* 还有一个bug没解决……
* ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200615094544.png)

### 2020-05-25

* 继续修改论文格式
* 服务器居然被攻击了…
  * ```* * * * * /tmp/./systemd -lan 166.111.57.30:3333```\
  * 记住Ubuntu的默认弱密码用户要删掉  


### 2020-05-24

* 准备rebuttal开始跑实验
* 改毕设文章

### 2020-05-23

* NIZ键盘调整键程的方式
  * 右Fn+F7
* 写致谢填写一些内容
* 出rebuttal了开始准备


### 2020-05-22

* 冲完了第一版的毕设论文，晚上把致谢给写了并且开始看tflite的定点
* 为rebuttal而焦虑...

* 峰哥的工作：
  * 2 Subtask
    * 2d image 2 PC（估计深度）
    * 点云之间的变换关系

### 2020-05-21

* 论文相关内容
  * 论文的每一张标题都需要对应标题
    * 前后章节之间也需要一定的对应性
    * 点以下关键词
  * 章节的最终输出要有量化

* 组会 - 神经网络加速器
  * 通用模型 - 通过编译器产生指令集序列 - 用神经网路处理器(DPU)进行执行
  * 无需重构，DPU烧录到FPGA中
  * 处理器的架构和基本算子
    * 支持的算子 ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200521130518.png)
    * FPGA的SoC ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200521130553.png)
      * DPU在PL中，与PS通过AXI总线接口通信
    * DPU
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200521130841.png)
      * 控制
        * Instruction的读取等
      * 存储
        * Data Mover 主要是片内片外的存储
        * Memory Pool
      * 计算
        * Conv 以及类卷积操作
        * MISC 别的操作的混合
  * 核心是将不同的操作分配到不同的时钟，利用流水
  * Conv在1xPxMxN的并行度
    * 兼容性升级
      * Save
        * Upsampling - 复制元素
        * 行内补0 - 支持deConv
        * 修改前向的加法树，不做input-c维度的累加
      * Load  
        * 整行补0(Load实际不读数字，直接读0)
  * DSP特殊修改
    * 利用27x18的DSP(ZCU102)一个乘法器支持两次的乘法运算
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200521132018.png)
      * 由于8x8最大也只能达到15位，左移了18位多了
      * 剩余3bit是用作DSP的级联，利用DSP的乘法累加操作，有效节省了加法树的资源
        * 最多可以满足8个加法的补位
    * DSP还支持倍频
      * 主时钟100M，但是DSP可以跑到200M，通过乒乓输入2组数据
      * 这里涉及一个跨时钟域
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200521132400.png)
      * 排布整齐，便于保持时钟速率
  * 时分复用
    * 卷积核33时候，至少需要9个clk才能出下次结果，在这9个clk中，将上次结果串行输入加法树后的数据处理逻辑中，省8/9的逻辑资源
    * Pooling和elementwise sum同理
  * Instruction Scheduler
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200521132834.png)
    * 卷积(计算模块)和下一次的dataload模块可并行，但是会有时序依赖
    * 这个步骤编译器会完成 - 本质上是任务上把某个寄存器的值写入，下一个任务的开始读并且校验这个寄存器的值
    * 硬件约束： 由于一个硬件模块只能执行一个操作
    * 向量约束L datamover所引入的约束
  * DataMover
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200521133043.png)
    * 主要处理了边缘情况(比如不整除)，获得整齐的输入数据，来让conv的模块高效起来
    * 整理碎片化的数据并且
    * Extra - 双HP接口
      * 实际Xilinx是有两个PS与PL端的数据接口，但是编译器认为是只有一个，会认为产生硬件冲突
        * 需要硬件实现硬件依赖和逻辑收敛






### 2020-05-20

* 上午在画论文的图…还有一部分没能完成呢
* 下午出门了


### 2020-05-19

* debug de到崩溃
  * 增长了少许的C++知识：
    * stderr是错误流，可以将```FILE f* = stderr```
      * 需要import一个库

### 2020-05-18
* 填充内容，完成运算模块改进的内容填充
* 继续调试det api的bug


### 2020-05-17

* 填充内容，完成低比特训练部分的内容填充
* 继续调试Det api的bug

### 2020-05-16

* 搭起来了论文框架
* 把服务器上环境崩溃的bug给de了


### 2020-05-15

* [Core dump的相关内容以及解决办法](https://blog.csdn.net/liumiaocn/article/details/103826645)
  * 如果报错core dumped应该会生成一个内存的core快照文件可以gdb进去(for C)
  * 如果使用docker的话container必须要以privilidge启动在某些环境下才可以让core文件顺利产生


### 2020-05-07 - 2020-05-14

* 继续被配环境搞的自闭
* 在这个过程中熟悉了tf的相关机制
* 解决了安装问题，但是转模型问题没有解决


### 2020-04-29~2020-05-07

* 被tf安装搞得自闭的几天
  * 具体的内容放在LPCVC2020的post里阐述，对配环境多了一些心得
* 以及出去出了两次片，修图和采风能力有了一丢丢的提升
* 2020-05-07晚，熟悉docker，在公司服务器上开始使用
* (以及是不是应该开始准备毕设了)


### 2020-04-28

* 修图，学习配色
* 比赛相关内容
* Tflite文档阅读

### 2020-04-28

* 读ResNest论文，继续调实验
* 扫街，天台多人运动

### 2020-04-27

* 读两篇NAS文章
* 改bug，加semi的fix并且调试
* 开会讨论DetNAS

### 2020-04-26

* 调试之前代码的bug，增加实验，画图
* 扫街

### 2020-04-25
* 费了不少功夫更新了grouping方法
* 费了一些功夫调试之前的bug


### 2020-04-24

* 试了一下新的stoc，真的有效果了(为什么还是有点诡异)
* 相机到了，扫街

### 2020-04-23

* 组会
  * 曾哥FPGA虚拟化Survey
    * JetStream: 在RTL层面设计了一套Pcie的协议,在多FPGA之间直接互联
      * 本来Xilinx的Pcie core是管FPGA和CPU的交互的,通过手动设计一个FPGA的pcie的Controller
    * FRMR: Madreduce on MultiFPGA 2010
      * 本身用了算法的Server-Client的数据流结构,来用作多卡
    * Axel: 异构云系统对MapReduce加速 2010
      * 节点之间用infinitBand与网口进行点点之间的互联
      * 节点之内用Pcie
    * Enabling Flexible network fpga clusters in a heterogenous cloud data cenrer: FPGA17 Toronto Univ: 异构节点
      * 引入了一个MMU - 一层存储管理层
    * 下面是微软三篇,很solid,已经落地了 
    * (Microsoft0 - 2014ISCA) Catapult Project - Reconfigurable Fabric for Datacenter
      * 可以说是第一篇用FPGA用到云加速领域
      * 对Bing做ranking的加速
    * (Microsoft1 - 2018ISCA) BrainWave
      * "real-time AI" 一个全栈的system的介绍,对标TPU
    * (Microsoft2 - 2018NSDI) Azure Accelerated
      * SmartNIC
      * SDN 
* 更新了float scale for nics_pytorch
* stochastic rounding 还是有bug...

### 2020-04-22

* 调试Fix框子并且debug(debug费了不少功夫)
  * 添加了Stochastic Rounding和另一种Quantize(非全部定点)
* 出去扫该

### 2020-04-21

* 搞定了最终的Rebuttal
* debug Fix,开始写Fix的相关doc


### 2020-04-20

* 协助凯哥写rebuttal
* hook的用法加上了
* 帮飞哥整理continual learning相关的东西
* (相机调研(wu))


### 2020-04-19

* 整理了Fix的代码，跑了一些实验，感觉还需要一定的开发
* 下午和晚上写Rebuttal

### 2020-04-18

* 看了一下Challenge的内容，读一下NAS+Det的文章
* 看了几篇NAS+Det的文章,感觉核心在于如何设计SS，切入点还需要从小目标的角度下功夫，当前算法应该再比较多的维度有空间


### 2020-04-17

* 叛逃到了Zotero
* 整理了一下最近的文献
* 写采访稿子
* 把QQuantization的两篇的阅读给补上

* 小组会 - Class Imbalance 问题的处理
  * 衡量标准: 类别的最大样本数量/最小数量的
  * 不平衡的问题在Det中尤为明显，因为一张Img当中会出现多个Obj
  * 3中流派： 1. Data-Resampling 2. Cost-Sensitive Learning  3. Hybrid Method(Mixed - Metric/Transfer Learning Combined with the 2 former traditional method)
  * Over/Under-Sampleing: 过采样和欠采样来补偿(对多样本的类别少取，对少样本类别的生成填充)
    * 相对比较老，而且没有太多提升(甚至不会超过Random Sampling的效果)
    * SMOTE(Over-Sampling)：认为Random Sample中重复采样了少样本Class(Tail-Class)的样本，导致容易过拟合(特征维度的插值)
    * 将Head欠采样，构成和Tail类大小相匹配的几个Subset，多个子模型AdaBoost
  * Cost-Sensitive Learning
    * 也被称为Re-Weight的方法
    * 有一个Cost Matrix与Confusion Matrix(包含了FP/TP等)对应
      * 对FP等东西需要不同的Cost，比如医疗中FP就比FT代价要小很多
    * 分为两类
      * Hard-Sampling Mining: 更关注容易分类错误的样本(更Care样本)
        * Focal-Loss：(广泛用于One-Stage的Det)在问题中背景和前景不均衡
          * 给Loss加一个调节因子-×(1-p_t)^(N) 置信度大，说明判定的好，就降低它在学习中的Contribution，   
          * 存在潜在的问题是对于极端的样本(置信度趋于0)的样本给与了更多的关注-讲道理只要一个threshold就可以解决
        * Gradient Harmonized SSD - 直接抛弃极难的样本
          * 从梯度的观察(对收敛的CNN的梯度进行一个可视化，发现当梯度绝对值很大的时候，并不好)
          * 所以修改了一个矫正，对很大的梯度反而用一个相对小的
      * Class-Balance Loss: 不同类别赋予不同权重(更Care分布)
        * 以样本数量的倒数加权
  * Hybrid
    * Metric Learning： (Margin/Hinge Loss) 思想是让不同的样本更远，相似的样本更近
      * Triplet Learning: 找到最困难的三元组(Anchor/Positive/Negative,找与Anchor最远的Positive和最近的Negative)最小化和Postive和最大化Negative
        * (是否需要最?)
      * Learning Deep Representation for Imbalanced Classification
        * 5元组 - 类内K-means
      * 以上两个都用KNN的分类器做Classifier
      * BBN - Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition
        * 2Stage
        * CE/RS(Re-Sampling)/RW(Re-Weight) - 发现应该将分类器和特征提取器解耦合
    * Transfer-Learning：
      * 用Resampling获得一个平衡的集合做Finetune

---

* 小组会 - Survey of Adversarial Learning
  * (这部分只包含了对抗攻击，主要对CV展开)
  * Base 攻击方法：数据污染，模型窃取
  * 起源于Goodfellow的ICLR2014-Intriguing Properties of NN
  * 分类为white-box(Attacker已知网络的架构等信息)和black-box(Attacker只能够知道输出，所以不能用梯度回传的方式来做)
  * 一种最朴素的防御方法 - 直接将对抗样本直接加入到训练之中(其实没有实际解决问题)
    * 另外一种是Gradient-Masking，意思是对Grad-Outlier进行Mask
  * white-box
    * (----基于Gradient----)
    * Fast Gradient Sign Method - 不断向梯度变大的方向做扰动(对输入做一个w更新的反向操作，lr的位置替换成一个高斯扰动)
    * Iterative Fast Gradient Sign Method / BIM - 每次扰动的时候迭代，保证每次的扰动是真正有效的
    * ILLCM - (不是一个Targeted的攻击 - 并不指定错分类别)
      * 之前的是从最大置信度的引Grad并且反向更新，而这篇文章是用置信度最小的去正向更新(挺有意思)
    * Random-FGSM - 目的是跳出Gradient-Masking的那个Threshold
    * Deep-Fool：尽可能的寻找一个少的对抗扰动
      * 找到距离最短的决策边界，往那个方向扰动
    * JSMA - 利用网络的SaliencyMap进行攻击
      * 找到对最后输出影响大的像素点进行修改，以此为目的最小化修改像素点的个数
    * (----基于constrained optimization----)
    * L-BFGS： 以最小化扰动为目的做一个Constrained optimization(目的是扰动小不被人眼所察觉)
    * HOT/COLD: 一般的方法都是对Loss来进行操作，其利用Logit(且只在意correct class以及target class)
    * CW Attack: 
    * VAE Attach: 去攻击VAE
    * Universal Adversarial Perturbation: 对于所有输入都可以实用的同一种对抗方式
    * Adversarial Transformation Network (ATN)： 用GAN来生成对抗样本
  * BlackBox
    * 新训练一个网络，去学习出等效的网络，再Follow white-box
    * Camou： 针对Detector的攻击 - 以Score作为依据，由于3D渲染器Carla不可微分，引了一个网路来学这个映射
    * ZOO: zeroth order optimization
    * Natural Adversarial Attack: 主要对于NLP，认为前提是对抗样本一定需要符合正常的分布(不可察觉性)，用一个GAN
  * Physical Attack
    * 最朴素的直接打印出来
    * EOT(expectation over transformation) - 在真实世界中有光照等信息，与数字域有明显的区别
    * ShapeShifter - 不用满足人类的不可察觉性，而是希望做的尽量自然  



### 2020-04-16

* Wandering Day


### 2020-04-15

* 整理了NAS文章
* 读了Adaptive Residue Block文章
* 换硬盘装系统


### 2020-04-14

* 上午下午花了半天时间来整理GCN Survey并且完成了
* 下午整理了以下Online Learning的Proposal发给了泓神
* 中午讨论了Surgery
* 晚上把GNN Survey简单的更新到了post上

* GNN Survey
  * 0. Basics for Graph
    * Network
  * 1. Graph Representational Learning
  * 2. GNN
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200414135850.png)

### 2020-04-13

* 上午有事情
* Fix了毕设代码的DA部分，主要是Dataloader部分改成了合理的操作
* 阅读GraphHyperNet，构思合并


### 2020-04-12
* 阅读SMASH代码
  * 太痛苦了


### 2020-04-11

* 读Hypernet的实现
* 因为服务器挂了,所以毕设代码更新暂停
* 讨论了Rebuttal
* Surgery图
* 修了梯子



### 2020-04-10

* 读HyperNet文章与阅读代码
* 继续改DSA……Appendix又bug了，还有加一个作者Contribution
* 重构DA的训练
* 算法小组会 - GCN Survey
  * Graph Representation Learning - 图表示学习
    * 简单case: Shallow Encoder
    * 输入数据是把所有点给Concat起来
    * 一个相似性函数(Similarity Function) 内积
    * *缺陷*
      * Feature not taken into account  
      * 参数量大
    * DNN AdjacenMatrix和FeatureConcat起来(每对应的特征和连接在一行)
    * 对于更大数量的图，可以先进行一个**图采样**，不够就填0
  * GNN - Neighbourhood Aggregation
    * 几层就是聚合几度邻居的信息
    * 对应传统的CNN的Filter滑窗，认为是对Fiter的感受野中的内容做了一个聚合(Aggregation)
    * **聚合方式** - 最直接的方式就是取一个平均
    * 前向的方式
      * Activation(W*X+b)
      * X是前一层的聚合结果
    * 无监督的训练方式 - 随机游走等等 
      * 有监督/半监督的就是Gradient-based
  * GCN
    * 修改了Aggregator
    * 将bias去掉了，做了一个逐Neighbour的Normalization
  * GraphSage
    * Aggregator
    * stm是个啥
  * 其他子方向
    * 谱图(Spectral)的思想
      * 将特征的聚合看作一个矩阵乘法，对其进行基于某个基底的分解
      * 基底就对应着一个谱域，相当于在谱域上进行操作，学这个上的变换
      * 相当于在时域和频域设计滤波器
        * 但是空域对于图来说可能更有效
    * 深度问题： 一般1~2层，问题是梯度问题
      * 将历史信息加以保存，用GRU的方法(有一部分遗忘)
    * 子图的Embedding
      * hierarchical？
      * 从点的Embedding到子图的embedding
    * Attention-based Embedding
      * 有一个Multi-head Attention
    * 加速
      * Subampling - (在找邻居的过程中降采样)
      * FastGCN
      * S-GCN (考虑历史问题)
      * AS-GCN
    * Shortcut



### 2020-04-09

* 修改Arxiv DSA 
* 毕设中期答辩
  * 需要突出自己的方案与别人的方案的区别
  * 需要突出定点时候运算的分析
* 重构代码
  * 搭Semi的框子


### 2020-04-08
* 有点头疼，半摸半干
* 准备答辩


### 2020-04-07

* 主要时间花在改PPT和Surgery的图
* 更新了一下AwesomeNAS的文章梳理
* 更正了DSA的arxiv，Latex杀我


### 2020-04-06

* 上午更新并Clean了毕设代码
* 下午出去了
* 晚上和妃哥ck了一下PPT-GATES的东西
  

### 2020-04-05

* 创建了awesomeNAS的list，正在添加文件
* 整理DSA并且挂Arxiv，中间遇到了不少问题
  * Win下的Latex环境配置着实出了一些问题
  * arxiv网站上提交文件的时候，注意可以放压缩包，会自动展开文件结构，但是**不支持rar哦**
  * 还有就是填MetaINFO的时候abstract不要空行
  * 需要在tex文件开头加上```\outputpdf=1```
  * 然后还需要用pdflatex编译
  * 还需要加上bibtex编译生成的.bbl文件
* 注意pdflatex的编译需要好几次
  * 第一次产生main.aux给bibtex用
  * 第二次调用 ```bibtex.exe main```来生成.bbl
  * 接下来需要两次pdflatex调用，才可以让cite正常显示，否则是显示问号




### 2020-04-04

* 上午外出
* 下午一半时间外出，改了GATES文章，阅GATES文章
* 晚上改报告(改代码)
  * 整理my NAS list(如果有时间的话)

---

* [GATES]()
* 🔑 Key: 
  * NAS中的Predictor问题，提供一个更好的Encoder
* 🎓 Source
  * Arxiv
  * THU EE
* 🌱 Motivation: 
  * Current Encoder model topological information implicitly
  * 原本的gcn之类的encoder方式edges stand for notion of affinity, feature on node
  * View NN as Data-Processing Graph
* 💊 Methodology:
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200404200848.png)
  * 认为优点在于能够直接Handle Topological isomorphism,以及对Information Processing的建模
* 📐 Exps: 
  * Nb101/201上KD，NatK，PatK
* 💡 Ideas:
  * 相关文章NAO，用一个Encoder-Decoder来做
  * In the Kendall's Tau measure, all discordant pairs are treated equally
  * 其他指标(因为kendall tau其实考虑了很多poor arch的相对关系，对于NAS来说用处不大)
    * NatK： predict给出的K个中最好的实际rank
    * PatK： Predictor TopK在Gt TopK中的比例
  * Nb101 - 432k archs - Op on Node
  * Nb201 - 15625 - OP on Edge





### 2020-04-03

* 勋神对旷视的CV工作做了一个简单总结
* 把GATES文章改了一下
* 花了不少时间改PPT
* [Overcoming Multi-Model Forgetting in One-Shot NAS with DiversityMaximization](https://shiruipan.github.io/publication/cvpr-2020-zhang/)
  * Motiveation
    * 传统的OneShot方式认为Jointly Optimized Supernet Weights是最优的
    * 但是sequentially train archs with partially-shared weights会导致Catastrophic Forgetting
    * 文章核心把One-ShotNAS看成一个Continual Learning的问题(Constrained Optimzation,learning of current arch should not degrade previous much)
  * Method
    * NSAS(Search-based Architecture Selection) Loss Function 
    * Enforce the architectures inheriting weights from the supernet in current step perform better than last step
    * 如果累计的话要求会太高了，所以不是限定全部的Previous Arch，而是选择其中的一个Subset(对于如何选定这个Subset是假定Subset中的Arch要有Diversity-找到最大Diversity的过程就是所为的Novelty Search)
    * 实现约束的方式是加一个Soft Regularization




### 2020-04-02

* 达摩院的Learning in the frequency domain
  * 直接从RGB入手其实只考虑了一个部分，其实整个图像采集系统，前景会有一个DCT的encoder做频域压缩
  * 想法是Remove掉decode的时候IDCT的计算(原本是在CPU上做的)
  * 另外在频域可以做一个压缩，可以减少CPU和GPU之间的带宽 (DCT产生的Channel 8x8x3个只选比较有效的)
  * 从一开始DownSample的时候，从裸图片到224x224之间有比较大的信息损失

---

* [One-Shot Neural Architecture Search via Self-Evaluated Template Network](https://arxiv.org/abs/1910.05733)
  * 传统的Evluation慢，Shared Weights的方式选取去Evaluate的组件的时候是Random的，不够Instructive
  * 提出了一个SETN(Self Evaluated Template Network)
    * 一个Evaluator去预测有更低Valid Loss的架构(类似一个Predictor)
    * 一个模板Template网络去Shared Params,包含了所有的Candidate
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200402210522.png)
    * 看上去就是对Shared-weights加了一个Predictor作为Controller，去从一个所谓的Template网络中采样出子架构，Controller来决定怎么采(而不是随机采样)
  * N个Cell
    * 每个Cell中B个Block
    * 每个Block可能是4元组
  * Candidate Network 
    * Contain All candidate CNN in search space
    * train stochsticly - uniformly sample 1 candidate and only optimize its params
      * Optimize each with equal possibility
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200402212418.png)
      * I是input是纯随机Sample，F是Function，其中的order指的是再一个集合O中采样，其中f1的index一定要小于f2
    * Evaluator：
      * Encode one CNN candidate as a set of quadruples
      * 从categorical distribution sample出一个choice，用softmax normalized value作为vector值
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200402213049.png)
  * **Extra**
    * 指出有些Shared-Weights的方法会shared parameter with a learnable distribution of archs
      * 作者认为这样会有bias，因为相对lightweight的model会更快收敛，learnable distribution will bias to these model
      * “the Matthew effect” to refer that some quickly-converged candidates will get more chances  to be further optimized in some NAS algorithms


### 2020-04-01

* 听了一个ML for EDA的Talk
  * (感觉大部分时间都每太Catch)
  * 几个领域
    * DL for EDA
      * Active Learning
      * 等价于一个Object Det，输入的Synth信息，预测可能出现的Placement的Conjestion点
    * Dl Engine for EDA - 问题抽象，加速Placement问题的求解本身
      * 利用DL的框架 - 将Non-Linear Placement转化为Training
    * Tetsing的问题。
      * 传统上是给一堆Input Pattern，输出是一系列OutputPattern，效率低，所以需要
      * 输入是一个Netlist
* 继续写很多没有意义的多西……
* 改PPT，压缩内容
* 几个小点正好记录下来
  * Pareto Frontier
    * 考虑每个点有多维属性，如果某一个点的所有属性都存在一个点好于其，那么排除该点，最后剩下的点的分布
  * Bessel曲线取法：
    * 取两个共享某个端点的曲线，在其上各取一点，两条线段的比率相同，扫一个比率
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200401202038.jpg)



### 2020-03-31

* 花了不少时间来整理和修改PPT
* 以及写一些乱七八糟没啥意义的格式问题

### 2020-03-30

* 学习了郭哥的Report<高能效神经网络训练加速系统研究>
  * 背景时训练 (1W-2WDollar/kW) - 有限能耗更多性能时数据中心建立的根本 / 另外在端上我们也希望能够训练(通信/隐私)
    * 样本量10E6，推理加更新10E10，迭代次数1E4
  * 目前的网络训练框架：部署工具(通用化平台的优化需要硬件定制) / 软硬件接口
  * 核心时高能效
    * 能量拆解： 数据传输(数据量x访存次数x单次访存能耗)，计算能耗以及静态能耗(计算量x计算功耗)，静态能耗（静态功耗x时间-这点是为了限制时间）
    * 硬件架构： 定制缓存和并行计算 - 降低访存 / 减少相对于通用计算中冗余部分，减少静态功耗
    * 部署工具:  定制化
    * 软硬件接口： 设计自动化工具，指令集设计
    * 剪枝: 减少计算量和数据量/ 量化：减少单次访存能耗和单次计算能耗
  * 基于FPGA的推理加速器：基于HLS/基于TCL模板的 - 如何动态更新？
    * 基于指令集
      1. 量化：层间差距大，逐层量化(层间需要一个缩放因子，用2的幂次) 
      2. 硬件工作：(输入缓存-计算单元-输出缓存的三级流水线)
         * 缓存： 
         * 输出通路： 
      3. 指令集接口与调度模块
         * 粗粒度指令(LOAD/SAVE/CALC)
         * 在指令中插入依赖标签(dependency flag)，便于并行度(解决不太能够提前预测的问题)
         * 可配置的tiling形式，提供编译器的优化空间   
         * 指令排布，循环往复，复用每个iter中最后一个iter的数据(1-N,N-1)
         * 传输数据量建模
  * 访存操作相比于计算操作能耗更高，需要降低片外访存
    * 新型存储器见能够提供比SRAM更高效的
    * 利用RRAM进行权重缓存，主要对于访存进行优化
    * RRAM的存储密度更高，但是读写能耗和带宽都不足SRAM(所以我们需要降低读写次数)
    * 本工作中固定了硬件的并行度，探索缓存的设计方案
      * 累加缓存，降低读写次数
      * 单层的数据调度优化，难以利用大的片上缓存(高密度)，跨层调度
  * 神经网络训练加速器设计
      * 网络的训练中仍然存在依赖高尾款计算以及准确率降低的问题
      * 稀疏网络训练的工作
      * 训练过程的主要难度在于低位宽 - 梯度下降
        * 随着逐渐收敛，累加器的累加值会逐渐变小
      * 在反向时候，卷积核的变化较大(特征图的大小一直在变化)，导致了并行设计困难
      * 前向反向都采用8，梯度保留INT32
      * (片上)对稀疏矩阵转置访问 - 采用二维下标 / (片外)CSC的按列编码，CSB的编码方式(按块)
* 主要做的是思考了，并且基本完成了毕设中期的PPT


### 2020-03-29

* 与汪总的讨论
  * Motivation - SemiNAS
    * 架构确定的过程本身不需要那么多的数据
    * 比如实际问题中
  * 先上来说为啥，而不是从技术上出发
  * 类比可以到更大体量的Unsupervised的数据


### 2020-03-28

* Finished the [Semi-Supervised Digest](https://github.com/A-suozhang/WhatIveRead/blob/master/papers/SemiSupervisedLearning.md) 
* 思考和做PPT - HardwareTraining
1. Challenges (在线训练，而不是Deploy(不清楚rram会不会有这个问题)就是Motivation相关的一些问题)
  * 不知道是PIM所以是不是可以做到一些修正 / 感觉有一些问题也可以不care，因为实际上并不大可能完成所有任务
  * 相比于预先训练好再Apply，有何优势
  * Dataset的储存相对大量-对比于参数量来说
  * 在线的时候Label从哪里来？
2. 
  * Plain Training - Sparse-Training
  * Finetune Certain Layer (User/Domain Adaptation) - Transfer to a relative Small Problem
  * Semi-Supervised Learning(Unsupervised Learning)
  * Incremental/Continual Learning/MetaLearning
* 每个Field的展开点： 问题定义 / 可能的Motivation / 算法的思想(算法对硬件的要求) / 算法本身的成熟程度 / 
  

### 2020-03-27

* 找桐姐要FewShot Survey的PPT
* 需要开做和给PPT了
	* Finished SemiNAS PPT
* Read some more Semi-Supervised Paper

### 2020-03-26

* 组会
  * 1. 数据增强不变性的ReID
    * ReID任务：给定一个识别的行人图像，在视频中再次识别出该对象
    * 首先经过一个特征提取，
    * 更好的特征：类间不变性，类间差距性
      * 损失函数的设计：最小化变体(经过增强之后的新样本，希望它差距小) -- 实现方式KL散度(非负，最小值为0) / Euclidean Distance
      * 可以拓展到多个样本之间，而不是两个样本之间
      * 用在什么地方？
      * Combine是什么方式？
    * 做到了让决策边界更加具有区分度
    * 实际的问题在于有遮挡，侧身等多种情况 -- 可以看作数据增强
  * 2. VO(Visual Odometry)
    * 估计相机在相邻帧之间的移动
    * SLAM的及其他组件： VO / Pr(Place Recog)场景的识别 / LD(Loop Detection) - Relocalization(重定位）
    * End2End VO via Unsupervised Learning
      * 不需要额外的标注，算法快速迁移到新的场景，以及在线训练
      * 利用图像重建作为自监督的信号
      * 有两个网络，一个深度一个位姿态，联合训练。一个输出深度图，一个输入位姿态变化
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200326132634.png)
        * K为一个二维到三维的映射(相机坐标到真实世界坐标)
      * 防止遮挡，只用一段时间内比较好的重建误差作为监督信号来防止因为遮挡导致重建误差过大不能正常反映问题
* SysArch小组会
  * SpMM稀疏矩阵乘法的加速
  * PPoPP19： 用CSr的方式先压缩(但是CSR本身并不能预测每一行有多少元素，对实际的分配有问题)
  * HiPC20： 用COO的形式，列，行，元素3个3个的储存，比较Naive
* 会议纪要Han Cai. 学长

Q: 讨论问题：相关性的问题，OFA的架构的搜索和从头开始训练的相关性问题，对于Benchmark的构建来说，他人测试算法的时候，是否可能会实际找到了好的arch，但是因为OFA本身的原因出了问题；
A: 相当于设计的时候直接在OFA的SS里去找，而不是更加General的NAS搜索；可以加入一些Hardware相关的Objective(Latency/Energy Constraint)的情况下，去做搜索 (FLOPs,PeakMemoryConsump,Param)
Q: 对Pruning/Quantization的支持：
A: Pruning在搜Channel的时候更细粒度，相当于做了Channel Pruning，对Quantization来说还要Sample出Quantization Policy，对应出一个Acc.Table
A: APQ的做法，对于Quantization，直接用Quantize之后的模型来测试精度不准，需要用全精度的做对定点后的做一个Transfer去tune

1. 预计加大OFA的SS，加入支持ResNet，Dilation和Group_Num
2. 加入Hardware以及Multi-Objective的
3. 跑一些Baseline，Benchmark一下各种方法的
4. 最后加入Pruning+Quantization的Joint Optimization

Q: 是否需要找一些额外的硬件平台去做
A: 需要那个Hardware的Profiling，换到其他的硬件需要去搭
Q: 表示我们这边会做一些硬件Profling的接口的工作，DPU/TX2/RK33(ASIC Accel),MobileNet-V3的SE-Module目前还没有比较好的硬件实现方式
Q: 关于MixedPrecision，我们希望去做的Mixed Precision偏Hardware，HAQ是开源的，APQ准备开源
A: 混合精度这边是一个Joint Optimization; 同时搜索模型和架构
Q: 我们主要做的内容？
A: 搜集硬件上的LUT，以及之后的Benchmark以及不同的算法的Performance，我们需要做一些复现；最后的quantization的Cost会比较大，后面再说
对于线性性比较强的Hardware(FPGA)按照Block-wise做，GPU和CPU的case，可能需要Train一个Model来Predict Latency
Q: LatencyModule是怎么做的
A：是在Mobile上做的，拆解出Block，把每个Block在不同arch上的平均Latency作为当前Block的Latency(ProxylessNAS-目前来说是基于线性假设做的)，测试之后在FPGA上也是OK的，但是GPU和CPU上没有太符合线性性。目前的思想是直接搜集PairData，用MLP去预测。
A: (优先) ⭐还需要确定一下各个Hardware所需要的具体Space
A: (优先级在Hardware之后) Objective可能还是会加入一个arch的Transferability


* ~~汇总SemiNAS的思路~~
  * 总觉得这个问题是可以做的(就是还没有完全想清楚)
* ~~有一篇VAE和GAN的区别的post需要看~~



### 2020-03-25

* 听了一下戴导的图计算的Intro，内容颇多，值得整理，[slide保存一份](https://www.lanzous.com/ianasja)
  * 系统与架构性能提升的3条途径：
    * 工艺的进步
    * 异构多核加速(面对特应用场景进行加速)
    * 新器件(脱离冯诺依曼架构进行探索)
* 还有一个简单的自监督的[post](https://zhuanlan.zhihu.com/p/115101734)
  * Self-Supervised Learning & Contrastive Learning
  * 有提出新的方法MoCo(Kaiming的MomentumContrastt4Unsupervised)/CMC(Contrastive Multiview Coding)
  * 很多是数据增强的进步：MixMatch MoEx
  * 最基本的Label Smoothing常用
    * 为何不做一个基于类间相关性的Label Smoothing(感觉应该有人已经做过了但是我不知道)
      * 类似利用前几个epoch valid上的错分类的样本作为衡量类间相关性的指标，给出一个较为rough的大类，然后做Smoothing
      * 这个work不work就说明了Label Smoothing带来好处的原因是到底只是数学意义上的这个解空间更加平滑了还是知识意义上的
        * (其实这样就很类似KD了？只是SubOptimalKD)
  * 用到了CutMix(裁剪一部分做mix)+Context Decay(弱化背景)
* 看了一个post讲了一些和[自监督的领域发展有关的文章(https://zhuanlan.zhihu.com/p/102573476)
  * 最早的ContrastiveLoss，两个力一个拉近一个推远，有理有据
  * 主要还是MoCo，将这个问题作为一个Dictionary Learning的问题一个Momentum(Self-Ensemble)用来Smooth Training和维护dict



### 2020-03-24

* 推导了一下Gumble Softmax以及Reparamertization的方式
* 后来有一些系列的工作没有好好完成，值得反省，摸day，我的

### 2020-03-23

* 继续整理最终的GATES实验，新的图已经出来了
* 继续调研Active Learning

### 2020-03-22

* 整理gates实验的材料，还存在的问题
* 看了少量Active Learning的东西


### 2020-03-21
* 阅读整理于讨论Semi+NAS的问题
* 细读了SemiGAN和NAO
* 晚上讨论并获得了一个相对有效的办法


### 2020-03-20

* 讨论了下阶段工作的安排，会有一些NAS相关的活可能要展开
* 找到了一个比较好的种子，看起来和原来差不多，gates sample eff实验差不多了
* 阅读deconv相关的内容
* 梳理和思考Online Learning的场景 


### 2020-03-19

* 捋了一下主要Conv block的设计
* 组会讲了DSA的工作
* 下午brainstorm 了新的思路和梳理了目前NAS
	* SemiSupervised+NAS需要做一个新的思考
	* TransNAS好像不太有空间
* 继续调试实验，de retrain every stage的bug
  * 有了少数进展


### 2020-03-18

* 准备组会PPT
* 继续推进实验...还是没有完成的样子
* 整理TransNAS和FewShotNAS



### 2020-03-17

* 依旧还是在调gates的实验
* 又了一些进展推了一些开发
	* 当需要某个类的构造方法但是不在这一层分装的时候的Trick ```self._XXX_cls = XXX.XXX.__class__   self._XXX_cls(init_a, init_b)```
* 对于Semi-supervised和NAS的联系的思考


### 2020-03-12 ~ 2020-03-16

* 我去居然已经有这么多天没有记录了……
* 主要时间花在更新gates的实验
* 还有做了一个PPT来讲DSA
* 然后还有在更新NAS Reading List，调研Few Shot NAS
* 以及在做一些单页手写式的Digest的尝试
	* MCMC  - 更新在stack当中
  

### 2020-03-11

* 读一下gates附录
* 发现有之前的实验有一些cfg上的bug需要重跑
* 继续Survey TransNAS


### 2020-03-10

* 继续修改GATES实验
* 与龙老师交流，听取大佬讲课
* 读了几篇Transferable NAS的文章

---

### 2020-03-09


* ReRun GATES Exp
* 读了一些NAS Paper
* 修改并提交了DSA Supp


### 2020-03-08
* 整理DSA素材
	* 基本完成,还需要
	* res20 33% 多跑几个种子
	* 把ckpt中的epoch给pop了

### 2020-03-08

* NAS Surgery 分享
	* Sample Efficient NAS bt Learning Action Space
		* 重点不在Encoder
		* 二分Search Space，像是一个MultiStage，MoneteCarlo树搜索（MCTS
	* NAO做weightsharing和predictor
		* 经目前的实验的predictor没有shared weights本身的Correlation更高
	* NB101 的实验结果是更接近的架构会有更好的性能
		* predictor可以看作是对架构空间的一个插值
* Fewshot NAS Survey


### 2020-03-07

* 整理awnas的log
* 准备开始起admm
	* 再加上vgg和res8的结果
* 检查别人是不是也是选的最后几个epoch的最大值


### 2020-03-06

* 现在是2020-03-06-03:25 文章交了，总结一下几点心得吧
  * 现在自己写文章知道这句话应该写什么但是还是表达不好…
  * grammarly check
    * 一般最后grammarly查出来的： 1. 三单 2. the/a 3. 极少的搭配
    * the/a 加了没有check
    * 在提交之前统一一下一些东西的用法
  * margin是个小bitch，我还是不会调
  * 相对minor的点如果会引起误解建议省去，还不大会出现文章写不满，只有压不下来
  * 早点找**没有参与过工作的，没有领域背景的**同志看文章，会有新的发现(啊你method看不懂啊)
  * 不要吝啬强调，文章的重点就paraphrase反复的说
  * 改图的一些心得
    * 对称是好文明，不仅是位置对称，还有字体字号的对应
    * 配色，这个倒是可以展开讲，目前我的体会是，饱和度拉低，色系倒是可以稍微跨越一些
    * 字体大小放大！
    * 实际放到文中的图里的字大小，和ppt里字大小不完全相关联，有时候需要把图压扁或者拉长才是真正关键的，因为论文格式里页宽就这么多
* 下午做了两个ppt,过了几篇gates相关的文章
* 需要把admm调一下和整理做一下


### 2020-03-03~2020-03-05

* 改文章，改图
* 做了一个尝试，中间过程各层的敏感性变化不足，好像gg了
* 整理checkpoint


* 普遍字小，淡的太淡
* ABCD这边加上对topo group的介绍
* 突出强调我们的不一样，和优势，直接把例子指出来把

* DSA文章里需要tg加一个例子在heat图里也有
* DSA overview需要加文字！  
* DSA需要讲一下admm为何块，因为alpha更新相对不频繁

* 看两篇关于图的post
  * [1](http://tkipf.github.io/graph-convolutional-networks/)
  * [2](https://www.inference.vc/how-powerful-are-graph-convolutions-review-of-kipf-welling-2016-2/?nsukey=ZtX1rspwk7JGr2qtDKhm6nw9FjJY8ab8pFgcX0GAJy5I1EA%2BxHMoKUhZtRBwGUwbtEYN4EVh6BBCtuVcTCtzGUgYT%2BgTxGkNcE8Y3DXEiqy%2FXApMV0tzqV0NpGC9rtLS8c%2FI%2FyYiaUsyNZ1pvTSTrw%3D%3D)

* 改文章的一些点
  * contribution第二点少一个s  (👌)
  * contribution最后一个加数据  (👌)
  * rw第一段缩、(👌)
  * method第一段有一个partial符号 (👌)
  * method的第一句需要扩写
    * allocates sparsity via optimizing keep ratio A
    * （第一句我加的比较长，感觉caption大家一般注意不那么到）
  * method的DP需要改得更容易让人看懂
    * 用文字展开公式（比如说expect diff那边）
    * 



### 2020-02-29 ~ 2020-03-02

* 关于文章，最后需要check layer/component的用法！
  * 还有budget pruning
  * 还有pretrain
  * prune flow / process
  * search/searching
* intro的时候需不需要说一下structural pruning
* 属性的第一点放在上面作为总览
* intro中加一个analysis的ref
* pfs的特性为何能够做到需不需要分析，感觉在前面应该不大用分析，到了最后分析也可
* DP的图要改，不够清楚
* Fig. 和Sec.
* from scratch加紧contribution

* 表要改，加粗，换列
* 仔细检查的图
* 表里改成勾和空
* 需要有一个GCN，而我们处理的是一个GCN
* DSA fig2需要改一下

* 花了一整天时间画图


### 2020-02-28

* ML的一个foundation是train和val分布iid，但是DA本身不能满足这一点
* DA的方法，本身可能和Semi-supervised的setting有一些类似
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200228094921.png)
* H-deltaH-divergence
  * 源域上的训练误差（Train Loss），第二项（Discrepancy： 类似2-player game）表示数据(Feature)分布的差异，lambda表示adapbility(label关于数据的条件分布的差异)其意义为可适应性
  * 第三项的值相对较小，所以之前大家认为可以忽略
  * 可适配性的定义
    * 将2个domain合起来，两个域上test loss最小值的和
    * 两个域如果Label的差异很大，那么lambda就会变大
* DANN 
* CDAN（NIPS 2018）针对联合分布的适配
  * 将数据distribution和特征distribution
  * 将XY的tensor product分解为
  * Entropy-Conditioning
    * entropy本身是表示置信度的不确定度
    * 类似attention
    * 对不确定度大的赋予更大的权重，能够改进第三项
* Representation-free DA
  * 把feature固定住，第二项就无法控制了，转而
  * 利用对抗样本
    * 基于随机梯度上升，可以从NN中相对脆弱的部分中获得一张像素类似的很distinct的图
    * 通过生成对抗样本，充斥在两个domain之间，把它填补上
    * 有一个通过鼓励一致的项，VAT
* Transferability for NN representation
  * finetuning: 把大数据集上的训练结果，作为小数据集的初始化
  * 一个可解释性的问题了
  * 认为transfer的过程能够让泛化性能更好(Test Error - Train Error)和模型的复杂度紧密相关
    * 而finetune应该是让复杂度变小了
    * 参数的距离几乎和模型复杂度成正比（开始的weight和最后的weight模长的范数，可以认为是复杂度的度量，也就是看模型活动了多远，也就是模型容量）
  * 实验结果表明在imagenet上预训练，减小了weight移动的距离
    * 学界共识是相对平坦的局部极小值更接近最小值，而相对陡峭的
    * 一个example，黑色的是finetune的
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200228102454.png)
    * 利用Hessian矩阵的特征值分解可以衡量曲面的“平坦”程度
  * 每层的重要性(Layer Importance) 
    * 度量方式是其他层的参数固定住，换参数
    * finetune和初始化训练
    * imagenet的中间层变化大
      * 每个block的第一个residue layer的重要性最强
    * 更高层次的feature，可迁移性不如浅层的（老），而
    * finetune中固定第一层和最后一层
    * Lipschitiz值，梯度的模值
* 主流算法，对抗式的特征适配




### 2020-02-27

* todo
* 文字调整做了
* 我们的方法，折线图里是不是需要强调一下？
* 要更新的结果在表里更新了
* exp setup部分更新imagenet
* 需要在TG里加一个部分说明fig11是一个exp
* 减少空间：
  * properties换conclusion （meta-pruning）
  * RW-NAS 删除
  * method每个section讲了啥，删


* DSA文章修改
  * 摘要
    * ~~插一个continuous进去对比…~~
    * 第三点是不是删掉？
    * 加了最后一句表示作用（明显变好怎么表示…）
  * intro （看起来有点太长）
    * 加这一段，前半段说别人怎样，后半段说我们的efficient
      * 改图，放在中间一段里面说明别人是3-Stage，我们是1-Stage，省掉了很多东西
      * 下面一段的sensitivity as gradient merge进来
    * 特性和contribution还是只留一个…
      * 只写contribution然后把DSA放第一个
      * 感觉特性有点重点太多，就在表里提一嘴？放后面
  * Analysis里定量分析一下
    * 3个stage各要花多少时间(分开对比)
      * 300 epoch
      * searching
      * 150 epoch tune
    * 我们整个流程时间和第一个stage类似
* 需要做的工作
  * 首先梳理量化别的方法到底需要多久的搜索时间
  * 改图，把第一个flow chart丰富，我们的方法放到method那边去
  * 把intro中加入这个scratch的分析
  * related work中的NAS？
* 需要参考的文章
  * autocompress
  * amc
  * metapruning
  * pruning from scratch
  * dynamic pruning with feedback


### 2020-02-26

* 画图调实验的一整天
* 终于几乎把gates的sample eff实验做完了
* 开始构思如何修改dsa


### 2020-02-25

* 又是动了一天把一个sample eff的图搞定了，但是还是有问题
  * 需要加一个统一用evolutionary的图
* 还需要一个和baseline方法比的boxplot
  * 需要反复跑很长的epoch
* 还需要一个N的ablation的图
  * 是用acc还是用epochs
  * （看）


### 2020-02-24

* 需要做的事情
  1. 改昨天晚上画图的各种弱智问题： （👌）
     1.1 rank+1 改代码+表
     1.2 改回原先的两份图
     1.3 两个图统一一下风格(改原来那个把) 
     1.4 kendall's tau 
  2. 改好bug
  3. 整理np的一些用法
  4. 看一个[dual lagarange的Wiki](https://en.wikipedia.org/wiki/Augmented_Lagrangian_method)

* ```ssh -p 42222 -R 12222:localhost:<本地ipynb端口> 101.6.64.67```\

* debug-看结果-以及继续调sample eff
* 需要拿出一个箱图(不管是找到的epoch数,还是同样step找到的最好acc)
  * 还需要拿出一个acc的曲线图
* 有一个表示extrapolation的图
  * inner sample数目太大太小都不好


### 2020-02-23

* scatter 
* Precision at k: 预测的前k个有多少个在真实的前k个当中
  * random sample N个，取alpha*N个，
* N at K： 预测的前k个里最好的K个，其实是第几名 （Top10或者是100个里）
  * min N at K
  * max K at N 

---

* 在摘要和前面的图强调加快速度
* 在两个图内把需要跑多少次给标出来



### 2020-02-22

* SA又出bug了… （👌）
  * 搞了许久，又是代码的弱智错误
  * 以后出现不理解的错误还是早点看代码…
  * 📌该打印的东西全部打印出来，去debug
* 需要搞清楚cfg的sample100是怎么搞的 （👌）
  * 就是inner samples变大
  * 然后单纯的SA controller是steps来表示
* 目前比较好的一个结果 （👌）
  * ```awnas search examples/nasbench/gates/nasbench-101_gates_enum_100.yaml --train-dir ./tmp_ztc/test/1 --save-every 100 --seed 1234 --gpu 7```
* 改cfg （👌）
* 读intro （👌）
  * 读caption
* hai




### 2020-02-21

* 主要做了三件事
  * 被Evo和SA的bug卡住，目前还没有解决
    * evo的被解决了，是因为存mutation结果的时候用的还是老的matrix，被这个很低级的bug卡了一晚上
    * 训诫！一定要细看，再简单的地方都可能出错📌
  * 算是调好了DSA的from scratch部分的实验
  * 写了一个画图脚本，熟悉了一下re



### 2020-02-20

* SysArch组小组会
  * Rstream - 单机的，基于磁盘的，进行图挖掘的一个系统

* 需要搞清楚的问题
  1. 辨析一下几个流程(check一下具体是怎么做的)
     1.1) 离散搜索的过程，对应着SA和Evo
      * SA是先随机取一个点，然后在它的邻域(做一个random pertubation)产生一个新点(严格来说可以是N个，但是一般是1个)，做一次val，如果新点的acc大于老的，那么固定取新的，如果小于，以一定概率取新的，这个概率随着时间推进而不断变小。
      * Evo则是一开始先维持一个population(比如说大小为100)
  2. avoid的做法 - 就是但凡evaluator evaluate过的模块都不让controller最后采出来，但是inner controller可以采到
     * 这样就会出现既然inner controller是不知道自己采集的sample是否经过valid的，就可能采不足，如果出现了这样的情况，说明inner controller陷入了一个局部，所以我们就给它reinit(SA从一个新的随机点开始，Evo重新建立一个population) 
     * avoid了之后应该保持最高的best acc
  3. 目前的ratio*N的问题 - 防止enum陷入完全训练不动的情况


* 需要手算一下inner sample
* reward会下降的问题
  * 因为controller采的时候用的valid acc可能是一次训练的，但是最后调用test的可能是另外一次训练的
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200220191309.png)
* valid best 95.05
* 现在的cfg需要测一测是不是确实低了
  * local的cfg都不要用
* new_nasbench-101_gates_enumeratess_sample100.yaml
  * 相当于random sample更多个
  * ratio=100； 200个，20000个
  * ratio=100； 采100次


### 2020-02-19

* 调了一上午一个很神奇的bug…结果是别的地方出错了
* ```awnas search examples/nasbench/nasbench-101_gates_sa.yaml --train-dir ./ztc_tmp --save-every 1```
  * ```AWNAS_TEST_NASBENCH pytest  -x -s ./tests/test_nasbench.py```
* LaNAS的代码 (还没有开源)
* 新的实验，follow BOGCN
* sampling ratio
  * 随机sample 200*（N）个架构过predictor，
  * 加一个random的arg，给indice shuffle一下


* DSA-analysis
  1. Efficiency Analysis
  2. CIFAR10 - from scratch warmup & from pretrain
  3. 加imgnet的语言分析和散点
  4. (现有的) allocation分布
  * -----------------------------------------------
  * Topological grouping (x)
  * 正交性是只讲

* 开发
  * 加一个random (👌)
  * 加一个解析画图脚本
  * 加一个print best
    * 在controller的step中存储下所有的需要被保存的架构
    * 然后在sample中的eval mode中加入一个打印最佳

* 调实验
  1. 都跑predictor-based的gates换gcn和mlp，确定确实更好
  2. 调gates的enum的enum的ratio
  3. 最后把SA，Evo作为baseline都按照gates的最好方案跑一下 


### 2020-02-18

* 给awnas加上了一个enumerate功能待check
* 整理了DSA-imgent的结果和表格加了top5统计
* precision at k
  * 预测的前k个有多少个在真实的前k个
  * 真实的前k个
* btc - Built-In-Component


### 2020-02-17

* 读代码
  * 搞清楚流程
    1. trainer是一个simple trainer对象，需要走5(cfg: trainer-epoch)个epoch,一个epoch对应一个stage
    2. 每个epoch包含了200(cfg: trainer-controller_samples)个iter，表示controller会采样出200个架构
    3. 每个iter中调用_controller_update，这个函数中包括了rollouts=controller.sample()
       3.1 在这个sample过程中，第一次predictor还没有经过训练，不经过inner_controller直接从search space(Nasbench)中随机sample 
       3.2 这之后，predictor经过了第一轮的训练，需要采用inner_controller(基于predictor所给出的结果)来采样
    4. evaluator去evaluate这个200个rollout
       4.1 这里调用了evaluator.update(),但是在这个case里是None
    5. controller.step()
       5.1 内含了train_predictor()，调用了train_epoch，输入是架构，label是evaluator的输出,在这个case里是nasbench的查表
    6. 进入下一次iter  
* 需要问的问题
  * 现在应该是卡在那个while 1里面，就是跑第二个epoch，inner_controller开始sample的时候 / 
  * trainer的derive sample=5(?)
  * controller-steps? 训predictor一轮？
  * predictor train不用调？
  * controller-cfg
    * inner_samples_n: 1 (how many archs inner controler to sample every step) - 对应num_iter
    * inner_samples: 1 (每个inner step中sample多少个)
    * inner_steps: 50 (在num iter的loop内部)
    * inner_sample
  * inner controller走50个inner steps，每次sample出1(inner_samples)个架构，在这些架构中选inner_sample_n个架构，做为一个sampler的iteration的结果
  * test是从derive出的数目中进行测试的
  * 由于nasbench是对每个架构训练了3次，而api中的query是直接sample的是sample出的某一次，目前来说test acc是保证采的mean，然而val是max

* 需要fix
  * enumerate全部search space过一遍然后直接选topk
    * 一种很暴力的exploration，直接选topk
  * best rollout不给上次出现过的，但是新的
  * 设计新的multistage


### 2020-02-16

* 整理数据，改表改图
* 配了latex环境


---

* 晚上开会了解aw_nas
  * controller里面含了一个inner controller
  * inner sample N
    * inner step - inner controllerd多少个step
    * inner sample - 默认为1
  * simple.py
  *   controller_update
  * cfg写在init里
  * i_inner是inner controller走一步，sample，
    * inner sample n，inner controller走完一轮，
    * inner controller一轮就是大流程中的一个iter，第6行采多少个，就要iter走多少个
    * decided就是比如走到第5个step，有4个已经在inner controller确定需要给evaluator的

  * ReNAS - 1 stage evolutionary搜索
    * random sample是一种

  * 关键的todo
    * 利用multistage data
      * 目前多个stage是平一起的
      * 在step函数里
    * 全部forward一遍的



---

### 2020-02-15

* NAS Bench不属于Cell-based
  * Nasbench 101 和 201的操作不同，聚合在op前后，实际操作不同 F(a)+F(b) = F(a+b)
  * Exploration & Exploitation 问题
* 目前的multi-stage的问题
  * exploration的方法
  * 如何去从multi-stage选
    * finetune？
    * 按层选，第一个stage的选200个，再在这个里面用stage的选100
* 实验 (讨论)
  1. NASbench101 & 201 kendal tau
  ---
  3. single-stage的更多指标，对于predictor的衡量
     * N at Rank，Evo
  4. NAS 101/102 -Multi-stage衡量 - (Sample efficiency)
     * 有一些内部的东西需要去调 
* aw_nas实验
  * 首先是把实验跑起来(话说本来是应该加虚拟连接的但是我好像直接复制过来了)  （👌）
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200215171513.png)
    * 原来git clone可以clone目录…  然后再pip install .
  * conda env （👌）
  * 读代码 + NASBench201
    * pair-margin的意义是当pair不满足的时候，保证loss超过一个margin的增加
    * NASBench201
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200215183750.png)
      * 设计了一个相对小的Cell-based的search space，把15,000个网络架构都训练了一遍
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200215184002.png)
    * Kendal tau
      * 输入两个集合，从中pair-wise取值，当完全相关的时候为1
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200215190027.png)
  * 画两个图 （👌）
    * heatmap的配色

* 需要问的东西
  1. 输入数据是这样的吗？（描述一个cell） （👌）
  2. default dict的问题 
  3. train_ratio只有0.1?


### 2020-02-14

* [] - 对照着metapruning改热力图结果
  * 画了一版新的图，还需要改
* 看了一下rank，好像不是很好写


### 2020-02-13

* 整理调试结果，跑新的数据 （👌）
* 等eva8这边跑完之后，在上面改写amc的方式 （现在看起来好像可以搁置了）
* 改写文章
  1. 我感觉可以调整一下段落顺序，把budget pruning的关键问题并到上一段，然后再写regularization不能做到，过渡到iterative flow 是majority  （👌）  
  2. stage这个我换成outer loop和图对应上？ （👌）
  3. 说明一下discrete searching的  （👌）
  4. 图2确实是在第四部分第一次提，要么我先加一句 “fig2 is illustrated in Sec4.1”  （👌）
  5. 特点部分精简一下吧，有些contribution里没有的东西加到contribution里
* 补图，改图 （👌）
  * 上传DP的图，更新caption （👌）


### 2020-02-12

* 上午调试昨晚出的结果，res18到了66
* 上午还看了一些GNN的基础知识
* 下午改图画图，加内容
* 整理内容，看代码实现
  * AMC的流程是先sample出channel数目，reconstruct，然后load是原模型
  * finetune 时候是256， lr - 0.05


### 2020-02-08 ~ 2020-02-11

* 整理resnet imagenet baseline （👌）
* lr相关的一系列内容 （👌）
  * batch大了之后lr怎么调 [Google文章](https://openreview.net/pdf?id=B1Yy1BxCZ)
    * 文章说的是不要做lr decay，而是逐渐增大bs（好了我的显存不够你可以闭嘴了）
    * Decaying the learning rate is simulated annealing
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200211125206.png)
  * prune的时候到底要不要多调一倍的时间,pfs中 （👌）


### 2020-02-08 ~ 2020-02-10
* 回到DSA
  * 过一遍文字  (👌）
    * 公式1/2为啥是一样的
    * Mtehod中bi-level opt是什么
  * 改DP的图   (👌）
  * 回顾imagenet （👌）
    * 加mob
  * 记录服务器 （👌）
  * 改related works（👌）
  * recoverablity定义（👌）
  * 改图Workflow
    * 体现searching加速
    * 体现senstivity analysis融入 （👌）
    * budget model保留 （👌）
    * 强调train once （👌）
    * topological grouping放左边，不要显得每次都要跑 （👌）
  * 改图DP
    * B1，B2点出来 （👌）
  * dis-data-parallel （👌）
    * 之后找个时间把机理搞一下…

*  CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python main.py cfgs/prune/res18/imgnet/res18_plan1_scratch.yaml --save ./tmp_ztc/6 --gpu 0,1,2,3,4,5,6,7 --resume scripts/load_res/res18_pretrained.t7 --pretrain
*  CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node 8 main.py cfgs/prune/res18/imgnet/res18_finetune.yaml --save ./tmp_ztc/finetune_resnet --gpu 0,1,2,3,4,5,6,7 --resume scripts/load_res/res18_pretrained.t7 --pretrain --distributed
* TRUE: After Epoch 37, 53.706 %  (1.947993e+09/3.627123e+09) of FLOPs Remains;
        [1.000, 0.656, 0.594, 0.883, 0.672, 0.594, 1.000, 0.582, 0.516, 0.436, 0.561, 0.471]
  EXPECTED: After Epoch 37, 49.123 % (1.781739e+09/3.627123e+09) of FLOPs (Expected) Remains;
        [0.847, 0.653, 0.575, 0.889, 0.672, 0.596, 0.943, 0.582, 0.520, 0.435, 0.558, 0.472]


* 今天配置了两台服务器重复了两次，记录一下流程
  1. 修改ssh的config，并且更新备份
  2. ssh-copy-id 到新的服务器以及proxy，达成免密码登录
  3. 复制wsl备份的eva的bashrc
  4. 从wsl根目录复制miniconda以及global.tar.gz，还有.tmux.conf到服务器
  5. 安装miniconda
  6. 执行/opt...deviceQeury/ 激活nvidia
  7. 安装torch（1.3.1）和torchvision(0.4.2)以及ipython和pillow（0.6.1）
  8. 先从wsl的bak中复制source.list过去apt-update一下，然后安装cmake，gcc，g++
  9. 配置vim
  10. 配置git

* 改文章
  * 对于differentiable的初衷需要一个更明确简单的说法 （👌）
    * 得加个一两句让DP更加有reason，简单加一个by  （👌）
  * workflow放到最前面  （👌）
  * budget prune的必要性 （...）
  * 比时间，引用，定量
  * prune from scratch （👌）
  * 加载analysis
    1. 先看搜索时间，就比他们快（是最好）（当然可以再强调一句效果也比aif更好）
    2. 咱们方法也可以prune from scratch，而且和pretrain结果差不多，如果分析折合时间更好？
* 需要加的内容
  * 改intro，逻辑反过来 （👌）

---

### 2020-02-07

* 继续改了一天文章
* 终于投好了
* 准备开始新的工作…

---

### 2020-02-05

* 画了一天的图 + 改文章

---

### 2020-02-05

* 继续读文章改文章
* 写了一个计算的脚本，抄袭了一下飞哥的Hook用法
	* 在get_op.py当中
* 需要继续读NAS文章(后来没有读)
* 可能有时间自己买一个V2ray的梯子作为备用-搞好了
* 需要学习一个Grammarly怎么用（还是按照复制进去做把）
  
---

### 2020-02-04

* 改文章(我太弱了)
* 发掘了windows terminal的配置带劲

---

### 2020-02-03

* 画了DP的图
* 看了几篇NAS的文章
* quantize-aware training，具体化的内容

---

### 2020-02-02

* 写fixed point training的文章
* 晚上和汪总讨论GATES文章

---

### 2020-02-01

* Topology grouping check
  * PFEC做了 ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200201183345.png)
  * Rethink shortcut不剪 ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200201184934.png)
* train-val split 补充写一下
* 随机种子
* analysis里加topo grouping的
* Basis for guiding pruning with task loss gradient 缩句
  * 和前面呼应起来
* TG图改
* 加Heatmap

---


* DP的流程图-改
* related work改，是不是可以把思路写在intro里


### 2020-1-31

* 补充experiment文字，以及analysis文件
* 对思路上有一些新的想法，补充到了related work
  * 主要逻辑是抽象为两个问题，我们是解决第二个问题，和第一个问题可以联结
  * filter importance
    * 它本身的重要性由自身的参数决定
    * 以及它所处的位置
  * 有intra-layer的importance还有layer-wise importance
* 很多地方的表述不是很好，还需要修改
* Workflow里面感觉需要加一个train once  
* 

### 2020-1-30

* 整理最后一波实验数据
* 收集数据做表格，整理图

### 2020-1-29

* 理表格跑实验
* ~~本子的一个小部分~~
* DP的图准备
* 整理之前的图
  * 敏感度分析



### 2020-1-28

* 继续跑实验，扫baseline
* 调我们的方法
  * 对照FPGM看它的层间PruneRatio分布
  * 看FPGM和TNAS的代码有没有用什么骚技巧
* 发现了别人这个换随机种子，在cifar10上差了一个点   
* ~~整理Online Learning的素材~~

* 起个ray 75% 50% 33% 都跑一下 
  *  pretrain （tick）


### 2020-1-27

* 重新回来更新日记·
* 跑了两个实验，别的没有太多新的进展 

### 2020-1-20 ~ 2020-1-26

* 过年，继续调整res20以及res56上的性能（目前和SOTA还有一定的距离）
* 初始学习matplotlib

---

### 2020-01-19

* 继续扫点跑实验
* 熟悉了matplotlib
* 把post-train加上去

---

### 2020-01-18

* 回家也要干活啊...
* DAC 2020 Review
* Res18 从pretrain开始扫
* Grad的图画一下
* HeatMap画一下
* 看NAS的文章
	* 还没有完成



---

### 2019-01-14~2020-01-17

* 各种调实验，各种文章


---

### 2020-01-13

* ASPDAC

* 准备imagenet,调试bug

---

### 2020-01-09 ~ 2020-01-12

* 调代码,写文章,太忙了,没有记录
* 代码能力还是欠缺啊,需要好好补上

---

### 2020-01-08

* 考了软件无线电,本科期间的考试over
	* 准备开一个整理复习资料的repo,明早做一下把
* 整理以及跑Cifar10的Res18实验

---

### 2020-01-07

* 调好了新的bug
* 复习软件无线电

---

### 2020-01-06

* 复习遥测
* 跑实验，发现新的bug

---

### 2020-01-05

* 上午花了很久调好了第一个bug是因为根号没加eps
* 下午复习遥测

---

### 2020-01-04

* Ray的使用(怎么做实验)
	* 写在Eva里面把
* 晚上遇到了一个很神奇的问题

---

### 2020-1-3

* 上午的尝试做了很多无用功,很难
* 更新代码morphnet,晚上开始搭建实验环境

---

### 2020-1-2

* 组会
	* FPGA Virtualization
		* Key Points
			* 用户隔离度
			* 负载
		* FPGA Sharing On Cloud
			* MultiChip 1 Task
			* 1 FPGA 1 Task
			* Share 1 FPGA MultiTask
				* TDM 
				* LogicDM
		* NN Accel 卡住的其实是DDR Reading
			* 更好的数据利用via More Tasks
			* DDR & DSP
		* 这篇文章用了空分复用
			* 可以达到更好的性能隔离
		* Low Overhead Configuration
			* 在编译器中相对静态的固定,作为静态编译
			
* Few-Shot Learning Survey

* Problem Formulation
	* Exmaple: N-Class K-shot per class
	* Core Problem:
		* ML in Empirical-Risk-Minimization
		* 当样本数目少的时候，用了均值代替期望，fewshot的时候两者差异大

* Related Problems
	* Meta-Learning / Metric Learning
		* Meta-Teacher:
			* MAML-学习一个好的初始化
			* Meta-Learner，不用SGD
	* Zero-Shot Learning
		* 依赖Transfer，利用多模态的信息
	* DA
		* 作为FewShot的任务
* Taxonomy
	* Data
		* Augment Data
		* Semi-Supervised: Label Propogation
		* GAN : Generate new Data
		* Intro-Class Varation - Pair-2-Pair
		* Semantic Information(like zero-shot)
		* 从两个类别分别在Feature空间取出两tuple，若他们距离接近，就认为他们是同一种Transform，通过一个MLP学习这种Tansform
	* Model
		* Constaint By Prior
		* 限制搜索空间
		* Metric Learning
			* Learn to Embed and compare
			* Learn A Space, where intra-Class distance bigger, in-class distance smaller
				* [-2] Layer as the space
		* Siamese Net 2015 
			* 2 Network, Same Weight, 2 Input, Make Representation coming from same network nearer, vice versa
		* Matching Net
			* Think The Backbone should condition at The K-Shot
				* Bring The K-Shot into Backbone Training
				* People often only finetune the final classifier, cause use it to train the whole network will collapse
				* Use bi-LSTM and Attention to adjust the whole network 
		* ProtoNet
	* Algo (Meta-Learning)
		* 通过改变优化方法，来更好的得结果
		* Meta-Learning
			* Learn a better initialization
			* Learn a better optimizer
		* MAML(Model-Agnoistic Meta-Learning for fast adaptation)
		* LSTM-based Meta-Learner 
			* Epside Training : Like TV Series
				* IN RL: Train For Some Time, Save, Then Train
				* IN MAML: Train on train set for a few steps, Then Test on Valid to Get Guidance

---

### 2020-1-1

* 更新到新一年拉！
* 上午下午都在养病，新年新气象
* 晚上细理了Baseline，看了Netadapt的源码...我感觉它DidNothing，但是可以用这个开源代码过来直接做测试
* 发现了LeGR框架中对ShortCut有特殊的操作技巧
	* 需要好好看一下
* 晚上准备开始复习软无


---

### 2019-12-31

* 上午摸鱼+做PPT
* 下午讨论整理文章，做PPT，确定创新点
* 晚上摸鱼，准备过年，养病

---

### 2019-12-30

* 上午复习，下午考试
* 晚上需要做几件事情：
	* 洗澡洗衣服
	* 整理表格，PPT明早做吧
		* 还需要找适合我们的一些Baseline
		* 然后PPT
	* 写周报
	* 帮皇帝写傻逼经验




---

### 2019-12-29
* 上午整理资料+睡觉狗命
*　下午需要赶快复习无线电导航！
	* 还多复习了一点遥测遥感
* 继续早睡觉狗命

---

### 2019-12-28
* 上午写报告
*　下午更新了Lasso等一部分代码
	* 以后clean的代码需要好好记录一下
* 又复发了...



---

### 2019-12-27

* 上午Moday
* 下午更新代码,改了一部分
*　还准备把报告也写了


---

### 2019-12-26

* 生病,Moday
* 晚上爬起来把Mathematica用实验实现了一下
	* 报告DDL周日

---

### 2019-12-25

* 上午到下午看代码,改代码
* 花了一些时间调网络和vim的bug 
* push上去的代码里有个typo clmapp -- 改好了
* 需要请教的
	* ipdb怎么换行  -- from IPython import embed; embed()
	* list append这种丑陋的东西怎么换掉　-- List Comprehensino
	* pytorch	-- 忘了自己想要问啥
	* 目录保持一致性(有没有/忘记了给) -- os.path.join 

---

### 2019-12-24
* 上午上课
* 下午本科生开题交流,讨论NAS
* 晚上看BAR,对比文章,找Baseline

---

### 2019-12-23

* 上午捋了一下Mathematica，稍微理解了一下，读了一篇文章
* 下午上课
* 晚上Prune项目整理Baseline，以及Mathematica可视化
	* 完成了

---

### 2019-12-22

* 核心问题
	* 我们希望用Clf Loss来指导PruneRatio的变化(可导过去),以一定概率采每个Channel,且希望其求和的方差为PruneRaito*xChannel
		* 需要让PruneRatio可导
* 讨论和给出了一个看上去尚可的方案
* 在做数学分析的时候发现需要好好整一下Mathematica

---

### 2019-12-21

* 上午摸鱼
* 下午review了一下和我们关系最近的几篇文章
* 晚上继续思考灵魂问题...


---

### 2019-12-20

* 简单修改了一下昨天写的层,添加了param以及Channel Prune的方法
* 浏览ICLR2020的文章
	* 反思一下自己又有点走马观花了,没有一个很好很完善的记录,做一些弥补,需要浪费一些时间了
	* 后来补充了整理
* 周五汇报工作
* 感觉可能还有几个小问题 (以后的一些对Idea的问题也可以留在)
	* 1. 感觉还是不太能合理的说明对Ratio求导的需求,比如说训练出一个合适的PruneRatio和直接训练出一个Mask(AdaptivePrune),我觉得甚至后者可能更合理?还需要思考
		* 面向有明确budget的场合,但是比如说用Saliency的方法配合上ADMM是否可以也解决这样的问题?
	* 2. 不知道能不能work
		*　灵魂的问题
	* 3. 和Lottery连接的话?或许可以指导iterative获得lottery?(最朴素的找Lottery也是按照pruneratio去剪的)
		* 感觉关联也没有那么大,不知道是不是要蹭
	* 4. 现在我们的workflow是不是还是可受多种budget指导(不止是FLOPs)
		 * 我理解现在我们做constraint只有ADMM?(理论上确实还是可限制在限定范围之内进行调整)-我们需要找一种ADMM的合理建模
		 * 现在这种Flow的话,直接指导PruneRatio变化的只有Acc,是否是忽略了一个很直观的先验(就是Latency和energy对PruneRatio的正相关)
* 关于Lottery
	* 涉及这个Task的文章大多数都比较empirical的做一些analysis(比如泛化,应用到其他领域)
	* 它和我们的一个最大的不同就是这个sparsity是unstructured的
	* 由于这篇文章导致一些文章研究怎么在Train之前就直接获得这些子结构

---

### 2019-12-19

* 上午继续看了一些ADMM相关的内容,和check了一下ICLR2020目前的情况
* 下午回校,晚上算法组小组会听了nian松哥的非常solid的工作,牛逼
* 晚上准备给写那个层开个头,另外和飞哥讨论和讲了一下目前的思路,感觉还有点可行

---

### 2019-12-18

* 上午接待了一个老师，吹了一吹牛逼
* 下午做了一些文献调研，对GM做了一些理解
* 晚上和妃哥讨论，基本毙掉了第一个方案，确定采取第二个方案

---

### 2019-12-17

* 小组会　－　低比特训练
	* 用的方式： 用了一个Scale（浮点数）和一个Offset
	* 以及Stochatisc Rounding（根据两端量化点的距离来以一定概率进行舍入）
	* 数量级缩放，较大的数目用小范围缩放
	* 分组统计： Group-wise
	* 两种误差 1）截至误差(Clipping) 2）区间误差
	* 信息拓展
	* 非线性量化


* 上午持续阅读了几篇文章，下午进行讨论之后对于怎么把PruneRatio和Loss导过来有了一些想法
* 下午和妃哥对原来的Flow进行了一个讨论
  * 发现最难受的是NetAdapt提出了我们所想的DataFlow
  * 但是LP作为我们的新核心，展开有几个
    * 1. 减少收敛需要的步长
      * 其实需要知道的是convex拟合之后计算代价加多了多少
    * 2. Extrapolation是别人不会去尝试的一个点（但是其实大多数都会去建模硬件结构，强调不知道Hardware也可以）
    * 3. 正常的卷积应该怎么建模(前层？)
    * 4. 怎么少取一些点
* 几个分布的概念需要重申一下(自己的数学实在是tmd太差了)
  * Beta
    * 二维的Dirichlet分布
    * 二项分布（伯努利分布）的共轭分布(参数P和随机变量X变换位置)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191217202021.png)
  * Laplace
    * 尾巴比高斯分布更加平坦的分布，一阶高斯？
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191217201856.png)
  * Dirichlet
    * 多变量的Beta分布
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191217201827.png)
  * 伯努利
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191217201920.png)
  * Gamma分布
    * 等候时间之和

---

### 2019-12-16
* 需要做的事情,过文献
  * ~~ ECC & ADMM ~~
  * Lottery等推送里的几篇 (可能要拖到明天上午了)
  * Bayesian (Variational Dropout) 
    * ~~ 看来一点背景知识 ~~
* 晚上过了一遍代码结构
  * 太多了，太PRO了
* ADMM用到了Augmented Largange（增广拉格朗日）比一般的Lagrange Multiplier有更好的收敛性能
	* Frobineus Norm 对于矩阵的向量L2范数
* 今天下午还调试了一下cmder，配置到了好看一些
  * 发现了在win下Term比Ubuntu慢的核心原因是MacType渲染速度慢，跟不上刷屏
  * 但是不开MacType实在是太丑了


---

### 2019-12-15
* 其实今天没做什么事情?
* 下午按照汪老师意见更新了Quantize Reading List
* 妃哥带着捋了一下aw_nas的代码
  * 之后需要把这个给过了,自己能上手跑起来
* 讨论
  * Extend到一般的Conv,需要层间建模
    * 计算量不能接受
    * 这样独立性假设就没有了
  * 涛哥说的RL不compatible的问题
    * 有N个动作,能够采集无穷多个样本,但是反馈随机,所以无穷采方差会无穷
    * 很多动作,但是没有机会每个都选择,如何知道哪个动作最好?
    * 对于我们的Case其实应该是第二种,而这不是AMC中的Default Setting能够解决的
  * GP的问题(之后空的时候需要加深一下理解)
    * 提到的关于L2 regularization其实是暗含了一个分布高斯的假设的事情的推导
    * 以及Bayesian方法这几个是一个事情,需要找时间深入理解一下

---

### 2019-12-14
* 上午又无所事事了...其实还是做了个PPT的
* 下午和汪总开会，开完讨论了一下其实已经4点了
  * 需要在PPT的前面加上人名和时间
  * 需要把PPT的内容补充到网上(不一定)
  * 需要加入UCB和松哥的几篇文章阅读（今晚？）
  * 需要准备做实验（看起来需要拖延）
* 晚上读AMC和Related Papers



---

### 2019-12-13

* 首先睡过了一个上午(我的)
* 试验一下低比特Activation，
  * 实验结果已经更新到debug issue中
* 补充论文的结果，了解NAS，修改PPT准备和汪总讨论 
* 晚上讨论LPCVC的结果，有了一些Idea
  * 要读的文章还有很多...



---

### 2019-12-12

* Communication Lower-Bound For CNN Accelerator(HPCA 2020)
* 对ASIC做了一个分析
  * DianNao（ICT）- DRAM带来了绝大多功耗
  * Eyeriss （IBM）
* 复用
  * 输入，权重，SlidingWindow，输出复用（输出的部分和一直存在片上）
  * 7层循环，搜索空间相对还是比较大的（对于EDA的设计来说）
* Red-Blue-Pebble Game
  * 一个快内存一个慢内存（DRAM认为是无线大）
  * 算法模型是一个有向图，点表示数据，边表示数据依赖
* 卷积操作和简单矩阵乘法的区别在于： *卷积的可以认为将输入给Unfold了*
* 当前卷积加速器能耗主要在存储，这篇工作找了通信一个最小值
  * 输入和权重重用平衡，输入输出都是最多
* *总结来看好像每太听懂，反思自己对加速器设计方面也是浅尝辄止，没有完全搞清楚或者是完全走过这个流程*

---

* 晚上小组会赶了和讲了一个Quantize的PPT，大家提出了一些问题
  * ~~Intel那个bias Correction到底是怎么做的，以及前面的~~
  * ~~TTQ的正负WQ，是怎么实际算的，以及XNORNet这些网络前向到底有没有加Saling Factor，需要去看代码~~
  * **为啥要在FPGA上做训练这个灵魂问题**
  * ~~SAWB里面的]二阶量是怎么求的~~
  * ~~ 定Task Interval的那篇文章是怎么做的~~
  * ~~ TerGrad~~
  * 汪总说的需要添加的几篇文章
    * ~~HAQ~~
    * AMS

* LPCVC问题
  * 流程
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191213233110.png)
  * 第一 LearningCurve和**敏感度分析**
    * 我们需要做的是从敏感度分析得到的几个点（直接替换去测试）去拟合一条曲线，且说明和一个完全Finetune出来的真实曲线的相关性
    * 利用模型去加速敏感度分析，少从几个点得出曲线
    * 本质上是用一个不那么黑盒的模型去解决这个拟合关系，建模的是从testCurve到TrueCurve的泛化能力 
    * 做一个建模，让他generalize，可能不能generalize
      * 不同opertaor Type
      * 不同层
  * 第二
    * 
  * 假设
    * 1. 各层影响是独立且可加
    * 2. PruneAcc & True Acc 线性矫正
      * （如果改了Fit模块这个假设就不存在了）
    * *对于AMC来说不需要第一个假设，但是第二个假设用了PruneAccxFlops作为RLAgent的Reward，所以要求两者有相关性*
  * 与AMC的区别
    * 完全黑盒的解决：RL Agent从庞大的SearchSpace采样出一组PruneRate，Reward是Acc*Flops，整个流程完全解决了
  * Expandible
    * FitAcc
      * 离散点更准(SA-Sensitivity Analysis)
        * 改BN
        * 能否analytical分析
      * Fit过程中
        * PruneCurv本身拟合（离散到曲线）【HARD】
          * 是为了少取一些点，也就是更快
        * PruneCurve到TrueCurve的矫正模型 【HARD】
          * 是为了更准确
    * FitLatency
    * LP
      * 凸函数代替线性 （减少需要迭代的次数）
      * Acc/Latency可以交换
    * Finetune
      * Faster/DataFree
        * Distillation
    * Extrapolation
      * 扩大模型
  * Sparks
    * 可控：相当于在找一个Acc和Latency之间的平衡（TradeOff）但是AMC只能给出一个平横，不可控且不能说明最优
    * 

### 2019-12-11

* 本来准备读论文和做PPT的看来是没有办法完成了
  * 这个可能需要明天去做了
* 下午讨论了一下定点相关的一些东西,预计周末要和汪总约一次
* 把自己的BN嵌入了框子开始训练,调整超参并且记录了一些结果
* (诶我上午干啥了?哦,看码,我是脑残)
* 晚上配置环境,其实现在怎么转发端口没有搞清楚,需要再问一次
  * ~~有时间应该查一下auth_key的原理记录下来~~

---

### 2019-12-10

* 疯狂阅读论文的一天，对低比特训练这个领域稍微加深了一些理解
* 出了一个reading list，还可以，后续继续更新吧
* 晚上读以下nntopmodule的构成


---


### 2019-12-9

* 上课和尝试完成Van老师实验的一天，还需要拜托丁哥哥&HC大佬带飞
* 配置了以下jupyter themes激励了我使用jupyter

---

### 2019-12-8

* 早上起来改好了backprop
  * 原来是昨天一个地方的(x - mean)看成了mean,很愚蠢
* 下午调试好了新的backprop
* 晚上和妃哥交流了一下比较后期的思路
* 晚上写周报，代入训练了一下没什么问题



---

### 2019-12-7

* 大家讨论很久才发现了是为什么，我真是愚蠢（草）
  * 孙博nb
* 晚上整理，开启了debug笔记（以后也可以这样debug）
  * 还整理了一些Pytorch Tensor和autograd的知识
* 写了backprop,出了一些问题

---

### 2019-12-6

* 上午开始写自己的BN层 
* 前向没问题，后向有问题
  * 一个bug调一天

---

### 2019-12-5

* 组会 （RL-Related Autonomous Driving）

	* High Confidence Planning 
	* L2 Adas / L3 (2007) 城市框架下的无人驾驶 
	* 决策过程中真实的环境复杂
	* 目前Data-Driven的方法需要很多的数据量
	* 抽象的3个维度
	  * End2End - 从感知的信息（雷达，视觉等过来）直接做，不大可能
	  * 基于Dynamic Map - 已知目前环境中的各个对象是啥，在哪里
	  * 规则枚举 - 对每个任务抽象并累计(车道线，跟车，超车...)
	* 应用RL
	  * Monte-Carlo树搜索，粒子滤波
	  * High-Conf
		* 基础规则 + RL (如果原本规则好，或者RL没有好的时候，会选择传统的)
		* 依据置信度提高，相信基础规则还是RL的一个ratio
	  * RL对场景敏感
	* 场景
	  * Collision Avoid in Agrresive Policy (很多车系都在车道上飘逸)
		* 以及环岛的Case，一个⚪，四个入口
		* 原本模型 MObil

* 小组会
	* 离散空间的探索（不是supervised的问题，不需要最大似然估计，而是要最大似然估计附近的点）
	  * 也可以认为是离散空间的采样 
	* RL和Supervised的区别在于后者学表示，损失函数是一定的
	  * 而RL可以认为是一种损失函数需要我们自己去explore出来的一种
	* RL是一个先有蛋还是先有鸡的问题
	  * 鸡和蛋分别是policy和学习方法
	  * 可以有专家设计的好状态空间和action，可以帮助训练（对于一个新的任务，很难有好的action，state空间抽象的设计，目前一般借助专家设计 *也就是中午那个工作的contribution*）
	  * 有了一个好的学习方法可以更好的去explore这个状态空间

---

### 2019-12-4

* 上午苟命
* 下午和飞哥讨论了一下,还整理了一下昨天的对自己代码需要加的东西
* 学习了几个python的库
  * logging
  * click
  * shutil
  * build net
* 看了一篇定点训练的文章
  * 大概理解了merge BN的意义


---

### 2019-12-3

* 中午小组会讨论了自己的工作
  * 曾C给了一篇很类似的文章来参考 DAC2020
* 下午到半夜和妃哥调定点框子的bug
  * 还讨论了一些问题
    * 比如merge convBN
    * 比如定点的取RANGE方法
  * 有很多收获需要整理
  * 我好像写了好多弱智错误
    * **记住Conv-BN-RELU!!!**
    * 还有对AvergaePool其实用adaptive的更好

---

### 2019-12-2

* 早上上课以及看文章做PPT
* 晚上整理PPT，以及定点实验

---

### 2019-12-1

* 量化grad出现了bug...
* 仔细推导了一下backprop的反向传播规律(学到了不少)
* 晚上对计算模式进行了测试

---

### 2019-11-30

* 量化了grad
* 看猫去了.moday!)

---

### 2019-11-29

* 上午熟悉了一下正则的用法,For Future reference,希望下次能够记住
* 第若干次推理backprop,这次好像比较清楚了
* 晚上整理笔记和熟悉nics_fix框架,准备apply量化grad


---

### 2019-11-28

* 组会 - RRAM

	* 存内计算(Enabling Processing-In-Memory with Emerging NVM For Data-Intensive(数据密集) Application)
	* The Problem: von Neunmann Bottleneck
	  * 冯诺伊曼架构存储与计算分离，计算中很多时间花在数据搬运上
	  * 数据搬运的Energy开销大
	* （Near Memory Processing） / Processing In Memory
	  * 主要避免了数据搬运的开销
	* Matrix Operation -> Memrresistor Crossbar
	* 做的是deconv的加速
	  * deconv在GAN，FCN中用到的多
	  * 主要需要zero-padding来完成upsampling
	  * 需要做zero-skipping
	* 基于RRAM的异构CNN训练
	  * 由于RRAM本身精度有限，做不好（RRAM整出16比特都费劲）
	  * 用异构来解决
		* GPU做训练
		* RRAM做前向
		* 3D电路堆叠来传Activation
	  * 用到了pipeline

* 算法组会 
	* 学姐讲AAAI,思路基本上是为了增强模型的泛化能力,或者是防止过拟合.对所有feature的方差(最后fc之前的2048个node,对每个输入样本求方差))做一个Regularization,鼓励网络给出对样本方差小的特征
	* 感觉和CORAL的思路很类似
	  * 但是用res50做backbone干svhn也太...
	* 感觉其实没有和SOTA去比较(但是由于它不需要目标域的数据,所以尚可)
	* 主要是实验做的很好
	  * 给了一个热力图.热力图的思路就是针对每个类别最后的fc和2048个node之间的weight强弱表示热力,然后将最后的feature map上采样回到原图
	  * [请问注意力机制中生成的类似热力图或者柱状图是如何生成的？ - 论智的回答 - 知乎](https://www.zhihu.com/question/274926848/answer/473562723)
	  * 还对2-Moon给了一个图
	* 涛哥对SGD的解释感觉非常有意义
	  * 论文说到了SGLD(郎之万热力学方法的SGD)
		* 应对的是LR趋近0时候的情况(对应特定的问题)
	  * 假设full batch的模型参数更新,后面加了一个根号LR加权的高斯噪声项
		* 由于趋于0的时候,根号比线性衰减的慢
	  * 实际我们需要拟合的一个曲面是很平滑的,等价于做最大似然;在他的task中需要获得的是最大似然的附近的采样.最大似然的采样就等价于去拟合一个比较noisy的原来的平滑的曲线.而后面的这一项就是为了在这种情况下能够取得好的性能.
	  * 而小batchsize,就是等价于加上了这一项.
	* 还有就是relu这个东西的本质,可以理解为分段函数,分段数目越细,越可以特别好的拟合原函数
	  * 而L2正则通过让大多数relu去dead掉,也就是稀疏化,目的是让这个分段不那么细,不那么过拟合

---

* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191128134747.png)
  * 目前的网络大小
* 帮凯哥打杂...正好熟悉一下正则和python os...
* 需要搞清楚具体的bakcprop的计算behaviour以及hardware apply想`

---

### 2019-11-27

* 感恩飞哥把多卡的bug解决了,FGNB!
  * 顺便总结了下pytorch dataparallel的behaviour
* 现在基本上能拿出一版80%的8比特模型 (基本通关)
* 开始学习HLS,跟着官方教程走把...



---

### 2019-11-26

* 算法上的问题基本没有解决
* 找到了一个能work的场景,但是还是依赖于大的batch size
* 和飞哥讨论在调bug来着,还是没有解决...
* 和郭哥讨论一下,准备开始学hls
* 对于这东西的硬件设计开始思考了
* 下午还学习了一小下c++的feature
  * 类型转换
  * 引用与指针 - 为了支持运算符重载中传索引而产生
  * 重载 - 同一函数多种参数
  * 继承(虚继承很少有用到)
  * 虚函数 (为了防止派生类的某个方法不会被调用,所以需要将基类中的某个方法设置为虚,让编译器动态绑定到派生类的对象)
  * 纯虚函数-抽象类 (f=0,不能被实例化,只是定义接口,这个方法由派生类来实现))
  * 模板 - 相当于同一个方法/类,可以被多种数据类型调用



---


### 2019-11-25
* 又是调参的一天...
* 发现了很明显的一个问题－就是多卡的时候及时不改变任何东西但是训练会变得不稳
* 测试了一下多加了dataaug,没有很明显的改变
* 量化多卡的bug汇报了,目前还存在

* 间隙记录了一下DQN
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191126093301.png)

---

### 2019-11-24

* 写好了开题报告
* 做了一天的实验
  * 另外会炸可能是我用了logits?(这个非常合理)

#### 1124的奇妙冒险

* 起因在于早上发现自己把sgd的weightdecay从2e-4打成了4e-2
* 改正之后一直在调,结果发现效果还不如之前???
* 于是对为什么展开了思考－首先因为我把dropout去掉了,所以对算法来说还是比较有效

* 首先weightdecay是怎么做的
  * 很直接就是在参数更新的时候直接给梯度乘上一个系数(1-weightdecay也就是0.999多)
  * 所以不断迭代的话参数理论会一直变小
* 具体内容还是收录在另外一片博文里了




---

### 2019-11-23

* 做完了开题PPT
* 系统看了一下Q，感觉多了一些收获
* 需要手推一下Backprop（已经不知道是多少次了永远记不住呢）
* 开题word写好一部分了
* 需要修改申请表上的题目，拿快递，上网填申请




---

### 2019-11-22

* 和汪总交流之后
  * 首先把我们所解决的问题更明确的场景给提出来
  * 开头先把实验场景写了
  * 把我们方法的优点列出来
* 凯哥提到了sim2real的东西可以搞一下
* **需要改PPT**
  * 改好了PPT
* 做了一半北航开题的PPT
* 测试了1k Label的实验场景
  * 还没有达到我希望达到的点
* 纯定点训练掉了几个点，回头调一下
* 需要继续调研量化的方法

---

### 2019-11-21

* 看到了一篇将Semi引入到Transfer中的文章
  * 说实话单纯文章没太大contribution,但是我可以引
* 做了定点测试，有一些问题
  * 发现了原来的网络其实小了
  * 用student做test发现结果超级noisy，改成teacher稳定多了
  * 貌似对小lr来说，量化炸了？ 


* 组会

	* DAC准备投稿的内容
	  * 考神的一个spNN的工作,GPU上稀疏矩阵乘
	  * 一个RRAM的加密的工作

* 算法组会

	* Multi-Agent Communication in RL
	  
	* Category
	  * 隐式的通信：对环境作用或者式通过自身行为的变化
	  * 显示的通信
	* MultiStep-Mnist
	  * 两个Agent通信，每人获得一张图片，经过5步之后猜测，鼓励猜对数字
	* CommNet
	  * 每一层网络取所有在通信范围之内的agent，取一个平均过一个transform和自己的结果一起做下一层
	  * 设置了一些场景
		* 车过红绿灯
	* 灵活的局部通信
	  * Attention，独立于RL(DDPG)的训练之外
	  * 用Attention取判断该通信是否有value
	  * *减少了无效通信的需求*
	* 涛哥说的非常有道理
	  * Reinforcement做的是**已知奖励，找策略的问题**
	  * DL做的是对大量的数据做**表征学习**
	  * 两者compatible的点在于
		* RL有Policy Gradient能让策略变得可导
	  * 数据分布首先要平稳而且独立同分布
		* SGD是有前提的，偏离前提太远，会不work

	* Adversarial

	* ICLR2017 Goodfellow 《Adversarial Examples In Physical World》
	  * 产生三种数字域的对抗样本
		* Attacker Strategy （从梯度传播入手）
		  * 完全已知目标模型之后，去把输入图片依据传回来的梯度做一个传播
	  * 直接打印出来就能work
	  * 还提出了一个Destruction Rate作为评价指标
	  * 此外还给出了一个Lower Bound


	* CVPR 2018 - 3D的样本


	* 有一个哥们水了好几篇
	  * 先说对抗样本不鲁棒，对距离光照不是很稳定，对Detection无效，说前面 的对的很齐
		* 《NO Need To Worry about Adversarial Example in Detection》
	  * 再说我找到了一种
		* 《Adversarial Example That Fools Detectors》
		* 需要对场景有一个3D模型，生成一个Texture依据空间特征贴到




---

### 2019-11-20

* 做PPT的一天
* 整理了一下文件综述和ReadingList
* 约了汪总讨论

---

### 2019-11-19

* 测试了Warmup，没什么问题
* 准备测试定点训练，出现了一些小bug，还有一些实现上的问题需要咨询飞哥
  * **具体是怎么确定的，看了一眼Quantzie-Aware的东西**
  * fix建立net的时候，必须要自己一个模块一个模块去搭吗，比如我要做一个Res18的量化，需要自己搭一个吗
    * 可以去做Patch
  * 对于DataParallel怎么处理
    * 是可以做的，我目前姿势有问题
  * 我现在的case，需要对所有的样本做一个0.99x+0.01(x+1),是否仍然有效，会存在一个float赋值给到int的问题
    * 思考了一下每个weight其实是有一个buffer的，那个buffer其实是可以存储我转换之后的东西
    * 然后定点的过程设置成auto的话是会在前向的时候先遍历一遍所有的weight，找到最大之后往后退几位，定点Register并且走
* 另外一个就是剪枝
  * 有没有什么比较耐操的方法
    * 目前就是L1范数
    * 还有涛哥文章之前提过去寻找最远的L2范数
    * 之前文章也没有在FPGA上跑起来，做了一个软件的实验
  * 郭哥之前那篇文章里大概剪到一个什么地步？
* 一个非常关键的问题就是定点之后这个Self-Ensemble的效果可能没了！大部分都是设置为0.99
    * 也是刚刚发现，很难搞，但是是不是可以和郭哥文章里的weight buffer那种方式，多存一份，多用一个
    * 还有一个想到的就是图像压缩解码的方式能不能作为一种aug？(值得测试) - 其实损失会有些小把。。。
* 做PPT整合思路，约汪总

---

### 2019-11-18

* 养病
* 跑手续好像比较可行了
* 摸鱼Day

---

# 2019-11-16/17

* 草我好像知道昨天那个是为什么了...**我居然把Mask弄反了...**
  * 其实替换softmax到logit其实只是加了一个约束,防止太错误的样本影响性能
  * 原本其实是th越高,而把th以下的东西采纳了,我是傻卵
* 上午到中午都在复现这个新的实验
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191116131701.png)
  * 这段话我感觉还是比较关键的,transfer其实是一个很好的解决Semi-Supervised Learning的方法
* 当前有一个很搞怪的Bug
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191116191603.png)
  * 在SVHN实验的时候Loss有抖动,飞哥说应该是随机性相关的原因
    * 目前已经排除了Dataloader的问题(用最直接的Dataloader也会存在这个问题)
    * 难道是这个任务太难了?
* 晚上开始测试Office集
  * 发现也有毛刺
  * 认知上难道说是计算Logit的MSE炸了?

---

#　2019-11-15

* 上午调试SVHN的半监督学习环境,顺便把Cifar的Semi调通了(**感觉这个步骤非常关键啊!**)
* 下午阅读郭哥文章,构思下周讲一下
* 晚上摸鱼+开始做PPT
  * 被v2ray折磨好久

---

# 2019-11-14

* 组会 - 曾C讲了一下NAS

	* 将搜索空间看作一个有向无环图，每一个架构都可以看作一个子图
		* 需要一个评估标准（可能不仅是Accuracy，可能还有一些其他的）
	* **Search Space**
	  * Global Search Space - 首先是Block By Block的一个一个Op搜索
		* （这里是搜每个模块是不是用Conv或者Pool）
		* 同时还去探索有没有分支和Jump Connection(改变链接方式)
		  * 比较复杂比较多
	  * hardware基本都是Segment Based，就是一个Module一个module
		* 而另一种是Cell-Based固定好了每个Cell的结构
		* 而Block-By-Block是更加细粒度的
	* **怎么选择**
	  * 用Reinforcement Learning去做
		* 对一个Agent，Accuracy是
		* NASNet就用了Policy Gradient
	  * 用遗传进化算法去做
	  * 去缩短评估Acc的时间
		* 用替代模型（一般是ML，用高斯模型去大概地估计）
	  * OneShot的
	* **评价标准**
	  * 先少训一些Epoch，再排序
		* 后续工作提出要做动态的变化
	  * Learning Curve Extrapolation（外推）
	  * 权重继承与结构变化
		* 先有一个Warm-Up 
		* 可以说是利用了Weight的信息
	  * Oneshot一次只评估一个
		* 问题在于这个bias会比较大          
		* ProxylessNAS - path-level-binarization
	* 与Hardware结合-
	  * Constraint变多，比如加入Latency
		* *MNasNet* 第一个将Latency引入的工作
	  * 直接对多目标优化
		* 基于Pareto Optimal的 - 找到满足多目标（当多目标矛盾的时候，零和优化）找到那个最优的边缘
		* 一些work尝试去分解       
	* 不仅做Hardware-Aware，做与Co-Design
	  * 基于RL的NAS和HLS的FPGA加速相结合 - 白盒的Simulator
	  * *思考如何把两个东西更加紧密的结合起来*

* CORL会议

  * [链接](https://github.com/zoeyuchao/Conference_Minutes/blob/master/CoRL2019.md)
  
* 算法组会

	* 算法组会 - 对抗样本
	* 基于Adversal Example
	  * 比如叠加一个干扰，网络就不work了(垫一个分布)
	* Adversal Training
	  * 包含了生成和抵抗
		* 基于最大化Loss的角度从数学推理去寻找一个对抗样本的分布
	  * L-BFGS-Attack (一般针对二维图像)
		* 但是对于实际的三维的物体作为对抗样本，还需要考虑光照等因素，不是特别友好 - EOT(Expeatation Over Transformation)
	* **EOT**
	  * 寻找一个变换的集合T （这是对对抗样本加上了一些光照等的数据增强）- 这个T是一个三维到二维的映射
	  * 很数学的一些评价指标
	  * **最大的问题是解决了Render这一层次的问题，主要是很多render不可导，把这个东西给考虑进去了**
	* 黑盒和白盒子攻击
	  * 对模型本身的了解情况，白盒知道结构，并且能知道Gradient
	  * 有的是加入随机，将其变成灰盒，就是我得到的Gradient不一定准确
	* 目前玩法
	  * 1. 实践上的，Adversal Training，针对某种方式去产生训练样本s，Follow Gradient去攻击
	  * 2. 理论上去找到一种好的衡量网络鲁棒性的性能的方法，定义为对输入加上一个多小的扰动，能够让网络失效的期望的lower bound
		* 由于计算量的问题，难以做到对一些大的数据集和结构进行评估

---

* OFA - Once For All
  * Han Song，一个特别大的架构，包括了各种KernelSize和各种的Depth和各种Expansion
  * 7x7 - 5x5 -3x3之间是有weight Share的，扣中间一块过一个Transform（这个对每个channel是一样的，省了很多weight存储）
  * 训练一次，一个超大的，对所有Arch的Accuracy打表，到时候用用哪个硬件就直接选哪个Arch
  * 和一般的NAS从一个小的不断到大的

---

* GNN
  * 卷积
    * 基于空域 （Spatial） - 相当于对于每个点每次选择最近的K个值进去卷，本身不包含链接信息，但是选择点的过程包含了信息
    * 基于谱域的（Spectral） - 有一个所谓的傅里叶变换，就是对Adjacent Matrix或者是对Laplace矩阵做一个奇异值分解，相当于得到了一组正交基，对这组正交基变化一下，作为新的基地，进行一个变换，将原来的输入映射到一个新的域当中进行处理（怎么处理这里的卷积核也可不同）
  * GCN，就是相当于再原本计算的基础上加上乘一个邻接矩阵
    * 这样的好处在于图的计算是累进的，比如说定义一次运算为取交集的话，反复运算就变成求它的闭包
    * 这样每一次卷就可以让图的链接关系更深入一层
  * 牛逼的地方在于顺序不变性 - 对于一些具有旋转特性的样本网络的计算方式就导致它本身就是等价的
  * 拉普拉斯矩阵的意义
    * Laplace算子-求的是梯度的散度
      * 对于图来说：从该点射出的梯度，减去汇入该点的梯度
      * 与边的方向无关，用来描述无向图
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191114230547.png)
      * 其N个特征值都非负


---

### 2019-11-13

* 让整个代码跑了起来
  * 目前还在添加trick让其获得标称的效果
  * 目前还没有跑到,这个加th的方法好像卡主了?
* 看了新的论文 MixMatch,Semi-supervised的另外一个SOTA
* **Ablation study**
  * ```An ablation study typically refers to removing some “feature” of the model or algorithm, and seeing how that affects performance.``` 
  * 简单来说就是去掉某些Feature之后模型还work不work,**控制变量**
  * 根据奥卡姆剃刀,简单和复杂的方法都能解决问题,而简单的方法更可靠
* 看了几个Prunning的方法,似乎希望能够对我的问题起效果   

---

### 2019-11-12
* 摸的一天，狗命
* 上午读了UDA，感觉数据增强的方法还有空间
* 对于选切入点有了一些信心，Semi是一个比较好的方法
  * 可以改成Consistent Learning
* 仔细读了一下resnet的源码,大概知道了是个什么样子的组成(很惭愧啊之前都是脑瘫拿来主义)
* 让semi的代码几乎能跑起来,还缺了一些feature



---

### 2019-11-11

* 看到了一篇文章[THERE ARE MANY CONSISTENT EXPLANATIONS OF UNLABELED DATA: WHY YOU SHOULD AVERAGE]()
  * Cornell
  * ICLR2019
  * 针对原本Meanteacher类的Weight Average方法在优化方法上进行了修改，提出了fast-SWA(Stochastic Weight Averaging)对标SGD的一种算法
* 注册了ASPDAC
* Load Data方法调好了


---

### 2019-11-10

* 苟命
* 下午做完了并整理了office31以及imageCLEF的结果
  * Work的不是特别好...
* 测试了一下定点工具
  * 但是好像有bug?
* 晚上整理了一下现在的思路,准备和汪总交流一次
  * 下午思考了一下并且找了目前思路的点
* 并且看了一下meanTeacher的Code,准备Setup一下SemiSupervised场景下是不是work

---

### 2019-11-9

* Office31实现确实会有一些问题ＡＷＳＬ,主要是到Ａ这个过程点会很低
* 可以尝试imageCLEF
* 正在入门飞哥的定点工具
  * 和飞哥交流了一下,大概还是有一些收获的


---

### 2019-11-8

* 更新了数据集,整理了一下digits上的结果,基本也就是只能复现之前的结果,而且基本证明了vgg不work是因为train from scratch而网络太大的问题
* 准备好了imageCLEF和Office数据集
* 正在准备硬件部分的Proposal
* 
---

### 2019-11-7

* 上午考试
* 组会群里发了 [NN Benchmark](http://www.npubench.org/?cat=21)
  * 两张很有意思的图
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191107123504.png)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191107123526.png)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191107123546.png)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191107123627.png)
* 中午组会
  * DPU Strcuture
    * 组成
      * 计算阵列
        * 以MAC为主要组成
      * 片上存储 
        * 带宽大 （100GB/s）
        * 容量几十M
      * 片外
        * 可以很大，但带宽在10G
      * 控制逻辑
        * 时分服用
        * 固定的有限状态机
    * 工作点
      * 近存储计算(和NVM关系更大)
      * 如何选取并行度
      * 指令接口的设计
      * 近似(fc层的SVD分解)、
* TVM
  * 端到端的DL算法编译工具
    * unify heterogeneous  
    * 部署的实现方式和硬件相关，目前的方法基本基于硬件厂商的高性能库 
    * 手工优化成本高，移植性差
    * 并且每个框架对于每种硬件都有独立的编译优化
  * 生成一个中间表示层
  * 在计算图优化层面已经比较ok和生成硬件代码之间有一个Gap
    * Solu： 张量表达式的中间表达
  * 计算图的优化v
    * Op Fusion
  * 计算图层次？(是否与硬件相结合)
    * 在数据流图后又包了一层
    * **张量表达式**：类似一个placeholder，描述了不同数据流之间的依存关系
      * 以及对卷积计算中的展开与变化
        * 比Halide要多的 Memory Scope， thread co-operation之间等特征
  * 张量表达式之后
    * LLVM，OpenCL CUDA HLS等等
  * 现在还又AutoTVM
    * 上板之后再调
  * 对不同的Structure
    * CPU - Scalar
    * GPU - Vector
    * Accel - Tensor
    * 这样可以减小搜索空间
    * 我理解和OneAPI不一样的是
      * 根据平台的搜索空间缩小其实是再autoTVM那一环
      * 而OneAPI是在直接生成张量表达式这一环就做了的
  * 搜索的方法
    * 随机搜索，遗传算法
    * XGBoost
    * Meshgrid
  * 未来工作
    * 支持更多后端
    * 根据硬件特点，完善scheduler的搜索空间    

* 下午接着调算法,原本比较困难的Task好像还是没有特别好的解决
* 被一个问题卡了很久,在同一个Domain上teacher的性能比student差很多
  * 考虑了很多原因,最后发现是因为Train的时候没有让Teacher参与训练,导致Teacher的BN参数没有被更新(因为我copy的时候没有把BN的参数更新过去)
  * 暂且解决
* 现在看起来AdaBN是有一定作用的
  * 直接到新的域apply，掉到10%，但是用了它还有50%



---

### 2019-11-6

* 复习通信网络原理的一天；
* 继续思考算法怎么改

---

### 2019-11-5
* 小组会，加速器相关内容
  * MICRO，ISCA的几篇文章
  * 主线是做稀疏化的加速，大部分的操作是存一个bitmap，然后有很多种切入点
    * 有一些关于负载均衡的比较有意思（但是大部分还是放在软件层面去做的）
  * 还有一些其他的工作
    * 拆分矩阵省存储
      * 不同的运算顺序会导致计算复杂度不一样 （nx1）(1xm)(mx1)
        * 顺序算 mxn+mxm
        * 先算后两个m+n
      * 最后的结果VGG16 ImageNet上能压到5倍左右？
        * 孙博说正常剪枝能够压到10
    * 对每层内的参数做细粒度的量化位宽
      * 对每个组(group)取不同的量化
      * 做了一个统计发现40%左右的只需要4比特
      * 后续怎么做？
        * 自适应地去调整乘法器所需要的周期数
        * 如果利用了这个，那么就不能在位宽这个维度有并行度
    * 有一篇文章尝试榨干最后一点优化
      * 在用乘法器算8比特乘法的时候，采用[Booth编码](https://www.zhihu.com/question/37637775)去把0的乘法给跳过去(因为0乘什么都是0)
        * Booth算法把连1换成两个1，来减少逻辑资源使用(我寻思我们实际用的DSP啊？)可以减少延迟
        * 本质上是减少了二进制乘法中的部分和

* 和郭哥讨论了一下
  * Prunning可以放一下
  * 首先还是要把Task完成,可以做一个偏应用的
* 继续炼丹
  * 找到了一个稳定的点
  * 摸索中
* 在看飞哥的定点工具用法
  * 主要库 ```import nics_fix_pt as nfp```
  * nnf就等价与nn
    * ```import nics_fix_pt.nn_fix as nnf```
  * 对每个model要做一个```model.set_fix_method(fix_method)```
    * fix method有三种
      * FIX_AUTO/ FIX_FIX / FIX_NONE
  * 这样定义model
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191105211057.png)
  * ```net.fc1_fix_params['weight']['method']```
    * 两层都是dict,里面存着信息

---

### 2019-11-4

* 早上突然发现服务器登录不上了
  * 然后发现是因为我开了Tensrboard的端口转发导致登录不上
  * 所以以后不要吧thinkpad上的tensorboard开着回去
* 继续炼丹的一天
  * 用Tensorboard找了一些规律
  * 调整了一下东西,昙花一线了昨天没有解决的问题(但是还是没有本质解决)
* 签了个字

---
### 2019-11-3
* 今天是突破性炼丹的一天...
* 复现出了Self-Ensemble的一部分内容,但是仍然有几个Task没有完全搞定
* 现在最大的问题是**某些模型一开始训练的时候conf就很低,低到无法打破conf_thresh而导致一直很菜**
  * 目前还不太清楚怎么解决
* 发现的一个新点
  * 一开始训练warmup的阶段,由于还没有触摸到conf-thresh,所以说相当于只有source domain在work(思考了一下好像确实是和target domain没有关系的)
    * 那么这个阶段是否可以提前做好?
  * 如果这样可以的话,那之后可能可以做一个实验,需要取多少个TrainingSample来存下来来保持label的clean?
* 还有一个多卡的Bug还没有解决


---

### 2019-11-2
* 熊哥实验（糊弄了好久）
* 继续炼丹,继续搭实验环境
  * 发现前面的augmentation和一些预处理可以直接用Salad的东西

---

### 2019-11-1
* 手续很闹心
* 回来汇报工作
* 配置一下弱智环境(IDM貌似还是没有work)
* 稍微推进了一丢丢代码

---


### 2019-10-31
* 组会
  * RRAM相关的一个INtro
    * 忆阻器认为是一个单比特，通过加电压来Set和Reset
    * Cell/Wire - Wire/Cell 
* Multi-Label Few-Shot via Memory-Enhanced
  * Metric Learning
  * MultiLabel 一个图片内有多个物体
    * 本质上相当于做N个2分类
      * 用BCELoss
      * 本质上是一个2^N，用Pair的方式减低
      * 留一个memory
      * 从FeatureMap通过一个Fc映射到一个概率空间
        * 传统的方式是取一个argmax，这里是每个再过一个Sigmoid，看大小定True，False
      * Cosine Similarity（Pearson Correlation Coefficient）
  * Few-Shot 利用少量样本获得
    * Augmentation-Based
    * INitialized-Based
    * Metric Learning
      * 寻找一个合适的Embedding空间
    * 先从ManyShot的数据集Pretrain，然后只训Classifier
    * 有一个思想是去把新的样本去Pair


---

### 2019-10-30
* 干了一天
* 上午和下午沟通了一下Self-Ensemble这种方法
  * 感觉还比较可行
  * 主要时间花在看弱智代码上
    * 真的很难用...
* 晚上做PPT，更新了思路，准备明天讲

---

### 2019-10-29

* 汪总表示需要把故事先说好，更新PPT
  * 提炼出来一个更小的故事（确认一个点了）
* Caoyu 
* Online Adaptation For Intelligent Dyncamic Systems
  * Edge Inference(1Tops) - Cloud Inference 
    * Between those (无人驾驶汽车，飞机)
    * 所谓*Compact的Data-Centre*
    * 强调*实时性*
  * 强调了新数据的存在
    * 不需要From Scratch，但是需要在线调整
  * Brain-Inspired了...
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191029111711.png)
    * Related到Transfer，Reinforces & Continual
  * 从硬件角度
    * Hybrid Memory Arch
    * 一部分需要很快的调整
      * NVM（不写，只做Inference） & SRAM（读写都快，可写）
      * 再次强调了**实时性**
  * Conrinual Learning - Catastrophic Forgetting
    * Regularization
    * Memory-Replay (有神经学的背景)
  * Cumulative Learning
    * Incremental对于一个假设10分类的问题，一类一类学，这个其实不太make sense
    * 先在云端学9类，再学最后一类
    * 核心的区别是*Pretrain On Clod & Adaptation On Edge*
      * 很奇妙的比喻： 1岁的小孩啥都不会，过来一年全都会了
      * 放在云端计算，留给终端的计算小
      * PST
        * 做一个Important Sampling，去固化比较重要的（like Prunning）
          * 权重大小*梯度
      * 将其Apply到NVM
        * 首先第一轮就会有损失（量化损失）
          * （软）也是做了KD（相当于在量化的过程中引入KD去Finetune） （P17）
          * （硬） RSA，去训这个SRAM
    * NN的发展趋势
      * Synapse 多，Neuron少，更加Dense
      * 从Memory-Bound更深一层，是内部lattice 
  * 提问
    * 提到可能下一步工作在前面这个第一个Task怎么确定
    * KD都是Offline的
    * Training放在FPGA上
* 尝试去讲故事
  * 晚上读新的论文，看可行性


---


### 2019-10-28
* 炼丹的一天
* ~~顺利反向复现论文~~
  * 我真🥦
  * 接着做实验把
* ~~visDA的有一篇self-ensemble的文章可以看看~~
* 签字的问题需要找老师

---

### 2019-10-27
* 上午过来接着配系统装软件
  * ~~win下跳板登录好像有一些问题...~~
    * 是因为初次登录貌似要下载一些东西，但是服务器没有入网，所以卡住了
* ~~做熊哥PPT~~
* 接着尝试炼丹,写Finetune的代码
  * 写好了,明天实验
* 继续思考
* ~~这篇文章的所谓Adaptive BN?~~
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191027210537.png)
  * 没啥子鸟用

---

### 2019-10-26
* 没有打卡的一天...
* 上午和中午校庆活动
* 下午修电脑，晚上装系统   
  * 做了一半熊哥PPT
* **是最近最摸鱼的一天了，需要反省啊！😡**

---

### 2019-10-25

* FCCM - Online Learning
    * 1-6  / 
* 罗列了很多了，找一个比较小的点去展开
    * 我的思路还是在Hardware-Friendly的TL方法(或者说是UDA)
* 首先还是要想一下目前的方法怎么不Hardware-Friendly了
    * 肯定是有东西的，优先度不是特别高
* TODO:*尽快把算法给拿出来*
* 和Design无关的盲测的方法
    * 给HLS Debug - 反馈回来的Verilog不可读 
    * Pre-Sliicon : Logic，
    * Post： 电特性，
        * 复制一份进去，检错
* TODO: **尽快找一个可行的方案去干**
    * Async是想要获得一个比较好的分类器，训练了一个Labelling网络(Feature Extractor共享这个还是比较elegant)
      * 问题是训练方式不是很elegant
      * 或者说如果能work的话这个方法也不是不可
    * Semi证明维护一个数据集能更好
        * 前提是需要一个Acceptable的老师
        * 尝试下AdaBN能否解决这个问题
* ~~TODO:盖章的问题~~.
    * 颖姐那边能handle


---

### 2019-10-24
* 中午讲了一下PPT
    * 问题
        * 提出往Meta-Learning（学习如何去学习），不是很Feasible
        * 提出Teacher有了Student有什么用
            * 俺准备把Teacher也放终端
        * 场景:我还是踩着TL这个场景
    * *先把算法整出来才是最关键的*
        * 淦...
    * 算法上的Contribution在哪里
        * 凯哥提的，Semi文章第一个是堆了大量的数据，和那种不是特别一致
        * *看我的TrainingSet准备怎么构建了*
            * 单纯的拿置信度应该是不大行？
* TODO: 改PPT，炼丹，
    * ~~ Load一下ImageNet  ~~ 
        * 顺便搭一下ImageNet的训练环境 
            * 搭好了，但是...好像被磁盘读取卡了性能
              * 测试实际涉及和sda的读写,速度10kb/s
              * ~~LZZSCL...~~
              * 另外测试了一下我的/home目录底下
                * 看不到速度,读取速度也正常,没有和sda通信
              * *目前的推测是我们的home目录是一SSD,但是那个3T的玩意估计是个机械*
            * 要么是DataLoader的问题，要么是?
    * 看懂DAN的那个MMD是怎么弄的
        * (写个论文解读)
    * ~~远程Jupyter Notebook~~ 。
        * 出现了奇妙bug，不能从0.0.0.0启动jupyter
        * 对Tensorboard给搞定了！  
        * 同理Jupyter Notebook也解决了!
        * 方案放在EVA开发日记里了




---

### 2019-10-23

* 今天是炼丹的一天
* 又深入了解了一下pytorch的设计,还是有点东西
* ~~多卡非常爽~~
* 继续读了几篇文章,昨晚发现的这个online trasnfer的pruning有点东西,和我的主题很切合
* TODO: 继续炼丹
  * 还有看一下Data AUG和可视化怎么做
  * 接着研究代码
* 继续读文章,改PPT,准备和汪总的交流
* 文件还没有出,就很尴尬

---

### 2019-10-22
* 把无线电导航和通信网络补了（上午）
* 下午上课，跑了个餐卡手续
* 晚上接着配环境
    * 发现充钱之后我在服务器上不能上线了（很尼玛神奇）通过手动添加ip的方式上线了 
* 下午在配置WSL，这东西有点好使
  * 记在UbuntuSetUp一文中了

---

* 配置了Linux环境下通过跳板机直接访问目标机器
  * 一次ssh而不是两次
  * 主要参考了[这篇文章](https://blog.csdn.net/DiamondXiao/article/details/52474104)
  * 在.bashrc里面加上
  ``` bash
    alias eva="ssh zhaotianchen@101.6.64.144 -p 22 -o ProxyCommand='ssh -p 42222 zhaotianchen@101.6.64.67 -W %h:%p'"
    alias fpga="ssh ztc@fpga1.nics.cc -p 22 -o ProxyCommand='ssh -p 42222 zhaotianchen@101.6.64.67 -W %h:%p'"
  ``` 

* 按照上面的配置之后还需要再进行一次秘钥copy
  * ```ssh-copy-id  -i id_rsa.pub zhaotianchen@101.6.64.144 -p 22 -o ProxyCommand='ssh -p 42222 zhaotianchen@101.6.64.67 -W %h:%p'```
  * 说明从跳板机登录（2次）需要的秘钥和一次的需要是不一样的
  * fpga1.nics.cc -> 101.6.68.236(由于用ssh config文件这种方式登录的话不能用域名)



---

### 2019-10-21
* 上午看了几篇新的论文，和VisDA的比赛解决方案，发现多了一些可用的Trick，同时发现多了一些文章要读
  * 主要就是在Noisy Label下怎么取得比较好的效果
* 今天FAIR把Semi文章的模型开源了    
  * 但是代码没有开源
  * 在git上找到了一个人的复现代码，但是好像有一些不大Work，可以参考
* 下午上课，复习了一下无线电导航
* 中午和晚上办网络的手续（好狠）
  * 有一说一网很贵
  * TODO: 问一下凯哥怎么整训练数据
* 晚上配置eva0

* 网络实验
	* 正常时间可以用DIVI（这个不要钱，而且挺快的）不属于清华内网
		* 可以通过跳板机连接eva和各种东西
	* 如果用Tsinghua Secure，相当于连入了清华内网了，就可以直接通过ip地址连接eva了（而不需要通过跳板机）
	* eva需要上线
	  * 和wiki上不一样我只要进去调用eva_share目录下的Tunet-2018c启动了之后就直接可以联网了（而且还是外网）
	  * 运行之后理论上会一直占用这个Term，但是我CTRL-C强制退出之后连接没有终止
	* 当然每天要去充钱
	  * 冲10块，只能微信（因为理论上你在看到自服务界面的时候还没有进入清华内网）- 但是每天充钱好像必须首先在清华内网里（日）
	  * 所以说充钱也是需要在清华内网里面的（日）
	* 上线之后打开usereg的自服务可以看到eva的ip出现，并且开始跑流量了
	* 实际测试了一下，如果账户里没有钱了，是不能正常用服务器登录的
		* 但是可以传文件上去，目前利用Win里的MobaXterm证明是可以的，在服务器没有联网的情况下把数据传上去了
	* 第二天起身发现，我的网络在服务器上是连不上去的，只有通过手动添加ip上去，所幸这样的方式目前能work

---

* 遇到问题 1.其实和网络没有太大的关联
  > Release file for http://… is not valid yet (invalid for another xxd xxh xxmin xxs)
  * [这篇文章](https://www.cnblogs.com/outs/p/9706437.html) 据说是改一下系统时间
  * 这个问题过了一段时间自己消失了，很nb
    * （~~炼丹炉的自我修复？~~）
  * 第二天这个问题又出现了，修改至阿里的源，问题暂时消失`

---

* 配置一次性跳板机的登录，并且推送图形界面
  * Win：利用好MobaXTerm
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191021230929.png)
    * 按这个方式配置，可以直接上去，然后测试过可以推送图形界面

* VsCode Jupyter-Notebook Built-In的支持
  * 先命令行```Python: Interpreter```
  * 然后```Python：Create New Blank Jupyter```
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191022201033.png)
  * 很香，然而服务器端用不了，因为Remote上没有Python插件？





---

### 2019-10-20
* 上午改了下PPT，做了点作业，看到一篇有意思的文章[数学之美番外篇：平凡而又神奇的贝叶斯方法](http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/)

> 概率论只不过是把常识用数学公式表达了出来。    —拉普拉斯

* 贝叶斯方法，一种相当General的推理框架
    * 从*逆概率*的角度思考
        * 正思路：从一个已知内部黑白球个数的袋子里摸球，摸出不同球的概率
        * 逆思路：从我们已经摸出来的球的情况，分析袋子里球的分布
    * why？ 人的观测能力是有极限的 ~~我不做人了JOJO！~~ 
        * 对于上面的问题：*不太可能完全获得袋子里面球的情况*而只能通过“取球”这个过程观测之后的结果
    * 分析问题方法
        * 首先给出几种Hypothesis（这里可以理解为*猜测*）
        * 然后根据观测到的结果，计算特定猜测的*后验概率*，从而选择最“靠谱”的假设，进行了*最大后验估计*
            * 当这个过程不考虑先验知识的话，就是*最大似然估计* （贝叶斯方法比简单的最大似然就是多了一个这个*先验概率*）
            * 对于上面的场景，先验知识就是袋子里都是球，~~不可能摸出一个皮卡丘~~
                * 而对于Bigger Picture来说，最大后验的事件的先验概率可能很小
                * 当我们实在没有先验信息的时候（在我们看来先验就是一个均匀分布）这时候只能用最大似然
                * 这里也是统计学家和贝叶斯学派的
                    * 统计学家：Let The Data Talk Itself
                    * 贝叶斯： 数据本身就有偏差
                * 一个有趣的例子 - 树后面有几个箱子
                    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191020110240.png)
                    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191020110312.png)
                    * 先验告诉我们两个箱子不大可能，因为两个箱子刚好一样颜色一样高概率比较小
                    * 但是这样的先验是否靠谱？这两个箱子会不会是同一批？    
            * 对于连续的情况，就是计算*PDF-概率密度函数*
    * 简单的贝叶斯公式
     > P(B|A) = P(AB) / P(A)
    * Example
        1. ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191020105057.png)
        2. 拼写纠正问题 thew被修改成什么

> 如果两个理论具有相似的解释力度，那么优先选择那个更简单的

* 谈及奥卡姆剃刀
    * 比如*Overfitting*的模型，将一些观测的误差，都尝试去解释
    * *贝叶斯奥卡姆剃刀*
        * 修正我们上面提到的先验出问题的问题？
        * 如果一个先验导致我们拟合的模型更加复杂
        * 相当于*奥卡姆剃刀原则*也是一种先验？

* EM算法
    * EM聚类，先验知识是数据一般按照*正态分布*
* 最大似然与二乘拟合  
    * 直线给出的是相对最靠谱的直线，而偏移的被认为是噪声
* 朴素贝叶斯方法
    * 条件独立假设：激进的认为条件概率竖线右边的各个事件是独立的
    * 为什么靠谱？
        * 讲道理是一定有关联不可能独立的
        * 有[前人帮我们证明了这些关联可以相互抵消](http://www.cs.unb.ca/profs/hzhang/publications/FLAIRS04ZhangH.pdf)

---

* 下午跑了修理，还没解决
* 下午修改发给汪总的PPT
    * 这个东西和incremental的联系
        * 充分利用数据，持续做训练，提升性能
    * 避免Overfitting
* TODO: 打印毕设需要的文件，约汪总一次线下
    * 还需要解决上网的问题，汪总回复之后问一下子把
      * 给颖姐发了邮件，等着回复吧...
    * ~~问一下凯哥是不是可以不存明文（可以存在cfg文件里面）~~
      * GG，看来必须自己搞一个账号了

---

### 2019-10-19
* 上午摸🐟+修电脑+空想是否思路有修改空间
* 下午读论文，改PPT
* 把Prim给做了
* 晚上给郭哥讲了一下
    * 看上去还比较feasible
    * ~~需要把基础知识部分改进一下~~
    * ❔考虑哪里可以hardware-friendly...      
        * 一个是训练集的构建方式

---

### 2019-10-18
* 上午整理思路做PPT
* 下午给雷老师讲PPT，整理论文阅读Post
    * 提的一个比较关键的问题是怎么个Hardware-Friendly
* 晚上补充文章和思路
    * 重新Review了一下TL的DataSet，还是有一定效果的
    * 接下来改一下PPT发给汪总把


---

### 2019-10-17
 
* 组会
	* RL在实际应用中获取对应平台的新数据
	* 搭建仿真器来代替在实际场景中训练
		* 快，成本低，操作空间更大
		* 仿真器有抽象/非抽象(更难)
		* 仿真器的粗粒度和细粒度不一，且不同精度之间不能直接迁移(分布不一样)
		* 在类似*自动驾驶*等实际场景成本高的情况下
	* 以多车避障为背景，构建一个仿真器
		* 局部最优-不动了就
		* 用激光雷达扫周围的东西
	* 涛哥的Work把高低成本的仿真器给结合起来了
		* 对于一个局部子问题上用低成本的搜索可行策略，并且传递回高层次仿真器，类似一个“专家”Advice，或者说是“攻略”
	* 重新讲了一遍RL基础（挺有价值的）
	* 仿真场景
		* 有的时候很难遍历
		* 一个经典的N chains问题，可以向左或者右，左可以+1，右走到尽头再向右会获得很多
		* 小车坡度的问题，向右开不上去，需要向左先走一段再向右
		* Multi-Bandit 多个老虎机,某个老虎机的P很高，两种策略1.先对每个做一个sample，选最好的，玩到死 2. 去趋向效果更好的，偶尔也试一次效率差的（这个概率如何选择？）
			* 后验采样Thompson Sampling-不是Greedy的对每个分布去均值，而是从分布中采样，因而对于劣势的分布方差大的化也可能被认为是一个好方法
	* 一个Work是在NN都SGD Framework下去找

* Sensetime 宣讲
	* 一个港中文的老师 - 王晓刚
	* 演讲的标题是工业界落地的
	* 整了个自己的计算平台Parrots
		* 多卡的一个操作
	* On Hardware 软硬结合，算法和传感器以及芯片的结合，创新点
		* 提到的是硬件背景
	* 工业布局
		* 智慧城市
			* 大规模的人脸识别；
				* Smart Locker
				* SenseID
			* 跨摄像头的视觉追踪
			* 3D
				* 人脸的建模与特征点（AR）
				* Vtuber(雾)
			* AR Navigation
	* 干货，招人相关

* Tusimple宣讲

	* 找了货运这样一个相对更加合理的场景  
	* 技术
		1. 感知 (主要用Vision)-卡车紧急刹车距离会比实际长，需要感知更远(Lidar)
			* 直接
			* 融合： 统一的表示，融合
				* *?时间上的Alignment*
				* 需要将图像从2D-3D,ill-posed,需要额外的辅助信息
				* 雷达的精度实际还是比较差，虽然能够直接获得速度（via 多普勒效应）
			* 1km的感知Demo
				* 一个激光雷达80m左右
				* 短距以及长焦的摄像头
		2. 定位
			* 卫星惯导-可行性不够
			* 摄像头：信息丰富，冗余而且不直接
			* 本质在于*匹配*
				* 与之前已经有的先验做匹配（也就是和实际的地图做匹配）
				* 绝对与相对相结合
		3. 路径规划
		4. 控制
	* 工程
		1. 车载系统
			* 模块的调度
			* 异构平台支持
		2. 仿真平台-用于集成测试
		3. 基础设施
			* 大规模计算平台
		4. 硬件设备
			* 做自己的摄像头
	* *？硬件平台*
	* 广告
	* 汽车不是刚需
	* 5G做云端运算不是特别靠谱
	* 雨天等复杂环境

---

### 2019-10-16
* 上午上课并且把银行卡的问题给解决了
* 中午整理了一下子装备哈
*  ~~等具体方案出来之后先和郭哥碰一下（大概周五左右） 约了周六下午 ~~   
    * ~~ 顺便问一下是不是需要把几个思路都放在里面  ~~  
    * 周末把PPT改好给汪总发过去
* 目前暂时的方案还是以Online Training为一个核心话题点，展开有大概3个思路，都可以Dig Deep
    1. Semi-Supervised
    2. Transfer
    3. Class Imbalance

---

### 2019-10-15
* 上午重新装Ubuntu...
    * 被代理卡了好久...
    * 搞定了ssh显示图形界面

* 组会
	* 讲了一下Semi的东西
		* 和云端的区分还是比较难，貌似只有*隐私问题*
			* 作为Online training会有一定的需求
			* 这个WorkFlow对应着一种Framework可能可行
		* 数据集维护，可以存一段时间  
			* 理论上只要有比较好的新的数据就可以了
			* 数据集的体量是多少？
				* 目前取得比较好的效果是10x原来数据集大小的样子（对于ImageNet来说我们的实验环境难以接受了）
		* 单纯的Classification提点数
			1. 实现起来不太可能，存储量太大了（这个Training一定是一个企业级的活，我自己做一定不能够这么做）
				* 除非换一个比较小的任务
			2. 本身只是为了提高一点点数，用处不是那么大
			* **往Transfer走相对会更有意义一些，需要深入思考和深入了解一下Transfer Learning**
		* 确实Online Training 梯度也会有精度损失，会不会产生影响
		* **Class Imbalance**也确实是一个需要解决的问题
			* TODO: 约意如神聊一下
		* 关于**Online Learning**
			* 是一个肯定存在需求的方向
				* 但其实还是取决与这个Online的场景能不能学到所谓"新的知识"
					1. 按照semi的workflow是完全没有的，还是原来的东西
					2. 按照Transfer的方案，其实是去后训一个Classifier
						* 目前看来最Promising的一个⭐
					3. 能做到辨识新的东西
						* 需要一个Incremental了，目前的算法感觉不是特别靠谱
			* 目前来说很多研究感觉*实验设计都不太考虑实际应用场景，很多都往所谓AI的“学习能力”在做，不是特别和硬件实现相契合关契合*
				* 说白了就是Training的这个Workflow还没有定论，甚至都没有人去解决Label的问题，如果我们最后的目标是硬件实现或者这加速的化，不是很Feasible
				* 所谓的Online偏向Continual“继续学习”的能力
	* 看了一下实验室的手册，准备预约一下机器
		* 内容好...充实
		* 顺手学习一个
			* [LDAP(Lightweight Directory Access Protocol)](https://segmentfault.com/a/1190000002607140)-专业的分布式数据库，写性能差，用于查询，满足树状结构
			* ICP备案
			* BeagleBone是TI与Digikey联合生产的低功耗开源单板计算机（信用卡大小，可跑Linux）
		* ~~一些数据集在服务器share（或eva_share、/dataset等共享的）文件夹已经有了，可以先问一下你的负责研究生~~
		* ~~填写一下参考，占用的容量~~
		* TODO: 熟悉一下官网上的vim和tmux教程  ~~希望自己不要又从这个简单的弄起~~
	* ~~ 需要改一下PPT先和汪总发一版 ~~
		* ~~需要看一下怎么用PPT高雅地画图，太丑陋了(暂时搁置了)~~
		* TODO: (比较后的，预计是对TL有了一个比较Feasible的方案之后)
			* TL还是相对比较Feasible的，具体的找算法已经思考还需要进一步看（可以给几个Example大概讲一下子他们的）

* 平头哥讲座
	* CTO，首席科学家 - 谢源
	* DL-BigData-算力的三重Positive Feedback（画饼可以用）
	* AI芯片场景
		* 服务器端；移动终端；物联网 - 需求不同 
	* 产品
		* 玄铁CPU-RISCV-16Core-2.5GHz
		* 无剑Soc平台   
			* 缩短研发周期
			* 基于中天微的指令集
		* 含光 - AI云上推理
			* ~~都是剑的名字，很恶趣味~~
	* 异构计算 Heterogeneous
	* 半导体公司的3 Stage
		1. TI 传统方式
		2. TSMC
		3. HiSilicon - 由系统公司驱动而来
	* RISCV的生态
		* 开源指令集的使用
			* 目前choice相对比较多x86和mips以及arm
		* Chisel - 面向对象的RTL描述语言 （但是编译器其实不开放）
			* 有尝试利用其做敏捷设计的开发
			* EDA工具上中国有欠缺
	* 低功耗，终端(IOT)的芯片
	 

---

### 2019-10-14
* 上午把雄哥作业做了，把显示器和硬盘安排了
* 读了一下Pytorch文档，有微小收获嗷👍
    * 微软自带的输入法居然可以打Emoji🐂🍺
* 晚上看了HLS，Vivado2017有奇妙bug，卸载换新的，好像ubuntu系统引导坏了

---

### 2019-10-13
* 继续修改和进一步思考开题的问题
    * 发现了很棘手的问题，这个YFCC不是很好用，有一定阻力，但是不是不行
    * 也有一些新的idea
        * 可以去证明一下定点的网络是否还是具有这样的性质
* 更加看了一下Transfer learning的tutorial
    * 感觉这玩意还是玄之又玄
* 复习了一下熊哥的课，名词太tmd多了，淦


---
 
### 2019-10-12
* 今天主要工作是做开题的准备PPT，稍微更加深入了一下文章
    * 数据集是怎么构建的
    * 大概是怎么训练的
* 如果需要把题目开小一点的话，可不可以直接从迁移学习入手，训这个CUB数据集，比较好训一点
* 读了Weakly Supervised Training
    * 网路对于Label Noise的容忍程度比想象中要高一些
* CUB2011数据集
    * 经常用来做*迁移学习*
    * 还有*细粒度的图像分类*
* 晚上还看了一些关于CNN加速方式以及TL的内容

---

### 2019-10-11
* 感冒依旧，躺了好久...还要参加一个1802的开学典礼，今天就继续思考了一下开题
* 找到了一个possible的开源代码(但是是做量化的) - 然而kill-the-bits里面还是只是开源了模型没有开源代码 ~~还是要自己刚~~


* New Idea
	* 想到了一个让Teacher和Student做**时分复用**的Idea，还ok
	* 还需要看看Self-Training相关的东西
		* 貌似现在还是一个比较开放的Field，主要描述了一个在Unlabel数据集上利用某一网络进行标注，维护一个新的Training Set(这里有一些玩头)
	* [EfficentNet提出对CNN结构设计的一些思考](https://mp.weixin.qq.com/s/T1ZwpaGO6PJR5Z6t2MULGQ)
		* 提出了**混合尺度变换**
		* 看来已经全面进入NAS时代了
		* 从3个维度开始考虑问题
			1. 深度
			2. 宽度 (体现在CH数目)
			3. 分辨率 (体现在输入图片的大小) 会影响到fine-grain的特征
		* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191011211753.png)
			* 将三种NN的尺度，混合起来限定为一种Block(代表这使用一定的资源？)，依据Block去搜索，相当于约束了搜索空间
				* 至于这个约束条件怎么来的，比较arbitary
	* [Pytorch 1.4他lei了](http://pytorch.org/)
		* 更新了[移动端](http://pytorch.org/mobile )和[量化](https://pytorch.org/tutorials/advanced/dynamic_quantization_tutorial.html)的一些操作


---

### 2019-10-10
* 十一之后刚刚回学校，就持续感冒，约莫有2~3天没好了，对工作时间的大量浪费，下面需要学习养生
    * 早睡早起
    * 能运动运动
    * 吃吃早饭
* **可持续发展非常重要**快些养病
* 学习了一下*通信网络原理*
    * 复习了一下之前落下的内容(还真不少...)
    * Chap2 排队论
        1. 一些基础的概念和描述
        2. MM/m/n模型 - 马尔科夫
        3. M/G/1 - 非马尔科夫，无限队列容量
    * Chap3 通信网络服务的建模
    * Chap5的一点尾巴
    * Chap6图论的相关内容(在通信网络的field内与路由密集相关)，记住的
        * 几个anecdote-哥尼斯堡7桥；四色猜想
        * *树*是任意两个节点之间只有一条边的
            * *引申到最小生成树*
        * 欧拉图，能够走回来的
            * 充要条件：每个节点的**度(degree)都是偶数**

* 组会
	* ReRAM组的主要Contribution
		* 梳理了一下RRAM组的主要contribution(2013-2019)
			* 达成了从器件-组成逻辑结构-系统架构-算法的完整Workflow
			* 在EDA层面搭平台，设计仿真器，以替代spice
		* RRAM非易失存储，高阻表示0，低阻表示1
		* NVM - Non-Volatile Memory非易失存储
		* 说到了一个新坑（据说是汪总现在在Stanford讲的）
			* 针对不同的平台通过NAS直接搜架构，是比较高层的一个说法
				* *不做对应设计，直接暴力搜。。。太狠了*

	* 曾C讲的关于FPGA虚拟化的一些Work
		* 主要是对FPGA云服务器，单块FPGA做多任务复用的
			* 不用TDM那样效率低，实际用的还是空分复用
		* 存在一个动态负载（Dynamic WorkLoad）的问题，不知道新的任务什么时候到来
		* 主要任务-提高修改FPGA配置的速度
			* 完整重配置-生成bit-让EDA去选择如何布线去生成架构，太慢了-需要1day
			* 基于指令集的FPGA设计(DPU)需要10-100s
				* 目前的指令集，缺少对*多PE可控并行*，以及*动态重配置*（将配置的指令分为Static和Dynamic的，Static的只需要执行一次）的支持
		> 感觉自己对基于指令集的FPGA设计理解不够深刻，也就是DPU是如何开发的，每一步做了什么，映射到这个问题上面是怎么更新

* New Idea
	* Multi-Precision CNN 对CNN来说不同层的敏感度是不一样的（可量化位数）

---

## 🤔自省🤔
* 认为自己不熟悉的领域过于万能，希望别的部分能够万能。（本质上还是一种程度上的推卸责任）
* 想得太往后，比如这一次的Semi-Supervised Learning，郭哥说的现在先想怎么把故事讲好
* 自己很容易追求短期内工作/学习获得的短暂成就感，但是没有及时巩固(或者所选择学习的东西不太有机会及时巩固)，比如Graph的那次
* 越来越感觉DL的某个领域到了这几年发展的论文有种比较排斥的感觉，不知道是超出了自己的认知范围还是为什么，我总是感觉他们在找水点，而没有靠谱的方案，反思一下自己认知里的“靠谱”是不是鼠目寸光了
* 所谓的去寻找硬件友好的算法，其实会排除掉有效东西

## Done

#### ⌛ Today

* 看AMC去找heuristic的剪枝的经验性方法看看能不能和我们对应上
* ~~ 调昨天那个崩掉的Res18的plan1,到底是为啥 ~~
* 查资料finetune res50的办法
	* 现在还没有搞定,需要请教一下凯哥
* ~~ Sensitivity Analysis ~~
	* 还需要拿上梯度去对照
* 起实验
* plot.py一起`
	* ~~ FLOPs, alpha(12x), test_acc ~~
	* ~~grad compute_loss; task_loss (带和不带relu)~~
* MobileNet实验
	* ~~Baseline~~
	* ~~扫一遍~~
* 改图(文献里的FlowChart)
*~~ introduction ~~

---
#### ⏰ ShortTerm

* Prune
* 代码
	* ~~把按照时间做log的东西改过来先)~~
	* ~~ 加上估计sparsity的模块 - Our Plan ~~
	* ~~morphnet的truncate方式修改~~
	* ~~ save-every / prune_trainer ~~
	* ~~ group_lasso的具体实现方式是什么? ~~
	* ~~ 要一下生成yaml的脚本 ~~
	* ~~ re 一下改state dict ~~
	* ~~ 架起来imagenet的baseline,开始跑 ~~
* 写一个finetune
	* 继续调cifar10上的我们的结果
* 写mask_vgg
* 总结文章related work
	* ~~ 加一个表格 ~~
	* ~~post-train和~~
* 添加实验
	* ~~tiny imagenet直接从一半开始~~
	* 改state dict,能直接从别人给的起手
* 压到了budget直接停止开始tune
	* 完成了..
* ~~ BN加Regularization作为一项,参与weight更新 ~~
* ~~改成每个epoch存储一次~~
* ~~ res50 ~~
* ~~ 改split ~~
	* ~~ 需要一个infinte ~~
* ~~ update alphas every N ~~
	* ~~ update M steps for alpha ~~
* ~~ 检查计算量是否正确 ~~
* ~~ 添加存储画图素材 ~~
	* ~~ 添加vgg实验 ~~
* 实验Settting
	* plan1修改
		* ~~ grad normalize ~~
		* ~~ Grad累计,multi-mc ~~
		* ~~ temperature ~~
		* ~~ adam思想不符 ~~
		* ~~ compute loss用实际的而不是keep ratio ~~
		* ~~ 是在压第一层 ~~
	* ~~ Baseline ~~
		* Post-Training: 相对比较白给
		* MorphNet
		* GroupLasso
	* ~~写一个checksparisty和test的脚本~~
	* ~~ Plan1 的SparsityRatio调不了...(可能不是稳定,就是超参数很耐调,我也调不动) ~~
		* ~~ 可以调了...按照数量级调整 ~~
	* ~~ 画图脚本 (Acc-Sparsity) ~~
		* ~~ 还是往里面加保存把. ~~
	* ~~ plan1从pretrain开始 ~~
	* ~~ 和原文对一下结果 ~~
	* ~~ 然后改VGG ~~
* ~~ 思考还有什么图可以画 ~~



#### ⌚ LongTerm

* 补充Bayesian相关的知识
	* 有一个Bayesian的教材有时间可以读(希望寒假有时间)
* NAS Paper Digest
	* NAS Surgery
* 更新定点训练框架
* ConsistencyTraining硬件规划

### TODO （2020-03） ⏰

* ~~一个Online Learning的场景的梳理(Proposal)~~
* ~~Active Learning整理 (暂时搁置)~~
* ~~SemiSupervised整理~~ 
* ~~整理gates实验的新材料~~
* 新锅
  * 背景知识的GCN Survey
  * ~~下周二，和微电所的交流，硬件Training的可能方向~~
* ~~多看CPC，做PPT~~
* 毕设中期相关内容
  * ~~需要补每周进度~~
  * ~~需要改PPT (题目微调的问题)~~
  * ~~需要写中期报告~~
* ~~GATES文章修改~~
* 需要更新的文章阅读
  * FewShotSurvey
  * ~~S4L结论~~

### TODO(2020-04)

* GCN Survey finished
* Surgery
	* Shared-Weights debugging
* 毕设中期相关内容
	* Apply Quantization
