---
layout:     post                    # 使用的布局（不需要改）
title:      日知录          # 标题 
subtitle:   看看自己能够坚持多久       #副标题
date:       2048-01-01            # 时间
author:     tianchen                      # 作者
header-img:  img/10_1/bg-tz1.jpg  #这篇文章标题背景图片  
catalog: true                       # 是否归档
tags:                               #标签
     - private
---
# 日知录
* 这个习俗大概来自于高中？FXB让我们记录下每天学到的东西，高中时候没有记住，不知道之后能不能记下来

---

### 2019-10-10
* 十一之后刚刚回学校，就持续感冒，约莫有2~3天没好了，对工作时间的大量浪费，下面需要学习养生
    * 早睡早起
    * 能运动运动
    * 吃吃早饭
* **可持续发展非常重要**快些养病
* 学习了一下*通信网络原理*
    * 复习了一下之前落下的内容(还真不少...)
    * Chap2 排队论
        1. 一些基础的概念和描述
        2. MM/m/n模型 - 马尔科夫
        3. M/G/1 - 非马尔科夫，无限队列容量
    * Chap3 通信网络服务的建模
    * Chap5的一点尾巴
    * Chap6图论的相关内容(在通信网络的field内与路由密集相关)，记住的
        * 几个anecdote-哥尼斯堡7桥；四色猜想
        * *树*是任意两个节点之间只有一条边的
            * *引申到最小生成树*
        * 欧拉图，能够走回来的
            * 充要条件：每个节点的**度(degree)都是偶数**

#### 组会
##### ReRAM组的主要Contribution
* 梳理了一下RRAM组的主要contribution(2013-2019)
    * 达成了从器件-组成逻辑结构-系统架构-算法的完整Workflow
    * 在EDA层面搭平台，设计仿真器，以替代spice
* RRAM非易失存储，高阻表示0，低阻表示1
* NVM - Non-Volatile Memory非易失存储
* 说到了一个新坑（据说是汪总现在在Stanford讲的）
    * 针对不同的平台通过NAS直接搜架构，是比较高层的一个说法
        * *不做对应设计，直接暴力搜。。。太狠了*

##### 曾C讲的关于FPGA虚拟化的一些Work
* 主要是对FPGA云服务器，单块FPGA做多任务复用的
    * 不用TDM那样效率低，实际用的还是空分复用
* 存在一个动态负载（Dynamic WorkLoad）的问题，不知道新的任务什么时候到来
* 主要任务-提高修改FPGA配置的速度
    * 完整重配置-生成bit-让EDA去选择如何布线去生成架构，太慢了-需要1day
    * 基于指令集的FPGA设计(DPU)需要10-100s
        * 目前的指令集，缺少对*多PE可控并行*，以及*动态重配置*（将配置的指令分为Static和Dynamic的，Static的只需要执行一次）的支持
> 感觉自己对基于指令集的FPGA设计理解不够深刻，也就是DPU是如何开发的，每一步做了什么，映射到这个问题上面是怎么更新

##### New Idea
* Multi-Precision CNN 对CNN来说不同层的敏感度是不一样的（可量化位数）

---

### 2019-10-11
* 感冒依旧，躺了好久...还要参加一个1802的开学典礼，今天就继续思考了一下开题
* 找到了一个possible的开源代码(但是是做量化的) - 然而kill-the-bits里面还是只是开源了模型没有开源代码 ~~还是要自己刚~~


##### New Idea
* 想到了一个让Teacher和Student做**时分复用**的Idea，还ok
* 还需要看看Self-Training相关的东西
    * 貌似现在还是一个比较开放的Field，主要描述了一个在Unlabel数据集上利用某一网络进行标注，维护一个新的Training Set(这里有一些玩头)
* [EfficentNet提出对CNN结构设计的一些思考](https://mp.weixin.qq.com/s/T1ZwpaGO6PJR5Z6t2MULGQ)
    * 提出了**混合尺度变换**
    * 看来已经全面进入NAS时代了
    * 从3个维度开始考虑问题
        1. 深度
        2. 宽度 (体现在CH数目)
        3. 分辨率 (体现在输入图片的大小) 会影响到fine-grain的特征
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191011211753.png)
        * 将三种NN的尺度，混合起来限定为一种Block(代表这使用一定的资源？)，依据Block去搜索，相当于约束了搜索空间
            * 至于这个约束条件怎么来的，比较arbitary
* [Pytorch 1.4他lei了](http://pytorch.org/)
    * 更新了[移动端](http://pytorch.org/mobile )和[量化](https://pytorch.org/tutorials/advanced/dynamic_quantization_tutorial.html)的一些操作

    
--- 
### 2019-10-12
* 今天主要工作是做开题的准备PPT，稍微更加深入了一下文章
    * 数据集是怎么构建的
    * 大概是怎么训练的
* 如果需要把题目开小一点的话，可不可以直接从迁移学习入手，训这个CUB数据集，比较好训一点
* 读了Weakly Supervised Training
    * 网路对于Label Noise的容忍程度比想象中要高一些
* CUB2011数据集
    * 经常用来做*迁移学习*
    * 还有*细粒度的图像分类*
* 晚上还看了一些关于CNN加速方式以及TL的内容

---
### 2019-10-13
* 继续修改和进一步思考开题的问题
    * 发现了很棘手的问题，这个YFCC不是很好用，有一定阻力，但是不是不行
    * 也有一些新的idea
        * 可以去证明一下定点的网络是否还是具有这样的性质
* 更加看了一下Transfer learning的tutorial
    * 感觉这玩意还是玄之又玄
* 复习了一下熊哥的课，名词太tmd多了，淦

---
### 2019-10-14
* 上午把雄哥作业做了，把显示器和硬盘安排了
* 读了一下Pytorch文档，有微小收获嗷👍
    * 微软自带的输入法居然可以打Emoji🐂🍺
* 晚上看了HLS，Vivado2017有奇妙bug，卸载换新的，好像ubuntu系统引导坏了
---

### 2019-10-15
* 上午重新装Ubuntu...
    * 被代理卡了好久...
    * 搞定了ssh显示图形界面

##### 组会

* 讲了一下Semi的东西
    * 和云端的区分还是比较难，貌似只有*隐私问题*
        * 作为Online training会有一定的需求
        * 这个WorkFlow对应着一种Framework可能可行
    * 数据集维护，可以存一段时间  
        * 理论上只要有比较好的新的数据就可以了
        * 数据集的体量是多少？
            * 目前取得比较好的效果是10x原来数据集大小的样子（对于ImageNet来说我们的实验环境难以接受了）
    * 单纯的Classification提点数
        1. 实现起来不太可能，存储量太大了（这个Training一定是一个企业级的活，我自己做一定不能够这么做）
            * 除非换一个比较小的任务
        2. 本身只是为了提高一点点数，用处不是那么大
        * **往Transfer走相对会更有意义一些，需要深入思考和深入了解一下Transfer Learning**
    * 确实Online Training 梯度也会有精度损失，会不会产生影响
    * **Class Imbalance**也确实是一个需要解决的问题
        * TODO: 约意如神聊一下
    * 关于**Online Learning**
        * 是一个肯定存在需求的方向
            * 但其实还是取决与这个Online的场景能不能学到所谓"新的知识"
                1. 按照semi的workflow是完全没有的，还是原来的东西
                2. 按照Transfer的方案，其实是去后训一个Classifier
                    * 目前看来最Promising的一个⭐
                3. 能做到辨识新的东西
                    * 需要一个Incremental了，目前的算法感觉不是特别靠谱
        * 目前来说很多研究感觉*实验设计都不太考虑实际应用场景，很多都往所谓AI的“学习能力”在做，不是特别和硬件实现相契合关契合*
            * 说白了就是Training的这个Workflow还没有定论，甚至都没有人去解决Label的问题，如果我们最后的目标是硬件实现或者这加速的化，不是很Feasible
            * 所谓的Online偏向Continual“继续学习”的能力
* 看了一下实验室的手册，准备预约一下机器
    * 内容好...充实
    * 顺手学习一个
        * [LDAP(Lightweight Directory Access Protocol)](https://segmentfault.com/a/1190000002607140)-专业的分布式数据库，写性能差，用于查询，满足树状结构
        * ICP备案
        * BeagleBone是TI与Digikey联合生产的低功耗开源单板计算机（信用卡大小，可跑Linux）
    * TODO: 一些数据集在服务器share（或eva_share、/dataset等共享的）文件夹已经有了，可以先问一下你的负责研究生
    * TODO: 填写一下参考，占用的容量
    * TODO: 熟悉一下官网上的vim和tmux教程  ~~~希望自己不要又从这个简单的弄起~~
* TODO: 需要改一下PPT先和汪总发一版
    * TODO: 需要看一下怎么用PPT高雅地画图，太丑陋了
* TODO: (比较后的，预计是对TL有了一个比较Feasible的方案之后)

##### 平头哥讲座
* CTO，首席科学家 - 谢源
* DL-BigData-算力的三重Positive Feedback（画饼可以用）
* AI芯片场景
    * 服务器端；移动终端；物联网 - 需求不同 
* 产品
    * 玄铁CPU-RISCV-16Core-2.5GHz
    * 无剑Soc平台   
        * 缩短研发周期
        * 基于中天微的指令集
    * 含光 - AI云上推理
        * ~~都是剑的名字，很恶趣味~~
* 异构计算 Heterogeneous
* 半导体公司的3 Stage
    1. TI 传统方式
    2. TSMC
    3. HiSilicon - 由系统公司驱动而来
* RISCV的生态
    * 开源指令集的使用
        * 目前choice相对比较多x86和mips以及arm
    * Chisel - 面向对象的RTL描述语言 （但是编译器其实不开放）
        * 有尝试利用其做敏捷设计的开发
        * EDA工具上中国有欠缺
* 低功耗，终端(IOT)的芯片
 

---

## 🤔自省🤔
* 认为自己不熟悉的领域过于万能，希望别的部分能够万能。（本质上还是一种程度上的推卸责任）
* 想得太往后，比如这一次的Semi-Supervised Learning，郭哥说的现在先想怎么把故事讲好
* 自己很容易追求短期内工作/学习获得的短暂成就感，但是没有及时巩固(或者所选择学习的东西不太有机会及时巩固)，比如Graph的那次

