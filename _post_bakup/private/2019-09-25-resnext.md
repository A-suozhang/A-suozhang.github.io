---
layout:     post                    # ä½¿ç”¨çš„å¸ƒå±€ï¼ˆä¸éœ€è¦æ”¹ï¼‰
title:      ResNetæ˜¯å•¥ï¼ŒSOTAçš„CNNè®¾è®¡æ€è·¯å¦‚ä½•ï¼Ÿ           # æ ‡é¢˜ 
subtitle:   å¯èƒ½è¿˜é™„å¸¦äº†ä¸€äº›è‡ªå·±å¯¹å·ç§¯è®¾è®¡çš„ç†è§£ï¼Ÿ        #å‰¯æ ‡é¢˜
date:       2020-04-29            # æ—¶é—´
author:     tianchen                      # ä½œè€…
header-img:  img/bg-zynq.jpg  #è¿™ç¯‡æ–‡ç« æ ‡é¢˜èƒŒæ™¯å›¾ç‰‡  
catalog: true                       # æ˜¯å¦å½’æ¡£
tags:                               #æ ‡ç­¾
     - DL
     - CNN
---

# Different Convs 

> å‚è€ƒäº†[çŸ¥ä¹-Convsè¯¦è§£](https://zhuanlan.zhihu.com/p/113211369?tdsourcetag=s_pctim_aiomsg)

1. Normal Conv (ä¸ç”¨é˜è¿°äº†ï¼Œè¿™å¼ å›¾ä¸é”™)
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200319103333.png)
2. 1x1 Conv/Pointwise Conv
   * 1st in NiN, Used in GoogLenet
   * å¯ä»¥ç”¨æ¥æ§åˆ¶Filteræ•°ç›®
   * **è·¨Channelçš„ä¿¡æ¯æ•´åˆ**  
3. Spatial&Cross Channel Conv
   * Used in the Inception Block
   * å…ˆç”¨ä¸€ä¸ª1x1Convæ¥é™åˆ¶Channelæ•°ç›®ï¼Œç„¶å3x3 Convï¼Œæœ€åç”¨concatçš„æ–¹å¼æ¥èåˆç‰¹å¾
   * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200319103903.png)
4. Grouped Conv
   * 1st in Alex, Applied in ResNeXT
   * å°†Featureåˆ†ç»„ï¼Œåœ¨ç»„å†…åšconvï¼Œæœ€åå°†ç»“æœConcatï¼Œä»¥å‡å°‘è®¡ç®—é‡
   * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200319104204.png)
   * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200319104245.png)
     * æœ‰ä¸€ä¸ªåŸºæ•°(Cardinaltyæ¥æ§åˆ¶ç»„çš„æ•°é‡) - éšç€åŸºæ•°çš„å¢åŠ ï¼Œè®¡ç®—é‡ä¼šå‡å°
     * åˆ†ç»„å·ç§¯è®©filterä¹‹é—´çš„ç›¸å…³æ€§æ›´å°äº†ï¼Œå¯ä»¥èµ·åˆ°ä¸€å®šçš„æ­£åˆ™åŒ–ä½œç”¨
     * åˆ†ç»„çš„æ“ä½œä¹Ÿå¯ä»¥è¢«å¹¶è¡Œèµ·æ¥
   * **ShuffleGroupConv**
     * 1st in ShuffleNet
     * ChannelShuffleä¿ƒè¿›å±‚é—´ä¿¡æ¯çš„flow
     * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200319105412.png)
       * å·¦ä¸€æ˜¯Bottleneck-ä¸­é—´æ˜¯ä¸€èˆ¬çš„ShuffleBlock-å³ä¸€æ˜¯strided shuffle block
5. Sepearable Conv
   5.1 Depth-wise Seperable Conv
      * åœ¨Xceptionå’ŒMobileNetç³»åˆ—ä¸­Applied
      * (Depthwise+Pointwise) - (PerChannel+1x1Conv)
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200319104813.png)
   5.2 Spatilly Separable Conv
      * å°†NxNæ‹†è§£ä¸º1xNä¸Nx1
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200319104630.png)
      * é—®é¢˜æ˜¯ä¼šå¸¦æ¥ä¸€å®šçš„ä¿¡æ¯æŸå¤±(ä¸æ˜¯æ‰€æœ‰çš„Filteréƒ½å¯ä»¥åˆ†è§£)
      * ä¸ä¹‹ç±»ä¼¼çš„æœ‰FlattenConv
        * ä¹Ÿæ˜¯çŸ©é˜µåˆ†è§£ï¼Œ3-dåˆ†è§£ä»¥å‡å°è®¡ç®—é‡2
        * è®°å¾—MICROè¿˜æ˜¯INSCAæœ‰ä¸€ç¯‡EDAçš„æ–‡ç« æ˜¯å»æ‰¾å¦‚ä½•å»Unroll
6. Dilated Conv
   * ç”¨äºå¤šå°ºåº¦çš„é‚»è¿‘ä¿¡æ¯èåˆ
7. Deformable Conv
   * ç›®æ ‡æ˜¯å½¢çŠ¶å¯ä»¥å­¦ä¹ çš„Convï¼Œå­¦ä¹ æ¯ä¸ªç‚¹çš„offsetï¼Œè®©Convä¸å†æ˜¯æ ‡å‡†çš„æ­£æ–¹å½¢
   * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200319110042.png)
   * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200319105645.png)
8. Attention
   9.1 SE Block
    * æ€æƒ³æ˜¯æ¯ä¸ªChannelçš„é‡è¦æ€§ä¸åŒï¼ŒåŠ äº†ä¸€ä¸ªAuxiliary Modelç»™æ¯ä¸ªé€šé“æ‰“åˆ†ï¼Œå°†ç»“æœä¸Feature Mapç›¸ä¹˜ï¼Œå¯¹ä¸åŒchannelèµ‹äºˆä¸åŒæƒé‡ã€
    * Channelç»´åº¦çš„Attention
   9.2 CBAM
    * åœ¨Channel-wise Attention åŠ ä¸Šäº†Spatial-wise Attention
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200319110436.png)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20200319110513.png)
    * ä¸¤ä¸ªæ¨¡å—çº§è”  

* Summary
  * å•ä¸€å°ºå¯¸å·ç§¯æ ¸ç”¨å¤šä¸ªå°ºå¯¸å·ç§¯æ ¸ä»£æ›¿ï¼ˆå‚è€ƒInceptionç³»åˆ—ï¼‰
  * ä½¿ç”¨å¯å˜å½¢å·ç§¯æ›¿ä»£å›ºå®šå°ºå¯¸å·ç§¯ï¼ˆå‚è€ƒDCNï¼‰
  * å¤§é‡åŠ å…¥1x1å·ç§¯æˆ–è€…pointwise grouped convolutionæ¥é™ä½è®¡ç®—é‡ï¼ˆå‚è€ƒNINã€ShuffleNetï¼‰
  * é€šé“åŠ æƒå¤„ç†ï¼ˆå‚è€ƒSENetï¼‰
  * ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯æ›¿æ¢æ™®é€šå·ç§¯ï¼ˆå‚è€ƒMobileNetï¼‰
  * ä½¿ç”¨åˆ†ç»„å·ç§¯ï¼ˆå‚è€ƒResNeXtï¼‰
  * åˆ†ç»„å·ç§¯+channel shuffleï¼ˆå‚è€ƒshuffleNetï¼‰
  * ä½¿ç”¨Residualè¿æ¥ï¼ˆå‚è€ƒResNetï¼‰









> å‚è€ƒäº†[çŸ¥ä¹-ResNeXTè¯¦è§£](https://zhuanlan.zhihu.com/p/51075096)

# ResNeXT
* ```ResNet + Inception```
* æœ¬è´¨æ˜¯**åˆ†ç»„å·ç§¯**([Group Convolution](https://zhuanlan.zhihu.com/p/50045821))

##  Split-Transform-Merge
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20190925220635.png)
* fc(å¯¹äºä¸Šä¸€å±‚çš„æ¯ä¸€ä¸ªç¥ç»å…ƒ)éƒ½æ˜¯ä¸€ä¸ªSplit-Transform(Activation)-Mergeçš„ç»“æ„
* è€ŒInception Moduleï¼Œä¹Ÿæ˜¯ä¸€ä¸ªè¿™æ ·çš„Split-Transform-Mergeçš„ç»“æ„

## Change Inception
* ResNextçš„ä½œè€…è®¤ä¸ºInception V4ä¸­Inception Moduleå†…éƒ¨éœ€è¦è®¾è®¡ï¼Œå¤ªäººå·¥å’Œåˆ»æ„(å¤ªå¤šçš„è¶…å‚æ•°éš¾ä»¥è°ƒèŠ‚)
    * åˆç†ä¹Ÿä¸åˆç†ï¼šè¿™æ ·è²Œä¼¼æ²¡æœ‰è€ƒè™‘åˆ°å¤šç§æ„Ÿå—é‡
* æ‰€ä»¥å¯¹æ‰€æœ‰çš„Inception Moduleé‡‡å–*ç›¸åŒçš„æ‹“æ‰‘ç»“æ„*ï¼Œåªé€šè¿‡Cardinalty(åŸºæ•°-è¿™ä¸ªè¯åœ¨æ•°å­¦é‡Œé¢æ˜¯â€œåŠ¿â€)æ¥æ§åˆ¶æœ‰å¤šå°‘ä¸ªè¿™æ ·çš„æ¨¡å—
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20190925221542.png) 
* ä¸Inception V4å¾ˆç±»ä¼¼ï¼Œåªæ˜¯Inceptionæ˜¯å…ˆconcatå†```1*1conv```ï¼Œè€ŒResNextæ˜¯å…ˆåˆ†è·¯```1*1Conv```å†Concat

## Group Conv
* ä»‹äºæ­£å¸¸å·ç§¯å’ŒDepth-wiseå·ç§¯ä¹‹é—´çš„æŠ˜ä¸­
    * æ—¢ä¸æ˜¯å¯¹æ¯ä¸€ä¸ªCç”¨ä¸€ä¸ªå·ç§¯æ ¸ï¼Œä¹Ÿä¸æ˜¯å¯¹æ‰€æœ‰Cç”¨ä¸€ä¸ªå·ç§¯æ ¸

### ResNeXtä¸ºä»€ä¹ˆå¥½

* å¼•å…¥äº†cardinaltyï¼Œæœ¬è´¨ä¸Šè¿˜æ˜¯ä¸åŒçš„groupï¼Œä¸åŒçš„groupå¯¹åº”ç€ä¸åŒçš„sub-sampleï¼Œå¯ä»¥å­¦åˆ°æ›´åŠ diverseçš„è¡¨ç¤º
* æœ‰äººæŒ‡å‡ºMulti-cardinaltyå…¶å®å’Œmulti-headçš„Attentionçš„æ„å‘³ä¸€æ ·
  * Take Part in different rpresentation subspace


# WRN(Wide ResNet)

> ResNetçš„åˆä¸€ä¸ªç»å…¸å˜ä½“

* æ‰€è°“çš„å®½ï¼Œå°±æ˜¯feature mapçš„channelæ•°...
* å‘½åæ–¹å¼ WRN-n(å·ç§¯å±‚æ•°)-k(å®½åº¦ç³»æ•°)-B(blockçš„ç»“æ„)
* ä½œè€…è¿›è¡Œç–¯ç‹‚å®éªŒä¹‹åå¾—åˆ°ç»“è®º
    * å¸¦Dropoutæ›´ç‰›é€¼
    * æœ‰çš„æ—¶å€™æ·±åº¦å¤ªæ·±åè€Œä¼šGG
    * B(3,3)æ˜¯æ¯”è¾ƒå¥½çš„ç»“æ„ï¼ŒæŒ‡ä¸€ä¸ªBlocké‡Œé¢2ä¸ª3x3å·ç§¯


# ShakeShake 
* æœ¬è´¨ä¸Šæ˜¯ä¸€ç§Regularizationçš„æ–¹æ³•,ä¸æ˜¯å¾ˆä¸»æµ,è¢«è¯æ˜åœ¨å°ç½‘ç»œä¸Šå–å¾—äº†æ¯”è¾ƒå¥½çš„æ•ˆæœ
* å¤šBranch(3)å’ŒResNetåˆ†è·¯çš„æ€è·¯ä¸€è‡´
* FeedForward Shake
  * åœ¨å‰å‘çš„æ—¶å€™å¯¹ä¸¤è·¯åˆ†åˆ«ä¹˜ä¸Šaå’Œ(1-a)åšäº†ä¸€ä¸ª*Disturbing*
  * åœ¨åŸæœ¬çš„Dropoutä¸­å·²ç»æå‡ºäº† - (æœ¬æ–‡æ–¹æ³•å¯ä»¥çœ‹åšä¸€ä¸ªè½¯çš„Dropout?)
  * å…¶å¯ä»¥å’ŒBNä¸€èµ·è·å¾—æ›´å¥½çš„æ•ˆæœ,[è¿™ç¯‡åšå®¢](https://zhuanlan.zhihu.com/p/33101420)æœ‰æåŠ
    * è¿™ç¯‡åšå®¢è®ºè¿°çš„æ˜¯*Dropoutä¸BNä¸compatibleçš„é—®é¢˜*
    * æ€è·¯æ˜¯Dropout,ä¼šç»™ç½‘ç»œåŠ ä¸Švariance shift(æ–¹å·®åç§»)è€Œå¯¼è‡´BNå±‚ä¸€å¼€å§‹å½’ä¸€åŒ–çš„æ–¹å·®é”™äº†!(traingå’Œinferenceä¸ä¸€è‡´äº†)
    * WRNçš„ä½œè€…åœ¨dropoutåé¢åŠ äº†ä¸€ä¸ªfcå†BN,ç¼“è§£äº†è¿™ä¸ªé—®é¢˜
    * Solu:
      * æœ€ç®€å•æš´åŠ›çš„æ˜¯æŠŠdropoutæ”¾BNçš„åè¾¹
      * æœ‰äººä½¿ç”¨é«˜æ–¯Dropout,ç»™ä¸€ä¸ªå‡åŒ€åˆ†å¸ƒçš„dropout(å…¶å®å’Œshakeshakeä¸€æ–‡ä¸­çš„æ–¹æ³•å¾ˆç±»ä¼¼)
* Backwardshake
  * backpropçš„æ—¶å€™å¯¹åå‘ä¼ æ’­ä¹ŸåšDisturbing


---

# ResNet æºç é˜…è¯»

> ç”±äºç”¨åˆ°çš„resnetæ¬¡æ•°å®åœ¨æ˜¯å¤ªå¤šäº†,æ‰€ä»¥å¯¹[Resnetæºç ](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py)åšä¸€ä¸ªè§£è¯»å§

* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191112202451.png)
* ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191112202623.png)



* **å¤§æ®µä»£ç  Alert**

``` py
def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                     padding=dilation, groups=groups, bias=False, dilation=dilation)


def conv1x1(in_planes, out_planes, stride=1):
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)
``` 

* æœ€ç®€å•çš„Conv,å°è£…äº†ä¸€å±‚,ç”±äºå†…éƒ¨åªæœ‰3x3å’Œ1x1
  * è°ƒç”¨çš„æ˜¯torch.nnä¸­çš„Conv2då‡½æ•°(è¿™ä¸ªè¿”å›çš„æ˜¯ä¸€ä¸ªnn.functionalå’Œnn.functional.conv2dç­‰ä»·)
  * è¾“å…¥args
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191112185933.png)
    * inplane/outplane è¾“å…¥è¾“å‡ºChannelæ•°ç›®,å¾ˆç›´è§‚
    * Kernel_size
    * Stride (é»˜è®¤ä¸º1))
    * padding (é»˜è®¤ä¸º0)
    * bias(é»˜è®¤ä¸ºTrue)è¿™é‡Œè®¾ç½®ä¸ºNone    
      * biasæ˜¯ç›´æ¥åŠ åœ¨æ¯ä¸ªOutput Channelä¸Šçš„
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191112185239.png)       
    * groups(æè¿°äº†inputå’Œoutputä¹‹é—´çš„Connection)è¿™é‡Œè®¾ç½®ä¸ºäº†1
      * inplaneå’Œoutplaneè¦éƒ½èƒ½è¢«groupsæ•´é™¤
      * groups = 1 - æ­£å¸¸çš„å·ç§¯
      * groups = 2 -  ç›¸å½“äºæœ‰ä¸¤ä¸ªå·ç§¯å±‚,æ¯ä¸ªå¤„ç†ä¸€åŠçš„inputchannel,äº§ç”Ÿä¸€èˆ¬çš„outputchannel,æœ€åå†Concatèµ·æ¥ (*ç›¸å½“äºåˆ‡æ–­äº†ä¸€åŠçš„in_channelä¹‹é—´çš„è”ç³»*)
      * groups = in_channel - ç›¸å½“äºæ¯ä¸ªin_channléƒ½å’Œ(OUTC/INC)ä¸ªå·ç§¯å’Œå»å·,æœ€åè¾“å‡ºçš„ç»“æœå…¨éƒ¨concatèµ·æ¥
    * dilation - é»˜è®¤ä¸º1
      * [å›¾ç¤º](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md)
    * *dilationå’Œstrideä¹‹ç±»çš„ä¸œè¥¿éƒ½å¯ä»¥æ˜¯ä¸€ä¸ªintæˆ–è€…æ˜¯ä¸€ä¸ªtuple*
      * å¯ä»¥ç”¨æ¥æè¿°æ¨ªçºµä¸ä¸€æ ·æ—¶å€™çš„æƒ…å†µ
      * ![](https://github.com/A-suozhang/MyPicBed/raw/master/img/20191112185933.png)

``` py

class BasicBlock(nn.Module):
    expansion = 1
    __constants__ = ['downsample']

    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,
                 base_width=64, dilation=1, norm_layer=None):
        super(BasicBlock, self).__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        if groups != 1 or base_width != 64:
            raise ValueError('BasicBlock only supports groups=1 and base_width=64')
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out

```

* ä¸¤åŸºæœ¬æ¨¡å—ä¸­çš„ä¸€ä¸ªBasicBlock
  * ä¸ºäº†å…¼å®¹å¾ˆå¤šçš„ç»“æ„æ‰€ä»¥æœ‰äº†ä¸€äº›å†—ä½™è®¾è®¡
  * åªèƒ½æ”¯æŒgroup=1,base-width=64
  * ```norm-layer```ä»¥åŠ```downsample```çœ‹ä¸Šå»æ˜¯å¯ä»¥é…ç½®çš„
    * Downsampleå…·ä½“æ˜¯ä»€ä¹ˆåœ¨makelayeré‡Œ
    * é»˜è®¤çš„normlayeræ˜¯None,ä¹Ÿå°±å¯¹åº”ç€BatchNorm2d
  * å±‚å†…è¿˜æœ‰ä¸€ä¸ªexpensionå‚æ•°é»˜è®¤ä¸º1(å¥½åƒä¹Ÿåªèƒ½ä¸º1)

``` py
class Bottleneck(nn.Module):
    expansion = 4
    __constants__ = ['downsample']

    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,
                 base_width=64, dilation=1, norm_layer=None):
        super(Bottleneck, self).__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out
```

* ä¸¤å¤§åŸºæœ¬æ¨¡å—é‡Œçš„ä¸€ä¸ª BottleNexk
  * expansionä¸º4
    * ç”¨åœ¨å†…éƒ¨çš„åé¢çš„conv1x1çš„channelæ•°é‡Œé¢
      * ä»widthæ‹“å±•åˆ°expansion*width
  * ```width = int(planes * (base_width / 64.)) * groups```
    * åŒæ ·ä¹Ÿæ˜¯ç¬¬ä¸€ä¸ªconv1x1çš„outchannel
    * ä¹‹åçš„conv3x3éƒ½ä¿æŒwidthä¸ºchannelæ•°



``` py
class ResNet(nn.Module):

    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,
                 groups=1, width_per_group=64, replace_stride_with_dilation=None,
                 norm_layer=None):
        super(ResNet, self).__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        self._norm_layer = norm_layer

        self.inplanes = 64
        self.dilation = 1
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        if len(replace_stride_with_dilation) != 3:
            raise ValueError("replace_stride_with_dilation should be None "
                             "or a 3-element tuple, got {}".format(replace_stride_with_dilation))
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,
                               bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,
                                       dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,
                                       dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,
                                       dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck):
                    nn.init.constant_(m.bn3.weight, 0)
                elif isinstance(m, BasicBlock):
                    nn.init.constant_(m.bn2.weight, 0)

    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,
                            self.base_width, previous_dilation, norm_layer))
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(block(self.inplanes, planes, groups=self.groups,
                                base_width=self.base_width, dilation=self.dilation,
                                norm_layer=norm_layer))

        return nn.Sequential(*layers)

    def _forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)

        return x

    # Allow for accessing forward method in a inherited class
    forward = _forward
```

* è¾“å…¥argæœ‰ä¸¤ä¸ªæ¯”è¾ƒæœ‰è¶£çš„å¯ä»¥é…ç½®çš„
  * ```zero_init_residue```
    * æœ‰å…³ä»£ç 
     
    ``` py

    if zero_init_residual:
    for m in self.modules():
        if isinstance(m, Bottleneck):
            nn.init.constant_(m.bn3.weight, 0)
        elif isinstance(m, BasicBlock):
            nn.init.constant_(m.bn2.weight, 0)

    ``` 

    * å¯¹æ¯ä¸ªBlock(ä¹Ÿå°±æ˜¯å¯¹åº”ä¸€ä¸ªResidue Branch)çš„æœ€åä¸€ä¸ªBNçš„weightç½®0
      * è®©æ¯ä¸ªBlockä¸€å¼€å§‹åªæœ‰Identity Mappingçš„æ•ˆæœ
  * ```Replace Stide With Dilation```
    * é¦–å…ˆè¦äº†è§£åˆ°Resnetå½“ä¸­æ²¡æœ‰pool(å¯¹ä¸èµ·æˆ‘æ‰“è„¸äº†,è¿˜æ˜¯æœ‰é‚£ä¹ˆå‡ ä¸ªpoolçš„,åªä¸è¿‡ä¸æ˜¯ä¸»è¦çš„),åŸºæœ¬æ˜¯é€šè¿‡stide=2çš„å·ç§¯æ¥è¾¾æˆæ•ˆæœ
      * ç­‰ä»·äºå…ˆå·ç§¯å†Pool
    * è¿™ä¸ªå‚æ•°å°±è¡¨ç¤ºæ˜¯å¦ç”¨Diated Convæ¥æ›¿ä»£stride2conv
    * è¿™ä¸ªçš„è¾“å…¥å‚æ•°æ˜¯ä¸€ä¸ªtuple,é‡Œé¢å†…å®¹ä¸ºTrue/Falses
* å¯¹äº224çš„imagnetæ¥è¯´
  * inplaneè®¾ç½®ä¸º64,ä¹Ÿå°±æ˜¯èµ·æ‰‹çš„ä¸€ä¸ª7x7Convçš„è¾“å‡ºchannelæ˜¯64
* initæ–¹å¼
  * å¯¹æ‰€æœ‰çš„Convé‡‡ç”¨kaiming_normal_
  * å¯¹æ‰€æœ‰çš„BatchNorm(æˆ–è€…å¯èƒ½æ˜¯groupNormå±‚),æŒ‰ç…§æ­£å¸¸çš„initæ–¹å¼å¯¹weightå’Œbiasåˆ†åˆ«ç»™0/1
  * å¯ä»¥å­¦ä¹ ä¸€ä¸ª
  
``` py

for m in self.modules():
    if isinstance(m, nn.Conv2d):
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
    elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

```
---

``` py

def _make_layer(self, block, planes, blocks, stride=1, dilate=False):
    norm_layer = self._norm_layer
    downsample = None
    previous_dilation = self.dilation
    if dilate:
        self.dilation *= stride
        stride = 1
    if stride != 1 or self.inplanes != planes * block.expansion:
        downsample = nn.Sequential(
            conv1x1(self.inplanes, planes * block.expansion, stride),
            norm_layer(planes * block.expansion),
        )

    layers = []
    layers.append(block(self.inplanes, planes, stride, downsample, self.groups,
                        self.base_width, previous_dilation, norm_layer))
    self.inplanes = planes * block.expansion
    for _ in range(1, blocks):
        layers.append(block(self.inplanes, planes, groups=self.groups,
                            base_width=self.base_width, dilation=self.dilation,
                            norm_layer=norm_layer))

    return nn.Sequential(*layers)

```

* MakeLayerå‡½æ•°éå¸¸å…³é”®
  * é¦–å…ˆä¸ºæ¯ä¸ªBlockåˆ›å»ºäº†DownSampleå±‚
    * é‡Œé¢æ˜¯ä¸€ä¸ªconv1x1+BN (è½¬åŒ–åˆ°plane*expansionæ•°ç›®çš„channel)
  * åˆ›å»ºäº†ä¸€ä¸ªlayersçš„list
    * ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªblock,ä»inplaneåˆ°plane
    * åå‡ ä¸ªplaneä»inplaneåˆ°expansion*plane
    * è¾“å‡ºä¸ºplane
  * è¿”å›ä¸€ä¸ªnn.Sequentialå¯¹è±¡
* resnetçš„ä¸»ä½“å°±æ˜¯å››ä¸ªlayerå’Œä¸€ä¸ªhead
* å®é™…è°ƒç”¨çš„æ—¶å€™
  * ä»Resnetå»ºç«‹çš„æ—¶å€™çš„è¾“å…¥å‚æ•°å†³å®š
    * Blcokæ˜¯blockç±»å‹,å¯¹äºres18å’Œ34æ˜¯BasicBlock,ä¹‹å50æ˜¯BottleNeckBlock
    * layersæè¿°äº†layerçš„å¤§å°,æ˜¯ä¸€ä¸ªlistä¼ å…¥,4ä¸ªå…ƒç´ å¯¹åº”4ä¸ªlayer,å¯¹äºres18æ˜¯[2,2,2,2]


``` py
self.layer1 = self._make_layer(block, 64, layers[0])
self.layer2 = self._make_layer(block, 128, layers[1], stride=2,
                               dilate=replace_stride_with_dilation[0])
self.layer3 = self._make_layer(block, 256, layers[2], stride=2,
                               dilate=replace_stride_with_dilation[1])
self.layer4 = self._make_layer(block, 512, layers[3], stride=2,
                               dilate=replace_stride_with_dilation[2])
```


---

* è¿˜è¦å¤šä¸€å±‚å°è£…

``` py
def _resnet(arch, block, layers, pretrained, progress, **kwargs):
    model = ResNet(block, layers, **kwargs)
    if pretrained:
        state_dict = load_state_dict_from_url(model_urls[arch],
                                              progress=progress)
        model.load_state_dict(state_dict)
    return model
```

* æœ€åçš„å°±æ˜¯å„ç§resnetäº†

``` py
def resnet18(pretrained=False, progress=True, **kwargs):
    r"""ResNet-18 model from
    `"Deep Residual Learning for Image Recognition" <https://arxiv.org/pdf/1512.03385.pdf>`_
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
        progress (bool): If True, displays a progress bar of the download to stderr
    """
    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,
                   **kwargs)
```

---

# å…¶ä»–ResNetçš„å˜ç§

> æ‰‹å·¥è®¾è®¡ä¼˜ç§€çš„æ¨¡å‹ç»“æ„é¢†åŸŸä¹Ÿæœ‰æ‰€è¿›å±•ï¼Œå¯¹æ ‡NAS,ç”¨æ‰‹å·¥è®¾è®¡çš„ç»“æ„è·å¾—å¥½çš„æ€§èƒ½

### [ResNeSt: Split-Attention Networks](https://hangzhang.org/files/resnest.pdf)

* ğŸ”‘ Key:   
  * New backbone for det & semantic-seg
  * Split Attention across feature map groups (within a block)
    * A new ResNet Cell 
* ğŸ“ Source:  
* ğŸŒ± Motivation: 
  * A new resnet cell, plug and play with ResNet
    * help the downstream tasks(like Det or Seg)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200428085217.png)
  * ResNet are meant for Image Classification - focus on depthwise & group-wise conv, howerer for downstream task, cross channel information are ctitical
    * Small reception field, no cross-channel interaction
  * create a versatile backbone with universally improved feature representation
* ğŸ’Š Methodology:
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200428090121.png)
  * Feature maps into groups(num of group is cardinality)
    * Radix as the split within a group
  * Split Attention
    * element-wise sum across multiple splits
    * Hï¼ŒW average pooling for gathering global contextual information
    * Channel-wise weighted soft fusion
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200428091033.png)
    * finally for groups, concat them
    * split block output with a shortcut
      * if stided, add another transformation with the output
  * Related with other attention methods
    * SE(Squueze and activation) use global context to predict channel-wise attention factor
      * when r=1ï¼ˆradixï¼‰ResNest is SENet, only difference is 
      * SE employed on the whole block regardless of groups, ResNest applied on each group
    * SKNet feature fusion between network branches
      * (author says that is could be low efficient and hard to caling to larger groups)
* ğŸ“ Exps:
  * 3x3 Max pooling instead of strided conv
  * All the training tricks(a little-bit concerned, we could employ these though)
* ğŸ’¡ Ideas: 
  * SENet
    * Channel-wise aggregation for the global context, then learn a set of weights
      * The excitation is actually an fc
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200428092523.png)
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200428092638.png)
  * SKNet
    * Split - Fuse - Select
      * two group conv branches with different kernel size
      * Fuse is a squeeze and excitation block
      * 2 softmax to get the channel weights, multiplying them, then added   
    * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200428093221.png)
    * Sacrifice a little flops for better perf.
      * Combine Attention with larger kernel


### [DenseNet](http://arxiv.org/abs/1608.06993)
* Thu Huang Gao
* å®ç°
  * Normal Res: x_l = H(x_{l-1})+x_{l-1}
  * Dense: x_l = H([x_0,x_1,...x_{l-1}]) - æ¯ä¸€å±‚éƒ½å’Œå…¶ä¹‹å‰çš„æ‰€æœ‰å±‚æœ‰é“¾æ¥
    * Concat 
* å‚æ•°
  * growth rate k: lth layer has: k_0+k*(l-1) input channel
    * small as 12
  * 1x1 Conv as bottleneck, 4k out channel
  * compression ratio: less channel at transition layer(where pooling is applied)


### [ConDenseNet](http://arxiv.org/abs/1711.09224)
* THU Huang Gao
* Learned Group Conv + Dense
* Target at Mobile, high efficiency - æ‰¾åˆ°è¿æ¥çš„ç›¸å¯¹å…³ç³»
  * denseçš„å…¨è¿æ¥ + learner group convå»é™¤æ‰é‚£äº›ç›¸å¯¹æ— æ•ˆçš„é“¾æ¥
* Normal Conv & Group Conv
  * ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200626150813.png)
  * group conv in 1x1 layer, acc drop.
* å¯¹äºdensenetæ¥è¯´ï¼Œå³ä½¿æŸä¸€ä¸ªfeature mapå’Œæœ¬å±‚ä¸­ä»»ä½•groupéƒ½æ²¡æœ‰å…³ç³»ï¼Œä¹Ÿä¼šä¸åé¢å±‚çš„äº§ç”Ÿè”ç³»(å› ä¸ºidentity mapping)
* å®ç°
  * 2 stage
    * condensing - ç¨€ç–åŒ–çš„æ­£åˆ™ï¼Œpruneæ‰ä½ç»å¯¹å€¼çš„Filterè¿æ¥ï¼Œ(ä¼šä¿æŒæ¯ä¸ªgroupçš„sparsity patternä¸€æ ·ï¼Œå»å…¼å®¹å¸¸è§çš„group-conv)
    * optimizing - ç„¶åå¸¦Maskå»åšæ­£å¸¸çš„è®­ç»ƒ